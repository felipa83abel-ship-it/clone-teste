// @ts-nocheck
// ffmpeg import causa erros de type em node_modules

/**
 * üé§ WHISPER STT (Speech-to-Text) - M√ìDULO INDEPENDENTE
 *
 * Implementa√ß√£o isolada de transcri√ß√£o com Whisper (Local).
 * ‚úÖ FASE 4.1: Removido whisper-1 (OpenAI/Cloud)
 * - Suporte a whisper-cpp-local (offline, alta precis√£o)
 * - Captura de √°udio via MediaRecorder + AudioWorklet
 * - Detec√ß√£o de sil√™ncio autom√°tica (sem streaming, mas com VAD)
 * - Transcri√ß√£o batch com auto-trigger por sil√™ncio
 *
 * Uso:
 * - startAudioWhisper(UIElements)
 * - stopAudioWhisper()
 * - switchDeviceWhisper(INPUT|OUTPUT, newDeviceId)
 */

// ‚ö†Ô∏è Prote√ß√£o contra redeclara√ß√£o (quando carregado via <script> tag m√∫ltiplas vezes)
if (typeof globalThis !== 'undefined' && globalThis._sttWhisperLoaded) {
  console.warn('‚ö†Ô∏è stt-whisper.js j√° foi carregado, ignorando redeclara√ß√£o');
} else if (typeof globalThis !== 'undefined') {
  globalThis._sttWhisperLoaded = true;

  /* ================================ */
  //	IMPORTS
  /* ================================ */

  // ipcRenderer ser√° inicializado por renderer.js
  // Usar fun√ß√£o getter para lazy evaluation
  const getVADEngine = () => globalThis.vadEngine;

  // üî• USA INST√ÇNCIA GLOBAL CRIADA EM RENDERER.JS
  // N√£o criar nova inst√¢ncia, usar a que j√° existe em globalThis.eventBus
  const fs = require('node:fs');
  const path = require('node:path');
  const os = require('node:os');
  const { promisify } = require('node:util');
  const ffmpeg = require('fluent-ffmpeg');

  const { execFile } = require('node:child_process');
  const execFileAsync = promisify(execFile);

  const ffmpegStatic = require('ffmpeg-static');
  if (ffmpegStatic) {
    ffmpeg.setFfmpegPath(ffmpegStatic);
  }

  const getEventBus = () => globalThis.eventBus;
  /* ================================ */
  //	CONSTANTES
  /* ================================ */

  // Configura√ß√£o de √Åudio 16kHz
  const AUDIO_MIME_TYPE = 'audio/webm';

  // Detec√ß√£o de sil√™ncio
  const MINIMUM_CAPTURE_BYTES = 2048; // evita WebMs min√∫sculos que quebram o ffmpeg

  // Configura√ß√£o Whisper Local
  const WHISPER_CLI_EXE = path.join(__dirname, 'models-stt/whisper', 'bin', 'whisper-cli.exe');
  const WHISPER_MODEL = path.join(__dirname, 'models-stt/whisper', 'models', 'ggml-tiny.bin');
  const WHISPER_LOCAL_TIMEOUT_MS = 10000;
  const WHISPER_LOCAL_PARTIAL_TIMEOUT_MS = 1500;
  const WHISPER_WARMUP_FILENAME = 'whisper-warmup.wav';
  const WARMUP_DURATION_SECONDS = 1;
  const WARMUP_SAMPLE_RATE = 16000;

  /* ================================ */
  //	ESTADO GLOBAL DO WHISPER
  /* ================================ */

  // VAD Engine
  let vad = null;

  // Estado de readiness do Whisper Local
  let whisperLocalReady = false;
  let whisperLocalWarmupPromise = null;

  // whisperState mant√©m seu pr√≥prio estado interno
  const whisperState = {
    input: {
      // ========== PROPRIEDADES COMUNS (CORE) ==========
      _isActive: false,
      _stream: null,
      _audioContext: null,
      _processor: null,
      _source: null,
      _startAt: null,
      _isSwitching: false,
      _deviceId: null,

      // ========== GETTERS/SETTERS PADR√ÉO (COMUM A TODOS) ==========
      isActive() {
        return this._isActive;
      },
      setActive(val) {
        this._isActive = val;
      },
      stream() {
        return this._stream;
      },
      setStream(val) {
        this._stream = val;
      },
      audioContext() {
        return this._audioContext;
      },
      setAudioContext(val) {
        this._audioContext = val;
      },
      processor() {
        return this._processor;
      },
      setProcessor(val) {
        this._processor = val;
      },
      source() {
        return this._source;
      },
      setSource(val) {
        this._source = val;
      },
      startAt() {
        return this._startAt;
      },
      setStartAt(val) {
        this._startAt = val;
      },
      isSwitching() {
        return this._isSwitching;
      },
      setIsSwitching(val) {
        this._isSwitching = val;
      },
      deviceId() {
        return this._deviceId;
      },
      setDeviceId(val) {
        this._deviceId = val;
      },

      // ========== PROPRIEDADES ESPEC√çFICAS DO WHISPER ==========
      _mediaRecorder: null,
      _audioChunks: [],

      mediaRecorder() {
        return this._mediaRecorder;
      },
      setMediaRecorder(val) {
        this._mediaRecorder = val;
      },
      audioChunks() {
        return this._audioChunks;
      },
      setAudioChunks(val) {
        this._audioChunks = val;
      },

      // ========== PROPRIEDADES AUXILIARES (VAD + UI STATE) ==========
      author: 'Voc√™',
      lastTranscript: '',
      inSilence: false,
      lastPercent: 0,
      shouldFinalizeAskCurrent: false,
      _lastIsSpeech: false,
      _lastVADTimestamp: null,
      lastActive: null,
      vadWindow: [],
      noiseStartTime: null,
      noiseStopTime: null,
    },
    output: {
      // ========== PROPRIEDADES COMUNS (CORE) ==========
      _isActive: false,
      _stream: null,
      _audioContext: null,
      _processor: null,
      _source: null,
      _startAt: null,
      _isSwitching: false,
      _deviceId: null,

      // ========== GETTERS/SETTERS PADR√ÉO (COMUM A TODOS) ==========
      isActive() {
        return this._isActive;
      },
      setActive(val) {
        this._isActive = val;
      },
      stream() {
        return this._stream;
      },
      setStream(val) {
        this._stream = val;
      },
      audioContext() {
        return this._audioContext;
      },
      setAudioContext(val) {
        this._audioContext = val;
      },
      processor() {
        return this._processor;
      },
      setProcessor(val) {
        this._processor = val;
      },
      source() {
        return this._source;
      },
      setSource(val) {
        this._source = val;
      },
      startAt() {
        return this._startAt;
      },
      setStartAt(val) {
        this._startAt = val;
      },
      isSwitching() {
        return this._isSwitching;
      },
      setIsSwitching(val) {
        this._isSwitching = val;
      },
      deviceId() {
        return this._deviceId;
      },
      setDeviceId(val) {
        this._deviceId = val;
      },

      // ========== PROPRIEDADES ESPEC√çFICAS DO WHISPER ==========
      _mediaRecorder: null,
      _audioChunks: [],

      mediaRecorder() {
        return this._mediaRecorder;
      },
      setMediaRecorder(val) {
        this._mediaRecorder = val;
      },
      audioChunks() {
        return this._audioChunks;
      },
      setAudioChunks(val) {
        this._audioChunks = val;
      },

      // ========== PROPRIEDADES AUXILIARES (VAD + UI STATE) ==========
      author: 'Outros',
      lastTranscript: '',
      inSilence: false,
      lastPercent: 0,
      shouldFinalizeAskCurrent: false,
      _lastIsSpeech: false,
      _lastVADTimestamp: null,
      lastActive: null,
      vadWindow: [],
      noiseStartTime: null,
      noiseStopTime: null,
    },
  };

  /* ================================ */
  //	SERVI√áO WHISPER
  /* ================================ */

  // Verifica se os arquivos do Whisper.cpp existem
  function checkWhisperFiles() {
    const exeExists = fs.existsSync(WHISPER_CLI_EXE);
    const modelExists = fs.existsSync(WHISPER_MODEL);
    return exeExists && modelExists;
  }

  // Realiza warm-up do Whisper Local
  async function warmupWhisperLocal() {
    if (whisperLocalReady) {
      return true;
    }

    if (whisperLocalWarmupPromise) {
      return whisperLocalWarmupPromise;
    }

    if (!checkWhisperFiles()) {
      throw new Error('Arquivos do Whisper.cpp n√£o foram encontrados para o warm-up');
    }

    const warmupPath = path.join(os.tmpdir(), WHISPER_WARMUP_FILENAME);
    whisperLocalWarmupPromise = (async () => {
      try {
        createWarmupWav(warmupPath);
        await execFileAsync(
          WHISPER_CLI_EXE,
          ['-m', WHISPER_MODEL, '-f', warmupPath, '-l', 'pt', '-otxt', '-t', '4', '-np', '-nt'],
          {
            timeout: 30000,
            maxBuffer: 1024 * 1024 * 5,
          }
        );
        whisperLocalReady = true;
        return true;
      } catch (error) {
        console.error('‚ùå Warm-up Whisper falhou:', error.message);
        whisperLocalReady = false;
        throw error;
      } finally {
        removeFileIfExists(warmupPath);
        whisperLocalWarmupPromise = null;
      }
    })();

    return whisperLocalWarmupPromise;
  }

  function createWarmupWav(filePath) {
    const samples = WARMUP_DURATION_SECONDS * WARMUP_SAMPLE_RATE;
    const byteRate = WARMUP_SAMPLE_RATE * 2;
    const blockAlign = 2;
    const buffer = Buffer.alloc(44 + samples * 2);
    buffer.write('RIFF', 0);
    buffer.writeUInt32LE(36 + samples * 2, 4);
    buffer.write('WAVE', 8);
    buffer.write('fmt ', 12);
    buffer.writeUInt32LE(16, 16);
    buffer.writeUInt16LE(1, 20);
    buffer.writeUInt16LE(1, 22);
    buffer.writeUInt32LE(WARMUP_SAMPLE_RATE, 24);
    buffer.writeUInt32LE(byteRate, 28);
    buffer.writeUInt16LE(blockAlign, 32);
    buffer.writeUInt16LE(16, 34);
    buffer.write('data', 36);
    buffer.writeUInt32LE(samples * 2, 40);
    fs.writeFileSync(filePath, buffer);
  }

  // Remove arquivo tempor√°rio se existir
  function removeFileIfExists(filepath) {
    if (!filepath) return;
    try {
      if (fs.existsSync(filepath)) {
        fs.unlinkSync(filepath);
      }
    } catch (error) {
      console.warn(`‚ö†Ô∏è N√£o foi poss√≠vel remover ${filepath}:`, error.message);
    }
  }

  // Prepara arquivo WAV a partir do buffer de √°udio WebM
  async function prepareWavFile(audioBuffer, tempWebmPath, tempWavPath) {
    fs.writeFileSync(tempWebmPath, Buffer.from(audioBuffer));
    await convertWebMToWAVFile(tempWebmPath, tempWavPath);
  }

  // Converte WebM para WAV usando ffmpeg
  function convertWebMToWAVFile(inputPath, outputPath) {
    return new Promise((resolve, reject) => {
      // @ts-ignore - ffmpeg pode ser function ou method, TypeScript n√£o resolve bem
      ffmpeg(inputPath)
        .audioCodec('pcm_s16le')
        .audioFrequency(globalThis.AUDIO_SAMPLE_RATE)
        .audioChannels(1)
        .format('wav')
        .on('end', resolve)
        .on('error', (err) => {
          console.error(
            '‚ùå Erro na convers√£o WebM ‚Üí WAV:',
            err instanceof Error ? err.message : String(err)
          );
          reject(err);
        })
        .save(outputPath);
    });
  }

  // Processa arquivo WAV com Whisper.cpp
  async function processWhisperFile(whisperModelPath, tempWavPath, isPartial = false) {
    const args = [
      '-m',
      whisperModelPath,
      '-f',
      tempWavPath,
      '-l',
      'pt',
      '-otxt',
      '-t',
      '4',
      '-np',
      '-nt',
    ];
    if (isPartial) {
      args.push('-d', '3000', '-ml', '50');
    }

    debugLogWhisper(`üöÄ Executando Whisper: ${WHISPER_CLI_EXE} ${args.join(' ')}`, false);
    const timeout = isPartial ? WHISPER_LOCAL_PARTIAL_TIMEOUT_MS : WHISPER_LOCAL_TIMEOUT_MS;
    const { stdout } = await execFileAsync(WHISPER_CLI_EXE, args, {
      timeout,
      maxBuffer: 1024 * 1024 * 5,
    });
    return (stdout || '').trim();
  }

  // Log detalhado de erros do Whisper Local
  function logWhisperError(execError, tempWavPath) {
    console.error(`‚ùå ERRO NA EXECU√á√ÉO DO WHISPER:`);
    console.error(`   C√≥digo: ${execError.code}`);
    console.error(`   Sinal: ${execError.signal}`);
    console.error(`   Mensagem: ${execError.message}`);
    if (execError.stderr) {
      console.error(`   STDERR do processo: ${execError.stderr}`);
    }
    if (execError.stdout) {
      console.error(`   STDOUT do processo: ${execError.stdout}`);
    }
    if (tempWavPath && fs.existsSync(tempWavPath)) {
      const stats = fs.statSync(tempWavPath);
      console.error(`   üìù WAV file existe: ${stats.size} bytes`);
    } else {
      console.error(`   ‚ùå WAV file N√ÉO EXISTE!`);
    }
  }

  // Transcreve √°udio com Whisper.cpp localmente
  async function transcribeWithWhisperLocal(buffer, source) {
    debugLogWhisper(`üöÄ Enviando para Whisper.cpp (local, alta precis√£o)...`, true);

    if (!checkWhisperFiles()) {
      throw new Error('Arquivos do Whisper.cpp n√£o encontrados!');
    }

    await warmupWhisperLocal();

    const tempDir = os.tmpdir();
    const tempWebmPath = path.join(
      tempDir,
      `whisper-${source}-${Date.now()}-${Math.random().toString(36).slice(2)}.webm`
    );
    const tempWavPath = tempWebmPath.replace('.webm', '.wav');

    try {
      await prepareWavFile(buffer, tempWebmPath, tempWavPath);
      const startTime = Date.now();
      const result = await processWhisperFile(WHISPER_MODEL, tempWavPath);
      debugLogWhisper(`‚úÖ Whisper.cpp conclu√≠do em ${Date.now() - startTime}ms`, true);
      return result;
    } catch (error) {
      logWhisperError(error, tempWavPath);
      throw error;
    } finally {
      removeFileIfExists(tempWebmPath);
      removeFileIfExists(tempWavPath);
    }
  }

  // Transcreve √°udio com o modelo Whisper configurado
  async function transcribeWhisper(audioBlob, source) {
    // ‚úÖ Apenas whisper-cpp-local (offline) est√° dispon√≠vel ap√≥s remover whisper-1
    const sttModel = 'whisper-cpp-local';
    debugLogWhisper(`üé§ Transcri√ß√£o (${sttModel}): ${audioBlob.size} bytes`, true);

    const buffer = Buffer.from(await audioBlob.arrayBuffer());

    try {
      let result;

      if (sttModel === 'whisper-cpp-local') {
        result = await transcribeWithWhisperLocal(buffer, source);
      } else {
        throw new Error(
          `Modelo Whisper desconhecido: ${sttModel} (apenas whisper-cpp-local est√° dispon√≠vel)`
        );
      }

      debugLogWhisper(
        `üìù Resultado (${result.length} chars): "${result.substring(0, 80)}${result.length > 80 ? '...' : ''}"`,
        false
      );
      return result;
    } catch (error) {
      console.error(`‚ùå Transcri√ß√£o Whisper falhou (${sttModel}):`, error.message);
      throw new Error(
        `Transcri√ß√£o com ${sttModel} falhou: ${error.message}. Altere o modelo em "Configura√ß√µes ‚Üí API e Modelos"`
      );
    }
  }

  /* ================================ */
  //	VAD (VOICE ACTIVITY DETECTION)
  /* ================================ */

  // Atualiza estado VAD
  function updateVADState(vars, isSpeech) {
    vars._lastIsSpeech = !!isSpeech;
    vars._lastVADTimestamp = Date.now();
    if (isSpeech) vars.lastActive = Date.now();
  }

  /* ================================ */
  //	WHISPER - INICIAR FLUXO (STT)
  /* ================================ */

  // Inicia captura de √°udio do dispositivo de entrada ou sa√≠da com Whisper
  async function startWhisper(source, UIElements) {
    // Configura√ß√µes espec√≠ficas por source
    const config = {
      input: {
        deviceKey: 'inputSelect',
        accessMessage: 'üé§ Solicitando acesso √† entrada de √°udio (Microfone)...',
        threshold: 0.02,
        startLog: '‚ñ∂Ô∏è Captura Whisper INPUT iniciada',
      },
      output: {
        deviceKey: 'outputSelect',
        accessMessage: 'üîä Solicitando acesso √† sa√≠da de √°udio (VoiceMeter/Stereo Mix)...',
        threshold: 0.005,
        startLog: '‚ñ∂Ô∏è Captura Whisper OUTPUT iniciada',
      },
    };

    const cfg = config[source];
    if (!cfg) {
      throw new Error(
        `‚ùå Source inv√°lido: ${source}. Use ${globalThis.INPUT} ou ${globalThis.OUTPUT}`
      );
    }

    const vars = whisperState[source];

    if (vars.isActive?.()) {
      console.warn(`‚ö†Ô∏è Whisper ${source.toUpperCase()} j√° ativo`);
      return;
    }

    try {
      // Obt√©m o dispositivo selecionado no UI
      const deviceId = UIElements[cfg.deviceKey]?.value;

      debugLogWhisper(
        `üîä Iniciando captura ${source.toUpperCase()} com dispositivo: ${deviceId}`,
        false
      );

      // Solicita acesso ao dispositivo selecionado
      debugLogWhisper(cfg.accessMessage, false);

      // Obt√©m stream de √°udio
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          deviceId: { exact: deviceId },
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: false,
        },
      });

      debugLogWhisper(`‚úÖ Acesso ao √°udio ${source.toUpperCase()} autorizado`, true);

      // Cria MediaRecorder para captura de √°udio (ANTES de AudioWorklet para ter refer√™ncia)
      const mediaRecorder = new MediaRecorder(stream, { mimeType: AUDIO_MIME_TYPE });

      // Acumula chunks conforme s√£o capturados
      const audioChunks = [];
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunks.push(event.data);
        }
      };

      // Quando para, envia para transcri√ß√£o
      mediaRecorder.onstop = async () => {
        debugLogWhisper(`üõë MediaRecorder parado para ${source.toUpperCase()}`, false);

        if (audioChunks.length > 0) {
          const audioBlob = new Blob(audioChunks, { type: AUDIO_MIME_TYPE });
          if (audioBlob.size < MINIMUM_CAPTURE_BYTES) {
            console.warn(
              `‚ö†Ô∏è Captura ${source.toUpperCase()} muito curta (${audioBlob.size} bytes); pulando transcri√ß√£o`
            );
          } else {
            try {
              const transcribedText = await transcribeWhisper(audioBlob, source);
              handleWhisperMessage(transcribedText, source);
            } catch (error) {
              console.error(`‚ùå Erro ao transcrever ${source}:`, error.message);
            }
          }
        }

        // Limpa chunks para pr√≥xima grava√ß√£o
        audioChunks.length = 0;

        // Reinicia MediaRecorder para continuar capturando ap√≥s a transcri√ß√£o
        if (vars.isActive() && mediaRecorder.state === 'inactive') {
          try {
            mediaRecorder.start();
            debugLogWhisper(`‚ñ∂Ô∏è MediaRecorder reiniciado para ${source.toUpperCase()}`, false);
          } catch (restartError) {
            console.error(`‚ùå Erro ao reiniciar MediaRecorder (${source}):`, restartError);
          }
        }
      };

      // Cria AudioContext 16kHz para processamento em tempo real (VAD)
      const audioContext = new (globalThis.AudioContext || globalThis.webkitAudioContext)({
        sampleRate: globalThis.AUDIO_SAMPLE_RATE,
      });
      await audioContext.audioWorklet.addModule(globalThis.AUDIO_WORKLET_PROCESSOR_PATH);

      // Cria MediaStreamSource e guarda via whisperState
      const mediaSource = audioContext.createMediaStreamSource(stream);

      // Inicia AudioWorklet para captura e processamento de √°udio em tempo real
      const processor = new AudioWorkletNode(audioContext, globalThis.STT_AUDIO_WORKLET_PROCESSOR);
      processor.port.postMessage({ type: 'setThreshold', threshold: cfg.threshold });
      processor.port.onmessage = (event) => {
        // Processa mensagens do AudioWorklet (audioData e volumeUpdate separadamente)
        processIncomingAudioMessageWhisper(source, event.data, mediaRecorder).catch((error_) =>
          console.error(`‚ùå Erro ao processar mensagem do worklet (${source}):`, error_)
        );
      };

      // Conecta fluxo: Source -> processor -> destination
      mediaSource.connect(processor);
      processor.connect(audioContext.destination);

      // Atualiza refer√™ncias de estado
      vars.setStream(stream);
      vars.setAudioContext(audioContext);
      vars.setSource(mediaSource);
      vars.setProcessor(processor);
      vars.setActive(true);
      vars.setStartAt(Date.now());
      vars.lastActive = Date.now();
      vars.setMediaRecorder(mediaRecorder);

      // Inicia grava√ß√£o
      mediaRecorder.start();

      debugLogWhisper(cfg.startLog, true);
    } catch (error) {
      console.error(`‚ùå Erro ao iniciar Whisper ${source.toUpperCase()}:`, error);
      try {
        vars.setActive(false);
      } catch (error_) {
        console.warn('‚ö†Ô∏è Aviso ao resetar active flag:', error_ && (error_.message || error_));
      }
      stopWhisper(source);
      throw error;
    }
  }

  // Processa mensagens de √°udio recebida do AudioWorklet
  async function processIncomingAudioMessageWhisper(source, data, mediaRecorder) {
    const vars = whisperState[source];
    if (data.type === 'audioData') {
      // Processa chunk de √°udio PCM16
      onAudioChunkWhisper(source, data, vars);
    } else if (data.type === 'volumeUpdate') {
      vars.lastPercent = data.percent;

      // Processa atualiza√ß√£o de volume/VAD
      handleVolumeUpdate(source, data.percent);

      // Detecta sil√™ncio e dispara transcri√ß√£o autom√°tica
      handleSilenceDetectionWhisper(source, data.percent, mediaRecorder);
    }
  }

  // Processa chunk de √°udio PCM16 do AudioWorklet
  function onAudioChunkWhisper(source, data, vars) {
    const { pcm16 } = data;

    if (!pcm16 || pcm16.length === 0) return;

    // VAD: Detecta fala usando VAD Engine
    const isSpeech = vad?.detectSpeech(pcm16, vars.lastPercent, vars.vadWindow);
    updateVADState(vars, isSpeech);
  }

  // Trata detec√ß√£o de sil√™ncio com VAD ou fallback
  function handleSilenceDetectionWhisper(source, percent, mediaRecorder) {
    const vars = whisperState[source];
    const silenceTimeout =
      source === globalThis.INPUT
        ? globalThis.SILENCE_TIMEOUT_INPUT
        : globalThis.SILENCE_TIMEOUT_OUTPUT;
    const now = Date.now();

    // Decis√£o principal: VAD se dispon√≠vel, sen√£o fallback por volume
    const useVADDecision = vad?.isEnabled() && vars._lastIsSpeech !== undefined;
    const effectiveSpeech = useVADDecision ? !!vars._lastIsSpeech : percent > 0;

    debugLogWhisper(
      `üîç VAD ${source}: ${vars._lastIsSpeech ? 'speech' : 'silence'} - üîä volume: ${percent.toFixed(2)}%`,
      false
    );

    if (effectiveSpeech) {
      // Se detectou fala, resetamos estado de sil√™ncio
      if (vars.inSilence) {
        if (!vars.noiseStartTime) vars.noiseStartTime = Date.now();

        const noiseDuration = vars.noiseStartTime - vars.noiseStopTime;
        vars.noiseStopTime = null;

        debugLogWhisper(
          `üü¢ üü¢ üü¢ ***** üîä Fala real detectada ap√≥s (${noiseDuration}ms) *****`,
          true
        );
      }

      vars.inSilence = false;
      vars.shouldFinalizeAskCurrent = false;
      vars.lastActive = now;
      vars.noiseStartTime = null;
    } else {
      // Sil√™ncio detectado ‚Üí verifica se j√° passou o timeout
      const elapsed = now - vars.lastActive;

      // Entrando em sil√™ncio est√°vel
      if (elapsed >= silenceTimeout && !vars.inSilence) {
        vars.inSilence = true;
        vars.shouldFinalizeAskCurrent = true;
        vars.noiseStopTime = Date.now();

        debugLogWhisper(`üî¥ üî¥ üî¥ ***** üîá Sil√™ncio est√°vel detectado (${elapsed}ms) *****`, true);

        // Dispara finalize apenas uma vez
        mediaRecorder.stop();
      }
    }
  }

  /* ================================ */
  //	PROCESSAMENTO DE MENSAGENS
  /* ================================ */

  // Processa mensagens do Whisper (final ou parcial)
  function handleWhisperMessage(result, source = globalThis.INPUT) {
    handleFinalWhisperMessage(source, result);
  }

  // Processa mensagens finais do Whisper (transcri√ß√µes completas)
  function handleFinalWhisperMessage(source, transcript) {
    debugLogWhisper(`üìù üü¢ Handle FINAL [${source.toUpperCase()}]: "${transcript}"`, true);

    const vars = whisperState[source];
    vars.lastTranscript = transcript.trim() ? transcript : vars.lastTranscript;

    if (transcript.trim()) {
      // Adiciona placeholder com transcri√ß√£o
      const placeholderId = `whisper-${source}-${Date.now()}-${Math.floor(Math.random() * 1000)}`;
      const metrics = calculateTimingMetrics(vars);

      // Adiciona transcri√ß√£o com placeholder na UI
      addTranscriptPlaceholder(vars.author, placeholderId, metrics.startStr);
      // Preenche placeholder com resultado final
      fillTranscriptPlaceholder(vars.author, transcript, placeholderId, metrics);
      // Limpa interim do UI
      clearInterim(source);
    }

    // Atualiza CURRENT question (apenas para output)
    updateCurrentQuestion(source, transcript, false);
  }

  /* ================================ */
  //	HELPERS
  /* ================================ */

  // Atualiza volume recebido do AudioWorklet
  function handleVolumeUpdate(source, percent) {
    // Emite volume para UI
    const ev = source === globalThis.INPUT ? 'inputVolumeUpdate' : 'outputVolumeUpdate';
    getEventBus().emit(ev, { percent });
  }

  // Adiciona transcri√ß√£o com placeholder ao UI
  function addTranscriptPlaceholder(author, placeholderId, timeStr) {
    getEventBus().emit('transcriptAdd', {
      author,
      text: '...',
      timeStr,
      elementId: 'conversation',
      placeholderId,
    });
  }

  // Preenche placeholder com transcri√ß√£o final
  function fillTranscriptPlaceholder(author, transcript, placeholderId, metrics) {
    getEventBus().emit('placeholderFulfill', {
      speaker: author,
      text: transcript,
      placeholderId,
      ...metrics,
      showMeta: false,
    });
  }

  // Limpa interim transcript do UI
  function clearInterim(source) {
    const interimId =
      source === globalThis.INPUT ? 'whisper-interim-input' : 'whisper-interim-output';
    getEventBus().emit('clearInterim', { id: interimId });
  }

  // Atualiza interim transcript no UI
  function _updateInterim(source, transcript, author) {
    const interimId =
      source === globalThis.INPUT ? 'whisper-interim-input' : 'whisper-interim-output';
    getEventBus().emit('updateInterim', {
      id: interimId,
      speaker: author,
      text: transcript,
    });
  }

  // Atualiza CURRENT question (apenas para output)
  function updateCurrentQuestion(source, transcript, isInterim = false) {
    const vars = whisperState[source];
    if (source === globalThis.OUTPUT && globalThis.RendererAPI?.handleCurrentQuestion) {
      globalThis.RendererAPI.handleCurrentQuestion(vars.author, transcript, {
        isInterim,
        shouldFinalizeAskCurrent: vars.shouldFinalizeAskCurrent,
      });
      // üî• S√≥ reseta quando for mensagem FINAL (n√£o interim)
      if (!isInterim && vars.shouldFinalizeAskCurrent) vars.shouldFinalizeAskCurrent = false;
    }
  }

  // Calcula m√©tricas de timing para transcri√ß√£o
  function calculateTimingMetrics(vars) {
    const startAt = vars.startAt?.();
    const now = Date.now();
    const elapsedMs = startAt ? now - startAt : 0;
    return {
      startStr: startAt
        ? new Date(startAt).toLocaleTimeString()
        : new Date(now).toLocaleTimeString(),
      stopStr: new Date(now).toLocaleTimeString(),
      recordingDuration: (elapsedMs / 1000).toFixed(2),
      latency: (elapsedMs / 1000).toFixed(2),
      total: (elapsedMs / 1000).toFixed(2),
    };
  }

  /* ================================ */
  //	TROCA DE DISPOSITIVO
  /* ================================ */

  // Troca din√¢mica do dispositivo Whisper (input/output)
  async function changeDeviceWhisper(source, newDeviceId) {
    const vars = whisperState[source];

    debugLogWhisper(
      `üîÑ changeDeviceWhisper CHAMADO: source=${source}, newDeviceId="${newDeviceId}"`,
      false
    );

    // Verifica se j√° est√° trocando
    if (vars.isSwitching?.()) {
      console.warn(`‚ö†Ô∏è J√° em processo de troca de dispositivo ${source.toUpperCase()}`);
      return;
    }

    // üî• IN√çCIO: Marca como trocando para evitar chamadas duplicadas
    vars.setIsSwitching(true);

    try {
      // CASO 1: Device vazio ‚Üí STOP
      const normalizedDeviceId = newDeviceId?.toString().toLowerCase().trim() || '';
      if (!normalizedDeviceId || normalizedDeviceId === 'nenhum') {
        debugLogWhisper(
          `üõë Device vazio para ${source.toUpperCase()}, parando Whisper... (deviceId="${newDeviceId}")`,
          false
        );
        stopWhisper(source);
        return;
      }

      // CASO 2: Inativo + device v√°lido ‚Üí START
      if (!vars.isActive()) {
        debugLogWhisper(
          `üöÄ Whisper ${source.toUpperCase()} inativo, iniciando com novo dispositivo...`,
          false
        );
        const uiElement = {
          [source === globalThis.INPUT ? 'inputSelect' : 'outputSelect']: { value: newDeviceId },
        };
        await startWhisper(source, uiElement);
        return;
      }

      // CASO 3: Ativo + device alterado ‚Üí RESTART
      if (vars.deviceId?.() !== newDeviceId) {
        debugLogWhisper(
          `üîÑ Whisper ${source.toUpperCase()} ativo com device diferente, reiniciando...`,
          false
        );
        try {
          // Para completamente o Whisper anterior
          stopWhisper(source);
          // Aguarda um pouco para liberar recursos
          await new Promise((resolve) => setTimeout(resolve, 300));
          // Reinicia com novo dispositivo
          const uiElement = {
            [source === 'input' ? 'inputSelect' : 'outputSelect']: { value: newDeviceId },
          };
          await startWhisper(source, uiElement);
        } catch (error) {
          console.error(`‚ùå Erro ao reiniciar ap√≥s troca de dispositivo:`, error);
        }
      }
    } finally {
      // üî• FIM: Seta deviceId e marca como n√£o trocando mais
      vars.setDeviceId(newDeviceId);
      vars.setIsSwitching(false);
    }
  }

  /* ================================ */
  //	WHISPER - PARAR FLUXO (STT)
  /* ================================ */

  // Para captura de √°udio
  function stopWhisper(source) {
    const vars = whisperState[source];

    // üî• IMPORTANTE: Faz cleanup MESMO que isActive() seja false
    // Pode haver estado inconsistente (ex: recorder ativo mas isActive=false)

    try {
      // Desconecta AudioWorklet
      if (vars.processor()) {
        vars.processor().disconnect();
        vars.setProcessor(null);
      }

      if (vars.source()) {
        vars.source().disconnect();
        vars.setSource(null);
      }

      // Fecha AudioContext
      if (vars.audioContext()) {
        if (vars.audioContext().state !== 'closed') {
          vars
            .audioContext()
            .close()
            .catch((err) => console.warn(`‚ö†Ô∏è Erro ao fechar AudioContext:`, err));
        }
        vars.setAudioContext(null);
      }

      // Para grava√ß√£o
      if (vars.mediaRecorder() && vars.mediaRecorder().state !== 'inactive') {
        vars.mediaRecorder().stop();
      }

      // Limpa stream
      if (vars.stream()) {
        vars
          .stream()
          .getTracks()
          .forEach((track) => track.stop());
      }

      // Reseta estado
      vars.setActive(false);
      vars.setStream(null);
      vars.setMediaRecorder(null);
      vars.setAudioChunks([]);

      // Zera o oscilador no UI
      handleVolumeUpdate(source, 0);

      debugLogWhisper(`üõë Captura Whisper ${source.toUpperCase()} parada`, true);
    } catch (error) {
      console.error(`‚ùå Erro ao parar Whisper ${source.toUpperCase()}:`, error);
    }
  }

  /* ================================ */
  //	DEBUG LOG WHISPER
  /* ================================ */

  /**
   * Log de debug padronizado para stt-whisper.js
   * Por padr√£o nunca loga, se quiser mostrar √© s√≥ passar true.
   * @param {*} msg
   * @param {boolean} showLog - true para mostrar, false para ignorar
   */

  /**
   * Log de debug padronizado para stt-whisper.js
   * Por padr√£o nunca loga, se quiser mostrar √© s√≥ passar true.
   * @param {...any} args - Argumentos para log (√∫ltimo pode ser booleano showLog)
   */
  function debugLogWhisper(...args) {
    const maybeFlag = args.at(-1);
    const showLog = typeof maybeFlag === 'boolean' ? maybeFlag : false;

    if (!showLog) return; // Ignorar se showLog √© false

    const nowLog = new Date();
    const timeStr =
      `${nowLog.getHours().toString().padStart(2, '0')}:` +
      `${nowLog.getMinutes().toString().padStart(2, '0')}:` +
      `${nowLog.getSeconds().toString().padStart(2, '0')}.` +
      `${nowLog.getMilliseconds().toString().padStart(3, '0')}`;

    const cleanArgs = typeof maybeFlag === 'boolean' ? args.slice(0, -1) : args;
    // Logar no console
    console.log(
      `%c‚è±Ô∏è [${timeStr}] ü™≤ ‚ùØ‚ùØ‚ùØ‚ùØ Debug em stt-whisper.js:`,
      'color: blue; font-weight: bold;',
      ...cleanArgs
    );

    // Registrar em Logger para hist√≥rico de debug
    globalThis.Logger.debug(`[stt-whisper] ${cleanArgs.join(' ')}`, { timeStr });
  }

  /* ================================ */
  //	INTERFACE P√öBLICA
  /* ================================ */

  /**
   * Inicia Whisper para INPUT + OUTPUT
   */
  async function startAudioWhisper(UIElements) {
    try {
      // Inicializa VAD Engine (singleton)
      vad = getVADEngine();
      debugLogWhisper(
        `‚úÖ VAD Engine inicializado - Status: ${JSON.stringify(vad.getStatus())}`,
        true
      );

      // üî• Whisper: Inicia INPUT/OUTPUT
      if (UIElements.inputSelect?.value) await startWhisper(globalThis.INPUT, UIElements);
      if (UIElements.outputSelect?.value) await startWhisper(globalThis.OUTPUT, UIElements);
    } catch (error) {
      console.error('‚ùå Erro ao iniciar Whisper:', error);
      throw error;
    }
  }

  /**
   * Para Whisper para INPUT + OUTPUT
   */
  function stopAudioWhisper() {
    try {
      // üé§ Whisper: Para INPUT e OUTPUT
      stopWhisper(globalThis.INPUT);
      stopWhisper(globalThis.OUTPUT);
      debugLogWhisper('üõë Whisper completamente parado', true);
    } catch (error) {
      console.error('‚ùå Erro ao parar Whisper:', error);
    }
  }

  /**
   * Troca din√¢mica do dispositivo (input/output) mantendo Whisper ativo
   */
  async function switchDeviceWhisper(source, newDeviceId) {
    try {
      debugLogWhisper(
        `üîÑ [switchDeviceWhisper] In√≠cio: source=${source}, newDeviceId="${newDeviceId}"`,
        false
      );
      const result = await changeDeviceWhisper(source, newDeviceId);
      return result;
    } catch (err) {
      console.error(`‚ùå [switchDeviceWhisper] Erro em changeDeviceWhisper:`, err);
      throw err;
    }
  }

  /* ================================ */
  //	EXPORTS (CommonJS)
  /* ================================ */

  module.exports = {
    startAudioWhisper,
    stopAudioWhisper,
    switchDeviceWhisper,
  };

  // ‚úÖ Exportar para globalThis dentro do bloco de inicializa√ß√£o
  if (typeof globalThis !== 'undefined') {
    globalThis.startAudioWhisper = startAudioWhisper;
    globalThis.stopAudioWhisper = stopAudioWhisper;
    globalThis.switchDeviceWhisper = switchDeviceWhisper;
  }
} // Fim da prote√ß√£o contra redeclara√ß√£o
