# ğŸ¯ InstruÃ§Ãµes para PrÃ³ximas AÃ§Ãµes

## Status Atual: âœ… FIX ENTREVISTA IMPLEMENTADO

A soluÃ§Ã£o foi desenvolvida e commitada. Falta executar os testes para validaÃ§Ã£o.

---

## ğŸ“‹ Checklist de Testes (Antes de PrÃ³ximas Tarefas)

### âœ… Teste 1: Pergunta Simples em Entrevista

```
1. npm start
2. Ativar modo entrevista
3. Falar uma pergunta simples: "Qual Ã© o seu nome?"
4. Detectar silÃªncio
5. Aguardar resposta do GPT
6. Verificar logs:
   - "ğŸŸ¢ ********  EstÃ¡ em silÃªncio"
   - "â³ Iniciando stream LLM"
   - "ğŸ”¥ [ENTREVISTA] Promovendo CURRENT..."
   - Sem erros
```

### âœ… Teste 2: Duas Perguntas Consecutivas

```
1. Completar Teste 1
2. Falar segunda pergunta: "Qual Ã© sua idade?"
3. Detectar silÃªncio
4. Aguardar resposta
5. Verificar:
   - CURRENT limpo apÃ³s primeira
   - Segunda pergunta promovida corretamente
   - Sem erro "pergunta jÃ¡ finalizada"
   - HistÃ³rico tem 2 perguntas/respostas
```

### âœ… Teste 3: MÃºltiplas Perguntas (3-5)

```
1. Repetir Teste 2 mais 2-3 vezes
2. Perguntas: "Qual Ã© seu hobby?", "Qual mÃºsica favorita?", etc.
3. Verificar fluxo contÃ­nuo sem travamentos
4. HistÃ³rico acumula corretamente
```

### âœ… Teste 4: RuÃ­do SimultÃ¢neo

```
1. Modo entrevista, pergunta 1
2. Enquanto GPT responde:
   - Tossir
   - Falar ao fundo
   - Som do sistema
3. Verificar logs mostram "â¸ï¸ IGNORANDO atualizaÃ§Ã£o..."
4. GPT responde com texto original (nÃ£o misturado)
```

---

## ğŸš€ Passos para Executar Testes

### ComeÃ§ar SessÃ£o de Teste

```bash
cd d:\Dev\Projeto Electron\git-felipa-perssua\clone-teste
npm start

# App abre em modo Electron
# Console mostra logs de inicializaÃ§Ã£o
```

### Monitorar Logs

Abrir DevTools (F12) ou verificar console do terminal para:

- `ğŸŸ¢ ********  EstÃ¡ em silÃªncio` â†’ VAD funcionando
- `â³ Iniciando stream LLM` â†’ GPT acionado
- `ğŸ”¥ [ENTREVISTA] Promovendo CURRENT` â†’ PromoÃ§Ã£o ocorrendo
- `â¸ï¸ IGNORANDO atualizaÃ§Ã£o` â†’ Flag isBeingAnswered funcionando

### Verificar Dados

- HistÃ³rico de perguntas/respostas acumula?
- CURRENT limpa entre perguntas?
- Sem duplicaÃ§Ã£o de respostas?

---

## ğŸ“Š Matriz de Teste

| Teste | AÃ§Ã£o                   | Resultado Esperado               | Status  |
| ----- | ---------------------- | -------------------------------- | ------- |
| 1     | 1 pergunta â†’ silence   | âœ… Promove, limpa CURRENT        | â³ TODO |
| 2     | 2 perguntas â†’ silence  | âœ… Ambas promovidas corretamente | â³ TODO |
| 3     | 3+ perguntas â†’ silence | âœ… Fluxo contÃ­nuo                | â³ TODO |
| 4     | RuÃ­do durante resposta | âœ… Ignorado, texto correto       | â³ TODO |
| 5     | Normal mode            | âœ… NÃ£o afetado                   | â³ TODO |

---

## ğŸ”§ Se Testes Falharem

### Erro: "pergunta jÃ¡ finalizada"

- [ ] Verificar se isBeingAnswered = false em resetCurrentQuestion()
- [ ] Verificar se llmStreamEnd estÃ¡ chamando reset
- [ ] Logs mostram? `ğŸ”¥ [ENTREVISTA] Promovendo`

### Erro: Texto misturado nas respostas

- [ ] Verificar se handleCurrentQuestion() retorna early quando isBeingAnswered = true
- [ ] Procurar por logs: `â¸ï¸ IGNORANDO atualizaÃ§Ã£o`
- [ ] Verificar se mais Ã¡udio chega durante resposta

### Erro: CURRENT nÃ£o limpa

- [ ] Verificar se renderCurrentQuestion() Ã© chamado apÃ³s promoÃ§Ã£o
- [ ] Procurar por erro em promoteCurrentToHistory()
- [ ] Verificar histÃ³rico - pergunta foi promovida?

---

## ğŸ“ ApÃ³s Testes Bem-Sucedidos

### FASE 4: Implementar Template Gemini

```javascript
// Em main.js adicionar handler para Gemini
case 'gemini':
    // Implementar integraÃ§Ã£o Gemini
    // Usar formato similar OpenAI
```

### FASE 5: Cleanup e DocumentaÃ§Ã£o

- [ ] Remover logs de debug (ou mover para DEBUG_MODE)
- [ ] Validar todos os caminhos de arquivo
- [ ] Atualizar README.md com status final
- [ ] Preparar para release

---

## ğŸ“‚ Arquivos Relevantes

- **renderer.js**: LÃ³gica principal (currentQuestion, interview mode)
- **TEST_ENTREVISTA.md**: CenÃ¡rios de teste (este arquivo)
- **FIX_ENTREVISTA_CONCURRENT.md**: AnÃ¡lise tÃ©cnica do fix
- **RESUMO_SESSAO_2025_01_23.md**: Timeline completa

---

## ğŸ“ ReferÃªncia RÃ¡pida

### Flag isBeingAnswered

```javascript
// Iniciar LLM response
currentQuestion.isBeingAnswered = true; // PAUSA

// Loop processamento
while (gptResponding) {
	// Novo Ã¡udio chega
	if (currentQuestion.isBeingAnswered) {
		return; // â† IGNORADO âœ…
	}
}

// Fim resposta
currentQuestion.isBeingAnswered = false; // RESUME
```

### Event Flow

```
Audio â†’ handleCurrentQuestion()
     â†’ updateCurrentQuestion() [se nÃ£o isBeingAnswered]
     â†’ renderCurrentQuestion()

Silence â†’ finalizeCurrentQuestion()
       â†’ askLLM() + isBeingAnswered = true
       â†’ llmStreamEnd
       â†’ promoteCurrentToHistory()
       â†’ resetCurrentQuestion() [isBeingAnswered = false]
```

---

## â±ï¸ Tempo Estimado

- Teste 1-3: **15-20 minutos**
- Teste 4: **10 minutos**
- Teste 5: **5 minutos**
- **Total**: ~45 minutos

---

## ğŸ¯ Sucesso = Quando...

âœ… Teste 1: Pergunta Ã© feita â†’ silence detectado â†’ GPT responde â†’ texto limpo  
âœ… Teste 2: Segunda pergunta funciona igual a primeira  
âœ… Teste 3: 5 perguntas consecutivas sem erros  
âœ… Teste 4: RuÃ­do durante resposta Ã© ignorado  
âœ… Teste 5: Modo normal continua funcionando

---

**Pronto para comeÃ§ar testes?** â†’ Execute: `npm start`
