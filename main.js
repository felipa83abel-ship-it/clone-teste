/* ================================
   IMPORTS E CONFIGURA√á√ïES INICIAIS
=============================== */

// üî• DEEPGRAM: Carrega vari√°veis de ambiente do .env
require('dotenv').config();

const { app, BrowserWindow, globalShortcut, ipcMain } = require('electron');
const OpenAI = require('openai');
const fs = require('node:fs');
const path = require('node:path');
const { execFile } = require('node:child_process');
const { promisify } = require('node:util');
const execFileAsync = promisify(execFile);

// Habilita reload autom√°tico em desenvolvimento
if (process.env.NODE_ENV === 'development') {
	try {
		require('electron-reload')(__dirname, {
			electron: require(`${__dirname}/node_modules/electron`),
		});
	} catch (err) {
		console.log('electron-reload n√£o carregado:', err);
	}
}

// Importa electron-store para armazenamento seguro
let ElectronStore;
try {
	ElectronStore = require('electron-store');
	if (ElectronStore.default) {
		ElectronStore = ElectronStore.default;
	}
	console.log('‚úÖ electron-store importado com sucesso');
} catch (error) {
	console.error('‚ùå Erro ao importar electron-store:', error);
	ElectronStore = null;
}

/* ================================
   CONSTANTES
=============================== */

const USE_FAKE_STREAM_GPT = false; // mude para false quando quiser usar o real

// Configura√ß√£o de modelo Vosk (local)
const VOSK_CONFIG = {
	// MODEL: 'vosk-models/vosk-model-small-pt-0.3' ( Modelo pequeno, r√°pido, menos preciso)
	MODEL: process.env.VOSK_MODEL || 'vosk-models/vosk-model-small-pt-0.3',
};

// Configura√ß√£o do modelo Whisper.cpp (local)
const WHISPER_CLI_EXE = path.join(__dirname, 'whisper-local', 'bin', 'whisper-cli.exe');
// Modelo ggml-tiny (Modelo menor, r√°pido, menos preciso)
const WHISPER_MODEL = path.join(__dirname, 'whisper-local', 'models', 'ggml-tiny.bin');

/* ================================
   ESTADO GLOBAL
=============================== */
let mainWindow = null;
let openaiClient = null;
let secureStore = null;
let clickThroughEnabled = false;

// üî• NOVO: Gerenciamento do Whisper.cpp como servidor persistente
let whisperServerProcess = null;
let whisperServerReady = false;
const { spawn } = require('node:child_process');

/* ================================
   INICIALIZA√á√ÉO DO SECURE STORE
=============================== */
if (ElectronStore) {
	try {
		secureStore = new ElectronStore({
			name: 'secure-keys',
			encryptionKey: 'perssua-secure-storage-v1',
		});
		console.log('‚úÖ SecureStore inicializado com sucesso');

		// Inicializa cliente OpenAI se houver chave salva
		const savedKey = secureStore.get('apiKeys.openai');
		if (savedKey && savedKey.length > 10) {
			console.log('üîë Chave OpenAI encontrada - inicializando cliente...');
			initializeOpenAIClient(savedKey);
		}
	} catch (error) {
		console.error('‚ùå Erro ao criar secureStore:', error);
	}
}

/* ================================
   FUN√á√ïES AUXILIARES
=============================== */

/**
 * Inicializa o cliente OpenAI
 */
function initializeOpenAIClient(apiKey = null) {
	try {
		const key = apiKey || (secureStore ? secureStore.get('apiKeys.openai') : null);

		if (!key || typeof key !== 'string' || key.trim().length < 10) {
			console.warn('‚ö†Ô∏è Chave da API inv√°lida ou muito curta');
			openaiClient = null;
			return false;
		}

		const maskedKey = key.substring(0, 8) + '...';
		console.log(`---> Inicializando cliente OpenAI com chave: ${maskedKey}`);

		openaiClient = new OpenAI({
			apiKey: key.trim(),
		});

		console.log('‚úÖ Cliente OpenAI inicializado com sucesso');
		return true;
	} catch (error) {
		console.error('‚ùå Erro ao inicializar cliente OpenAI:', error.message);
		openaiClient = null;
		return false;
	}
}

/**
 * Verifica se os arquivos do Whisper.cpp local existem
 */
function checkWhisperFiles() {
	const exeExists = fs.existsSync(WHISPER_CLI_EXE);
	const modelExists = fs.existsSync(WHISPER_MODEL);

	console.log('üîç Verificando arquivos Whisper:');
	console.log(`   Execut√°vel: ${exeExists ? '‚úÖ' : '‚ùå'} ${WHISPER_CLI_EXE}`);
	console.log(`   Modelo: ${modelExists ? '‚úÖ' : '‚ùå'} ${WHISPER_MODEL}`);

	return exeExists && modelExists;
}

/**
 * üî• NOVO: Inicia Whisper.cpp como servidor persistente
 * Mant√©m o processo rodando enquanto o usu√°rio est√° em modo de escuta
 * Isso evita overhead de inicializa√ß√£o e problemas com WebM corrompido
 */
async function startWhisperServer() {
	if (whisperServerProcess) {
		console.log('‚ö†Ô∏è Servidor Whisper j√° rodando');
		return true;
	}

	if (!checkWhisperFiles()) {
		console.error('‚ùå Arquivos do Whisper n√£o encontrados!');
		return false;
	}

	console.log('üöÄ Iniciando Whisper.cpp como servidor persistente...');

	try {
		// Inicia Whisper.cpp em modo de espera por stdin
		whisperServerProcess = spawn(WHISPER_CLI_EXE, ['-m', WHISPER_MODEL, '-l', 'pt', '--print-progress'], {
			stdio: ['pipe', 'pipe', 'pipe'],
			detached: false,
		});

		whisperServerProcess.on('close', code => {
			console.log(`üìå Processo Whisper encerrado com c√≥digo: ${code}`);
			whisperServerProcess = null;
			whisperServerReady = false;
		});

		whisperServerProcess.on('error', err => {
			console.error(`‚ùå Erro no processo Whisper: ${err.message}`);
			whisperServerProcess = null;
			whisperServerReady = false;
		});

		whisperServerReady = true;
		console.log('‚úÖ Servidor Whisper iniciado com sucesso');
		return true;
	} catch (error) {
		console.error(`‚ùå Erro ao iniciar servidor Whisper: ${error.message}`);
		whisperServerProcess = null;
		whisperServerReady = false;
		return false;
	}
}

/**
 * Encerra o servidor Whisper.cpp persistente
 */
function stopWhisperServer() {
	if (!whisperServerProcess) {
		console.log('‚ö†Ô∏è Servidor Whisper n√£o est√° rodando');
		return;
	}

	console.log('üõë Encerrando servidor Whisper...');
	try {
		whisperServerProcess.kill();
		whisperServerProcess = null;
		whisperServerReady = false;
		console.log('‚úÖ Servidor Whisper encerrado');
	} catch (error) {
		console.error(`‚ùå Erro ao encerrar servidor: ${error.message}`);
	}
}

/**
 * Converte WebM para WAV usando ffmpeg (para Whisper.cpp)
 * Trabalha com caminhos de arquivo (n√£o buffers)
 * Origem: commit 9545a76
 */
function convertWebMToWAVFile(inputPath, outputPath) {
	return new Promise((resolve, reject) => {
		// Usa ffmpeg est√°tico se dispon√≠vel
		const ffmpeg = require('fluent-ffmpeg');
		const ffmpegPath = require('ffmpeg-static');
		ffmpeg(inputPath)
			.setFfmpegPath(ffmpegPath)
			.audioCodec('pcm_s16le')
			.audioFrequency(16000) // Whisper usa 16kHz
			.audioChannels(1) // Mono
			.format('wav')
			.on('end', () => {
				console.log('‚úÖ Convers√£o WebM ‚Üí WAV conclu√≠da');
				resolve();
			})
			.on('error', err => {
				console.error('‚ùå Erro na convers√£o WebM ‚Üí WAV:', err);
				reject(err);
			})
			.save(outputPath);
	});
}

/**
 * Converte WebM/Ogg para PCM 16-bit 16kHz (formato que Vosk espera)
 * Usa ffmpeg para decodifica√ß√£o
 */
async function convertWebMToWAV(webmBuffer) {
	try {
		const ffmpegPath = require('ffmpeg-static');
		const inputFile = path.join(app.getPath('temp'), `input-${Date.now()}.webm`);
		const outputFile = path.join(app.getPath('temp'), `output-${Date.now()}.wav`);

		try {
			// Escreve WebM tempor√°rio
			fs.writeFileSync(inputFile, webmBuffer);

			// Converte com ffmpeg: WebM ‚Üí WAV 16-bit 16kHz mono (MESMA FORMA DE ANTES)
			await execFileAsync(
				ffmpegPath,
				[
					'-i',
					inputFile,
					'-acodec',
					'pcm_s16le', // PCM 16-bit signed
					'-ar',
					'16000', // 16kHz sample rate
					'-ac',
					'1', // Mono
					'-f',
					'wav', // WAV container (melhor preserva√ß√£o de qualidade)
					outputFile,
				],
				{ maxBuffer: 10 * 1024 * 1024 },
			);

			// L√™ arquivo WAV convertido
			const wavBuffer = fs.readFileSync(outputFile);

			// Limpa arquivos tempor√°rios
			fs.unlinkSync(inputFile);
			fs.unlinkSync(outputFile);

			console.log(`‚úÖ Convertido WebM (${webmBuffer.length} bytes) ‚Üí WAV (${wavBuffer.length} bytes)`);
			return wavBuffer;
		} catch (error) {
			// Limpa se houver erro
			if (fs.existsSync(inputFile)) fs.unlinkSync(inputFile);
			if (fs.existsSync(outputFile)) fs.unlinkSync(outputFile);
			throw error;
		}
	} catch (error) {
		console.error('‚ùå Erro ao converter WebM para WAV:', error.message);
		throw error;
	}
}

/* ================================
   HANDLERS IPC - GERAIS
=============================== */

// Erros do renderer
ipcMain.on('RENDERER_ERROR', (_, info) => {
	console.error('Renderer reported error:', info && (info.message || info));
	if (info?.stack) console.error(info.stack);
});

// Status do cliente OpenAI
ipcMain.handle('GET_OPENAI_API_STATUS', () => ({
	initialized: !!openaiClient,
}));

/* ================================
   HANDLERS IPC - API KEYS
=============================== */

// Verifica se h√° API key
ipcMain.handle('HAS_API_KEY', async (_, provider) => {
	try {
		const key = secureStore.get(`apiKeys.${provider}`);
		return {
			hasKey: !!key && key.length > 10,
			provider,
		};
	} catch (error) {
		console.error('‚ùå Erro ao verificar API key:', error);
		return { hasKey: false, provider };
	}
});

// Recupera API key
ipcMain.handle('GET_API_KEY', async (_, provider) => {
	try {
		const key = secureStore.get(`apiKeys.${provider}`);
		return key || null;
	} catch (error) {
		console.error(`‚ùå Erro ao recuperar chave de ${provider}:`, error);
		return null;
	}
});

// Salva API key
ipcMain.handle('SAVE_API_KEY', async (_, { provider, apiKey }) => {
	try {
		if (!apiKey || apiKey.trim().length < 2) {
			return { success: false, error: 'API key inv√°lida' };
		}

		const trimmedKey = apiKey.trim();
		secureStore.set(`apiKeys.${provider}`, trimmedKey);

		// Se for OpenAI, inicializa cliente
		if (provider === 'openai') {
			const success = initializeOpenAIClient(trimmedKey);
			if (mainWindow?.webContents) {
				mainWindow.webContents.send('API_KEY_UPDATED', !!success);
			}
			return { success, provider };
		}

		return { success: true, provider };
	} catch (error) {
		console.error('Erro ao salvar API key:', error);
		return { success: false, error: error.message };
	}
});

// Remove API key
ipcMain.handle('DELETE_API_KEY', async (_, provider) => {
	try {
		secureStore.delete(`apiKeys.${provider}`);

		if (provider === 'openai') {
			openaiClient = null;
		}

		return { success: true, provider };
	} catch (error) {
		console.error('‚ùå Erro ao deletar API key:', error);
		return { success: false, error: error.message };
	}
});

// Inicializa cliente OpenAI com chave fornecida
ipcMain.handle('initialize-api-client', async (_, apiKey) => {
	const initialized = initializeOpenAIClient(apiKey);
	if (mainWindow && mainWindow.webContents) mainWindow.webContents.send('API_KEY_UPDATED', !!initialized);
	return { initialized };
});

/* ================================
   HANDLERS IPC - TRANSCRI√á√ÉO ONLINE (OpenAI)
=============================== */

/**
 * Transcri√ß√£o com OpenAI Whisper-1 (online)
 * Chamado por: renderer.js ‚Üí transcribeAudio() quando sttModel === 'whisper-1'
 * Refer√™ncia: handlers IPC 'transcribe-audio' e 'transcribe-audio-partial'
 */
async function transcribeAudioCommon(audioBuffer, isPartial = false) {
	console.log('\n--------------------------------------------------------');
	console.log('üìã STT HANDLER ATIVO: WHISPER-1 OPENAI (Cloud, Vers√°til)');
	console.log('--------------------------------------------------------');
	// Verifica se o cliente est√° inicializado
	if (!openaiClient) {
		console.log('‚ö†Ô∏è Cliente OpenAI n√£o inicializado, tentando recuperar...');
		const initialized = initializeOpenAIClient();
		if (!initialized) {
			throw new Error('OpenAI API key n√£o configurada. Configure em "API e Modelos" ‚Üí OpenAI.');
		}
	}

	// Prote√ß√£o para buffers muito pequenos
	const size = audioBuffer?.byteLength || audioBuffer?.length || 0;
	if (isPartial && size < 800) {
		console.log('STT main (partial): buffer demasiado pequeno, ignorando');
		return '';
	}

	// Salva arquivo tempor√°rio
	const tempFileName = isPartial ? 'temp-audio-partial.webm' : 'temp-audio.webm';
	const tempFilePath = path.join(app.getPath('temp'), tempFileName);

	try {
		fs.writeFileSync(tempFilePath, Buffer.from(audioBuffer));

		const transcription = await openaiClient.audio.transcriptions.create({
			file: fs.createReadStream(tempFilePath),
			model: 'whisper-1',
			language: 'pt',
		});

		return transcription.text;
	} catch (error) {
		console.error(`‚ùå Erro na transcri√ß√£o ${isPartial ? 'parcial' : ''}:`, error.message);

		if (error.status === 401 || error.message.includes('authentication')) {
			openaiClient = null;
			throw new Error('Chave da API inv√°lida ou expirada. Verifique suas configura√ß√µes.');
		}

		if (isPartial && error.status === 400 && error.error?.message?.includes('Invalid file format')) {
			return '';
		}

		throw error;
	} finally {
		if (fs.existsSync(tempFilePath)) {
			fs.unlinkSync(tempFilePath);
		}
	}
}

/**
 * Transcri√ß√£o local com Whisper.cpp
 * Origem: commit 9545a76
 * Processa WebM ‚Üí WAV ‚Üí Whisper.cpp
 */
/**
 * Transcri√ß√£o com Whisper.cpp local (alta precis√£o, offline)
 * Chamado por: renderer.js ‚Üí transcribeAudio() quando sttModel === 'whisper-cpp-local'
 * Refer√™ncia: handlers IPC 'transcribe-local' e 'transcribe-local-partial'
 * Processo: WebM ‚Üí WAV ‚Üí Whisper.cpp ‚Üí Texto
 */
// Helper function para processar arquivo WAV no Whisper
async function processWhisperFile(whisperModelPath, tempWavPath, isPartial = false) {
	const whisperStart = Date.now();

	const args = ['-m', whisperModelPath, '-f', tempWavPath, '-l', 'pt', '-otxt', '-t', '4', '-np', '-nt'];

	if (isPartial) {
		args.push('-d', '3000', '-ml', '50');
	}

	console.log(`üöÄ 4. Executando Whisper: ${WHISPER_CLI_EXE} ${args.join(' ')}`);

	const { stdout } = await execFileAsync(WHISPER_CLI_EXE, args, {
		timeout: isPartial ? 1500 : 10000, // üî• OTIMIZADO: Parcial 1.5s (era 3s), Final 10s
		maxBuffer: 1024 * 1024 * 5,
	});

	const whisperTime = Date.now() - whisperStart;
	console.log(`‚úÖ 5. Whisper executado em ${whisperTime}ms`);

	if (stdout && stdout.trim()) {
		console.log(`üìù STDOUT (primeiros 200 chars):`, stdout.substring(0, 200));
	} else {
		console.log(`üìù STDOUT: vazio ou nulo`);
	}

	return (stdout || '').trim();
}

// Helper para log de erro durante execu√ß√£o do Whisper
function logWhisperError(execError, tempWavPath) {
	console.error(`‚ùå ERRO NA EXECU√á√ÉO DO WHISPER:`);
	console.error(`   C√≥digo: ${execError.code}`);
	console.error(`   Sinal: ${execError.signal}`);
	console.error(`   Mensagem: ${execError.message}`);
	if (execError.stderr) {
		console.error(`   STDERR do processo: ${execError.stderr}`);
	}
	if (execError.stdout) {
		console.error(`   STDOUT do processo: ${execError.stdout}`);
	}

	if (fs.existsSync(tempWavPath)) {
		const stats = fs.statSync(tempWavPath);
		console.error(`   üìù WAV file existe: ${stats.size} bytes`);
	} else {
		console.error(`   ‚ùå WAV file N√ÉO EXISTE!`);
	}
}

// Helper para validar e preparar arquivo WAV
async function prepareWavFile(audioBuffer, tempWebmPath, tempWavPath, isPartial) {
	fs.writeFileSync(tempWebmPath, Buffer.from(audioBuffer));
	console.log(`üìÅ √Åudio WebM salvo: ${tempWebmPath} (${audioBuffer.length} bytes)`);

	const convertStart = Date.now();
	await convertWebMToWAVFile(tempWebmPath, tempWavPath);
	const convertTime = Date.now() - convertStart;
	console.log(`üîÑ 2. Convertido para WAV em ${convertTime}ms: ${tempWavPath}`);

	if (!fs.existsSync(tempWavPath)) {
		throw new Error('Arquivo WAV n√£o foi criado');
	}

	const wavStats = fs.statSync(tempWavPath);
	console.log(`üìä 3. WAV stats: ${wavStats.size} bytes`);

	if (wavStats.size < 1000) {
		console.warn('‚ö†Ô∏è Arquivo WAV muito pequeno, pode estar corrompido');
	}
}

async function transcribeLocalCommon(audioBuffer, isPartial = false) {
	console.log('\n--------------------------------------------------------');
	console.log('üìã STT HANDLER ATIVO: WHISPER.CPP LOCAL (Offline, Alta Precis√£o)');
	console.log('--------------------------------------------------------');
	const startTime = Date.now();
	console.log(`üé§ [WHISPER LOCAL${isPartial ? ' PARTIAL' : ''}] Iniciando...`);
	console.log(`‚è±Ô∏è Recebido buffer: ${audioBuffer.length} bytes`);

	if (!checkWhisperFiles()) {
		if (isPartial) return '';
		throw new Error('Arquivos do Whisper.cpp n√£o encontrados!');
	}

	const tempDir = app.getPath('temp');
	const tempWebmPath = path.join(tempDir, `whisper-${isPartial ? 'partial' : 'temp'}-${Date.now()}.webm`);
	const tempWavPath = tempWebmPath.replace('.webm', '.wav');

	try {
		await prepareWavFile(audioBuffer, tempWebmPath, tempWavPath, isPartial);

		let result = '';
		try {
			result = await processWhisperFile(WHISPER_MODEL, tempWavPath, isPartial);
		} catch (execError) {
			logWhisperError(execError, tempWavPath);
			// üî• [NOVO] Ao inv√©s de relan√ßar silenciosamente, log claro
			const timeoutMs = isPartial ? 3000 : 10000;
			const errorMsg =
				execError.signal === 'SIGTERM'
					? `‚è±Ô∏è Whisper timeout (${timeoutMs}ms) - arquivo grande demais ou modelo carregando`
					: `‚ùå Whisper erro: ${execError.message}`;
			console.error(`üö® TRANSCRIBE-LOCAL FALHOU: ${errorMsg}`);
			throw new Error(errorMsg); // Propaga para renderer saber que falhou
		}

		const elapsedTotal = Date.now() - startTime;
		console.log(`üìä Tempo total: ${elapsedTotal}ms`);
		console.log(
			`‚ú® Resultado (${result.length} chars): "${result.substring(0, 80)}${result.length > 80 ? '...' : ''}"`,
		);

		return result;
	} finally {
		try {
			if (fs.existsSync(tempWebmPath)) {
				fs.unlinkSync(tempWebmPath);
				console.log(`üóëÔ∏è Deletado WebM temp`);
			}
			if (fs.existsSync(tempWavPath)) {
				fs.unlinkSync(tempWavPath);
				console.log(`üóëÔ∏è Deletado WAV temp`);
			}
		} catch (cleanupError) {
			console.warn('‚ö†Ô∏è Erro ao limpar arquivos temp:', cleanupError.message);
		}
	}
}

// ==========================================
// HANDLERS IPC - STT (Speech-to-Text)
// ==========================================
// Refer√™ncias de quem chama:
//   - OpenAI Whisper-1: renderer.js ‚Üí transcribeAudio() com sttModel === 'whisper-1'
//   - Whisper.cpp Local: renderer.js ‚Üí transcribeAudio() com sttModel === 'whisper-cpp-local'
//   - Vosk Local: renderer.js ‚Üí transcribeAudio() com sttModel === 'vosk-local'

// Handler: Transcri√ß√£o OpenAI Whisper-1 (online)
ipcMain.handle('transcribe-audio', (_, audioBuffer) => transcribeAudioCommon(audioBuffer, false));
ipcMain.handle('transcribe-audio-partial', (_, audioBuffer) => transcribeAudioCommon(audioBuffer, true));

// Handlers para Whisper.cpp (local, alta precis√£o)
ipcMain.handle('transcribe-local', (_, audioBuffer) => transcribeLocalCommon(audioBuffer, false));
// üî• [DESABILITADO] transcribe-local-partial foi desabilitado
// Motivo: WebM chunks incompletos causam erro ffmpeg constantemente (c√≥digo 3199971767)
// Transcri√ß√£o completa funciona perfeitamente - confiar apenas nela
ipcMain.handle('transcribe-local-partial', (_, audioBuffer) => {
	return ''; // Retorna vazio silenciosamente - transcri√ß√£o parcial desabilitada
});

// üî• NOVO: Handlers para gerenciar servidor Whisper persistente
ipcMain.handle('start-whisper-server', async () => {
	console.log('üì° Solicita√ß√£o para iniciar servidor Whisper');
	return await startWhisperServer();
});

ipcMain.handle('stop-whisper-server', () => {
	console.log('üì° Solicita√ß√£o para parar servidor Whisper');
	stopWhisperServer();
	return true;
});

/* ================================
   HANDLERS IPC - DEEPGRAM (STT)
=============================== */

// üî• DEEPGRAM: Transcri√ß√£o via SDK com suporte a chunks
ipcMain.handle('transcribe-audio-deepgram', async (_, audioDataBase64) => {
	try {
		const deepgramApiKey = process.env.DEEPGRAM_API_KEY;
		if (!deepgramApiKey) {
			throw new Error('DEEPGRAM_API_KEY n√£o configurada no .env');
		}

		// Converte base64 (string) de volta para Buffer
		const buffer = Buffer.from(audioDataBase64, 'base64');
		console.log('üé§ Enviando chunk para Deepgram | size:', buffer.length);

		// Usa Deepgram SDK com prerecorded (para chunks isolados)
		const { createClient } = require('@deepgram/sdk');
		const deepgram = createClient(deepgramApiKey);

		const { result, error } = await deepgram.listen.prerecorded.transcribeFile(buffer, {
			model: 'nova-2',
			language: 'pt-BR',
			smart_format: true,
			container: 'webm',
		});

		if (error) {
			console.error('‚ùå Erro Deepgram SDK:', error);
			throw new Error(`Deepgram error: ${error.message}`);
		}

		const transcript = result?.results?.channels[0]?.alternatives[0]?.transcript || '';
		console.log('‚úÖ Transcri√ß√£o Deepgram:', transcript || '(vazio)');
		return transcript;
	} catch (err) {
		console.error('‚ùå Erro ao transcrever com Deepgram:', err.message);
		throw err;
	}
});

/* ================================
   HANDLERS IPC - GPT
=============================== */

async function ensureOpenAIClient() {
	if (!openaiClient) {
		console.log('‚ö†Ô∏è Cliente OpenAI n√£o inicializado, tentando recuperar...');
		const initialized = initializeOpenAIClient();
		if (!initialized) {
			throw new Error('OpenAI API key n√£o configurada. Configure em "API e Modelos" ‚Üí OpenAI.');
		}
	}
}

ipcMain.handle('ask-gpt', async (_, messages) => {
	await ensureOpenAIClient();

	try {
		let response;

		if (USE_FAKE_STREAM_GPT) {
			// usa o mock
			response = { choices: [{ message: { content: 'Resposta mockada s√≥ para teste üöÄ' } }] };
		} else {
			// usa o OpenAI real
			response = await openaiClient.chat.completions.create({
				model: 'gpt-4o-mini',
				messages,
				temperature: 0.3,
			});
		}

		return response.choices[0].message.content;
	} catch (error) {
		console.error('‚ùå Erro no GPT:', error.message);
		if (error.status === 401 || error.message.includes('authentication')) {
			openaiClient = null;
			throw new Error('Chave da API inv√°lida para GPT. Verifique as configura√ß√µes.');
		}
		throw error;
	}
});

ipcMain.handle('ask-gpt-stream', async (event, messages) => {
	const win = BrowserWindow.fromWebContents(event.sender);

	try {
		await ensureOpenAIClient();
	} catch (error) {
		win.webContents.send('GPT_STREAM_ERROR', error.message);
		return;
	}

	try {
		let stream;

		if (USE_FAKE_STREAM_GPT) {
			// usa o mock
			stream = fakeStreamGPT();
		} else {
			// usa o OpenAI real
			stream = await openaiClient.chat.completions.create({
				model: 'gpt-4o-mini',
				messages,
				temperature: 0.3,
				stream: true,
			});
		}

		for await (const chunk of stream) {
			const token = chunk.choices?.[0]?.delta?.content;
			if (token) {
				win.webContents.send('GPT_STREAM_CHUNK', token);
			}
		}

		win.webContents.send('GPT_STREAM_END');
	} catch (error) {
		console.error('‚ùå Erro no stream GPT:', error.message);
		if (error.status === 401 || error.message.includes('authentication')) {
			openaiClient = null;
			win.webContents.send('GPT_STREAM_ERROR', 'Chave da API inv√°lida. Configure na se√ß√£o "API e Modelos".');
		} else {
			win.webContents.send('GPT_STREAM_ERROR', error.message);
		}
	}
});

// ‚úÖ Mock simples para simular stream
async function* fakeStreamGPT() {
	const response = 'Ol√° Thiago! Isso √© um mock de resposta simulando o GPT üöÄ';

	// Quebra em peda√ßos vari√°veis (como se fossem tokens/chunks)
	const chunks = response.match(/.{1,8}/g); // peda√ßos de at√© 8 caracteres

	for (const chunk of chunks) {
		// Delay aleat√≥rio entre 50ms e 200ms
		const delay = 50 + Math.random() * 150;
		await new Promise(r => setTimeout(r, delay));

		yield { choices: [{ delta: { content: chunk } }] };
	}
}

/* ================================
   HANDLERS IPC - CONTROLE DA JANELA
=============================== */

// Click-through
ipcMain.on('SET_CLICK_THROUGH', (_, enabled) => {
	clickThroughEnabled = enabled;
	mainWindow.setIgnoreMouseEvents(enabled, { forward: true });
	console.log('üñ±Ô∏è Click-through:', enabled ? 'ATIVADO' : 'DESATIVADO');
});

ipcMain.handle('GET_CLICK_THROUGH', () => clickThroughEnabled);

// Zonas interativas
ipcMain.on('SET_INTERACTIVE_ZONE', (_, isInteractive) => {
	if (clickThroughEnabled) {
		mainWindow.setIgnoreMouseEvents(!isInteractive, { forward: true });
	}
});

// Drag and drop da janela
ipcMain.on('START_WINDOW_DRAG', () => {
	if (!mainWindow) return;
	mainWindow.moveTop();
	mainWindow.startDrag?.();
});

ipcMain.handle('GET_WINDOW_BOUNDS', () => {
	return mainWindow ? mainWindow.getBounds() : null;
});

ipcMain.handle('GET_CURSOR_SCREEN_POINT', () => {
	try {
		const { screen } = require('electron');
		return screen.getCursorScreenPoint();
	} catch (err) {
		console.error('Erro ao obter posi√ß√£o do cursor:', err);
		return { x: 0, y: 0 };
	}
});

ipcMain.on('MOVE_WINDOW_TO', (_, { x, y }) => {
	if (!mainWindow) return;
	try {
		const b = mainWindow.getBounds();
		mainWindow.setBounds({
			x: Math.round(x),
			y: Math.round(y),
			width: b.width,
			height: b.height,
		});
	} catch (err) {
		console.warn('MOVE_WINDOW_TO falhou:', err);
	}
});

/* ================================
   HANDLERS IPC - VOSK (VIA PYTHON SUBPROCESS)
=============================== */

let voskProcess = null;
let voskReady = false;

/**
 * Inicia servidor Vosk em Python (subprocess)
 * Comunica via stdin/stdout JSON
 */
function startVoskServer() {
	return new Promise((resolve, reject) => {
		try {
			console.log(`üöÄ Iniciando servidor Vosk (Python) com modelo: ${VOSK_CONFIG.MODEL}...`);

			voskProcess = spawn('python', ['vosk-server.py', VOSK_CONFIG.MODEL], {
				cwd: __dirname,
				stdio: ['pipe', 'pipe', 'pipe'],
			});

			// Aumenta limite de listeners para m√∫ltiplas requisi√ß√µes
			voskProcess.stdout.setMaxListeners(50);

			let readyCheck = false;

			voskProcess.stdout.on('data', data => {
				const line = data.toString().trim();
				console.log(`[Vosk] ${line}`);

				// Aguarda sinal VOSK_READY
				if (line === 'VOSK_READY' && !readyCheck) {
					readyCheck = true;
					voskReady = true;
					console.log('‚úÖ Servidor Vosk pronto!');
					resolve(true);
				}
			});

			voskProcess.stderr.on('data', data => {
				console.log(`[Vosk stderr] ${data.toString().trim()}`);
			});

			voskProcess.on('error', error => {
				console.error('‚ùå Erro ao iniciar Vosk:', error.message);
				voskReady = false;
				reject(error);
			});

			voskProcess.on('close', code => {
				console.log(`‚èπÔ∏è Vosk processo encerrado (c√≥digo ${code})`);
				voskReady = false;
				voskProcess = null;
			});

			// Timeout de 5s para inicializar
			setTimeout(() => {
				if (!readyCheck) {
					console.error('‚è±Ô∏è Timeout ao inicializar Vosk');
					reject(new Error('Vosk n√£o respondeu (timeout)'));
				}
			}, 5000);
		} catch (error) {
			console.error('‚ùå Erro ao criar processo Vosk:', error);
			reject(error);
		}
	});
}

/**
 * Handler IPC para transcri√ß√£o Vosk em streaming
 * Envia comando JSON para servidor Python
 */
ipcMain.handle('vosk-transcribe', async (_, audioBuffer) => {
	console.log('\n--------------------------------------------------------');
	console.log('üìã STT HANDLER ATIVO: VOSK LOCAL (Python Server)');
	console.log('--------------------------------------------------------');
	try {
		// Inicia servidor se n√£o estiver rodando
		if (!voskReady || !voskProcess) {
			console.log('üîÑ Inicializando Vosk...');
			await startVoskServer();
		}

		// Converte para Buffer se necess√°rio (IPC pode enviar Uint8Array ou objeto)
		let buffer = audioBuffer;
		if (!Buffer.isBuffer(buffer)) {
			if (buffer?.data && Array.isArray(buffer.data)) {
				// Se for objeto com array 'data' (serializado)
				buffer = Buffer.from(buffer.data);
			} else if (ArrayBuffer.isView(buffer)) {
				// Se for Uint8Array ou similar
				buffer = Buffer.from(buffer);
			} else if (typeof buffer === 'object' && buffer !== null) {
				// Se for object gen√©rico com propriedades num√©ricas
				const arr = Object.values(buffer);
				buffer = Buffer.from(arr);
			} else {
				throw new Error('audioBuffer formato inv√°lido');
			}
		}

		console.log(`üé§ Recebido WebM: ${buffer.length} bytes`);

		// Converte WebM para WAV 16-bit 16kHz (MESMO FORMATO QUE ERA ANTES)
		let wavBuffer;
		try {
			wavBuffer = await convertWebMToWAV(buffer);
		} catch (error) {
			console.error('‚ùå Erro na convers√£o WebM‚ÜíWAV:', error.message);
			throw new Error(`Falha ao converter √°udio: ${error.message}`);
		}

		// Codifica WAV em base64 (JSON-safe)
		const audioBase64 = wavBuffer.toString('base64');

		// Cria comando JSON
		const command = {
			type: 'transcribe',
			audio: audioBase64,
		};

		// Envia comando para servidor Python
		const commandJson = JSON.stringify(command) + '\n';

		// Aguarda resposta
		return new Promise((resolve, reject) => {
			const timeout = setTimeout(() => {
				voskProcess.stdout.removeListener('data', responseHandler);
				reject(new Error('Timeout ao aguardar resposta do Vosk'));
			}, 5000);

			// Listener para resposta - filtra apenas JSON v√°lido
			const responseHandler = data => {
				const lines = data.toString().split('\n');

				for (const line of lines) {
					const trimmed = line.trim();

					// Ignora linhas vazias ou que n√£o parecem ser JSON
					if (!trimmed || trimmed.startsWith('[VOSK]') || trimmed === 'VOSK_READY') {
						continue;
					}

					// Tenta parsear como JSON
					try {
						const response = JSON.parse(trimmed);
						clearTimeout(timeout);
						voskProcess.stdout.removeListener('data', responseHandler);
						console.log('üìù Resposta Vosk:', response);
						resolve(response);
						return;
					} catch (e) {
						// Ignorar: N√£o √© JSON v√°lido, aguardar pr√≥xima linha
						// O loop continuar√° por 'data' e 'end' listeners
						console.warn(`‚ö†Ô∏è Linha Vosk n√£o √© JSON v√°lido, aguardando pr√≥xima linha... ${e}`);
					}
				}
			};

			// Aguarda pr√≥xima linha de resposta
			voskProcess.stdout.on('data', responseHandler);

			// Envia comando
			voskProcess.stdin.write(commandJson);
		});
	} catch (error) {
		console.error('‚ùå Erro em vosk-transcribe:', error.message);
		return {
			final: '',
			partial: '',
			isFinal: false,
			error: error.message,
		};
	}
});

/**
 * Handler para finalizar Vosk e obter resultado final
 */
ipcMain.handle('vosk-finalize', async () => {
	try {
		if (!voskReady || !voskProcess) {
			return { final: '' };
		}

		console.log('üîÑ Finalizando Vosk e obtendo resultado final...');

		const command = { type: 'finalize' };
		const commandJson = JSON.stringify(command) + '\n';

		return new Promise(resolve => {
			const timeout = setTimeout(() => {
				resolve({ final: '' });
			}, 2000);

			const responseHandler = data => {
				clearTimeout(timeout);
				voskProcess.stdout.removeListener('data', responseHandler);

				try {
					const response = JSON.parse(data.toString().trim());
					console.log('‚úÖ Vosk finalized:', response);
					resolve(response);
				} catch (error) {
					console.error('Erro ao fazer parse da resposta final do Vosk:', error);
					resolve({ final: '' });
				}
			};

			voskProcess.stdout.once('data', responseHandler);
			voskProcess.stdin.write(commandJson);
		});
	} catch (error) {
		console.error('‚ùå Erro em vosk-finalize:', error.message);
		return { final: '' };
	}
});

/* ===============================
   SCREENSHOT CAPTURE - DISCRETO E INDETECT√ÅVEL
=============================== */

const { desktopCapturer } = require('electron');

let lastCaptureTime = 0;
const CAPTURE_COOLDOWN = 2000; // 2 segundos
const SCREENSHOT_RETENTION = 5 * 60 * 1000; // 5 minutos

/**
 * Captura screenshot da tela sem indicadores vis√≠veis
 * Exclui a pr√≥pria janela do App da captura
 */
ipcMain.handle('CAPTURE_SCREENSHOT', async () => {
	const now = Date.now();

	// üõ°Ô∏è Cooldown check
	if (now - lastCaptureTime < CAPTURE_COOLDOWN) {
		const waitTime = Math.ceil((CAPTURE_COOLDOWN - (now - lastCaptureTime)) / 1000);
		return {
			success: false,
			error: `Aguarde ${waitTime}s antes de capturar novamente`,
		};
	}

	// üõ°Ô∏è Salva opacidade original COM FALLBACK seguro
	let originalOpacity = mainWindow?.getOpacity() ?? 1; // Fallback: 1 (totalmente opaco)

	try {
		console.log('üì∏ Iniciando captura de tela discreta...');

		// 1Ô∏è‚É£ Torna janela COMPLETAMENTE invis√≠vel
		if (mainWindow) {
			// ‚úÖ HARDENING INVISIBILIDADE: Usa M√öLTIPLOS m√©todos simult√¢neos
			// Garante que nenhuma ferramenta de captura (Zoom, Teams, OBS, etc) detecte a janela
			mainWindow.setOpacity(0); // Invis√≠vel opticamente
			mainWindow.setIgnoreMouseEvents(true, { forward: true }); // N√£o interfere com mouse
			console.log('üëª Janela invis√≠vel (opacity=0 + ignoreMouseEvents)');
		}

		// Aguarda m√∫ltiplos frames do compositor (50ms = ~3 frames a 60fps)
		// Garante que a invisibilidade foi propagada ao sistema de composi√ß√£o
		await new Promise(resolve => setTimeout(resolve, 50));

		// 2Ô∏è‚É£ Captura a tela usando desktopCapturer
		const sources = await desktopCapturer.getSources({
			types: ['screen'],
			thumbnailSize: { width: 1920, height: 1080 },
		});

		if (!sources || sources.length === 0) {
			console.error('‚ùå Nenhuma tela encontrada');
			return { success: false, error: 'Nenhuma tela encontrada' };
		}

		// Pega a primeira tela (tela principal)
		const screenshot = sources[0].thumbnail.toPNG();

		// 3Ô∏è‚É£ Salva no diret√≥rio temp
		const tempDir = app.getPath('temp');
		const timestamp = Date.now();
		const filename = `my-screenshot-${timestamp}.png`;
		const filepath = path.join(tempDir, filename);

		fs.writeFileSync(filepath, screenshot);
		console.log(`‚úÖ Screenshot salvo: ${filepath} (${Math.round(screenshot.length / 1024)}KB)`);

		// Atualiza timestamp
		lastCaptureTime = now;

		return {
			success: true,
			filepath,
			filename,
			size: screenshot.length,
			timestamp,
		};
	} catch (error) {
		console.error('‚ùå Erro ao capturar screenshot:', error);
		return {
			success: false,
			error: error.message,
		};
	} finally {
		// üõ°Ô∏è CR√çTICO: Garante restaura√ß√£o SEMPRE (sucesso ou erro)
		// originalOpacity tem fallback (1), ent√£o sempre ter√° um valor v√°lido
		if (mainWindow) {
			mainWindow.setOpacity(originalOpacity);
			mainWindow.setIgnoreMouseEvents(false); // IMPORTANTE: Restaura eventos de mouse
			console.log(`üëÄ Janela restaurada (opacity=${originalOpacity})`);
		}
	}
});

/**
 * Analisa screenshots com OpenAI Vision API (gpt-4o)
 */
ipcMain.handle('ANALYZE_SCREENSHOTS', async (_, screenshotPaths) => {
	try {
		await ensureOpenAIClient();

		if (!screenshotPaths || screenshotPaths.length === 0) {
			return {
				success: false,
				error: 'Nenhum screenshot para analisar',
			};
		}

		console.log(`üîç Analisando ${screenshotPaths.length} screenshot(s)...`);

		// üì∏ Converte screenshots para base64
		const images = screenshotPaths
			.map(filepath => {
				if (!fs.existsSync(filepath)) {
					console.warn(`‚ö†Ô∏è Screenshot n√£o encontrado: ${filepath}`);
					return null;
				}

				const buffer = fs.readFileSync(filepath);
				const base64 = buffer.toString('base64');
				console.log(`  ‚úì Carregado: ${path.basename(filepath)} (${Math.round(buffer.length / 1024)}KB)`);

				return {
					type: 'image_url',
					image_url: {
						url: `data:image/png;base64,${base64}`,
					},
				};
			})
			.filter(Boolean); // Remove nulls

		if (images.length === 0) {
			return {
				success: false,
				error: 'Nenhum screenshot v√°lido encontrado',
			};
		}

		// ü§ñ Monta mensagens para a API
		const messages = [
			{
				role: 'user',
				content: [
					{
						type: 'text',
						text: 'Analise a captura de tela. Se houver c√≥digo, forne√ßa APENAS o c√≥digo com coment√°rios em portugu√™s explicando cada linha. N√ÉO inclua explica√ß√µes textuais adicionais, resumos ou introdu√ß√µes. Use Java como padr√£o se a linguagem n√£o for identific√°vel. Formato: apenas c√≥digo + coment√°rios. Mantenha espa√ßo de uma linha se a proxima linha for um novo bloco de coment√°rio + c√≥digo para facilitar o entendimento. ',
					},
					...images,
				],
			},
		];

		let response;

		if (USE_FAKE_STREAM_GPT) {
			// usa o mock
			response = { choices: [{ message: { content: 'Resposta mockada s√≥ para teste üöÄ' } }] };
		} else {
			// usa o OpenAI real
			response = await openaiClient.chat.completions.create({
				model: 'gpt-4o-mini', // Modelo com suporte a vis√£o (gpt-4o)
				messages,
				max_tokens: 2000,
				temperature: 0.3,
			});
		}

		const analysis = response.choices[0].message.content;

		// üîÑ Limpeza de imagens antigas maior que 5 minutos
		cleanupScreenshots();

		return {
			success: true,
			analysis,
		};
	} catch (error) {
		console.error('‚ùå Erro ao analisar screenshots:', error);

		if (error.status === 401) {
			return {
				success: false,
				error: 'API key inv√°lida ou expirada',
			};
		}

		return {
			success: false,
			error: error.message,
		};
	}
});

/**
 * Limpa screenshots antigos do diret√≥rio temp
 */
async function cleanupScreenshots() {
	try {
		const tempDir = app.getPath('temp');

		if (!fs.existsSync(tempDir)) {
			return { success: true, cleaned: 0 };
		}

		const files = fs.readdirSync(tempDir);
		const now = Date.now();
		let cleaned = 0;

		files.forEach(file => {
			if (file.startsWith('my-screenshot-')) {
				const filepath = path.join(tempDir, file);

				try {
					const stats = fs.statSync(filepath);
					const age = now - stats.mtimeMs;

					// Remove se for mais antigo que 5 minutos
					if (age > SCREENSHOT_RETENTION) {
						fs.unlinkSync(filepath);
						cleaned++;
						console.log(`üóëÔ∏è Screenshot removido: ${file}`);
					}
				} catch (err) {
					console.warn(`‚ö†Ô∏è Erro ao processar ${file}:`, err.message);
				}
			}
		});

		if (cleaned > 0) {
			console.log(`‚úÖ Limpeza conclu√≠da: ${cleaned} arquivo(s) removido(s)`);
		}

		return { success: true, cleaned };
	} catch (error) {
		console.error('‚ùå Erro na limpeza:', error);
		return { success: false, error: error.message };
	}
}

// Handler IPC para limpeza manual de screenshots
ipcMain.handle('CLEANUP_SCREENSHOTS', cleanupScreenshots);

/* ================================
// FECHAMENTO DA APLICA√á√ÉO
=============================== */
ipcMain.on('APP_CLOSE', () => {
	console.log('‚ùå APP_CLOSE recebido ‚Äî encerrando aplica√ß√£o');
	app.quit();
});

/* ================================
   CRIA√á√ÉO DA JANELA
=============================== */
function createWindow() {
	console.log('ü™ü Criando janela principal (frameless)');

	mainWindow = new BrowserWindow({
		width: 1220, // Largura padr√£o (820 ou 1220)
		height: 620, // Altura padr√£o (620)
		x: 0, // Posi√ß√£o X inicial (horizontal)
		y: 0, // Posi√ß√£o Y inicial (vertical)

		transparent: true, // Permite fundo transparente
		backgroundColor: '#00000000', // Fundo totalmente transparente
		frame: false, // Sem bordas (frameless)
		hasShadow: false, // Sem sombras

		skipTaskbar: true, // N√£o aparece na barra de tarefas
		// focusable: false, // N√£o recebe foco (reduz detectabilidade)
		alwaysOnTop: true, // Janela sempre acima das outras
		alwaysOnTopLevel: 'screen-saver', // N√≠vel mais alto

		thickFrame: false, // Otimiza√ß√µes de performance
		paintWhenInitiallyHidden: false, // N√ÉO renderizar antes de estar vis√≠vel

		resizable: true, // Redimension√°vel
		minimizable: false, // N√£o minimiz√°vel
		maximizable: false, // N√£o maximiz√°vel
		//fullscreen: true, // Permite fullscreen
		closable: true, // Fech√°vel

		webPreferences: {
			nodeIntegration: true, // Permite Node.js no renderer
			contextIsolation: false, // Desativa isolamento de contexto
			backgroundThrottling: false, // mant√©m execu√ß√£o mesmo em segundo plano
			enableBlinkFeatures: 'MediaSessionAPI', // Minimiza exposi√ß√£o de MediaSource
		},
	});

	// üî• FLAG ESPECIAL DO WINDOWS
	mainWindow.setMenu(null); // Remove menu padr√£o
	mainWindow.setContentProtection(true); // protege contra captura externa

	// Para macOS/Linux:
	mainWindow.setVisibleOnAllWorkspaces(true, {
		visibleOnFullScreen: true,
		skipTransformProcessType: true,
	});

	// Carrega a p√°gina principal
	mainWindow.loadFile('index.html');

	console.log('ü™ü Janela criada em modo overlay');

	// Eventos da janela
	mainWindow.on('closed', () => {
		console.log('‚ùå Janela principal fechada');
	});
}

/* ================================
   INICIALIZA√á√ÉO DO APP
=============================== */
app.whenReady().then(() => {
	// Cria a janela principal
	createWindow();

	// Atalhos globais

	// ÔøΩÔ∏è DevTools em desenvolvimento (focusable: false bloqueia before-input-event)
	if (!app.isPackaged) {
		globalShortcut.register('Control+Shift+I', () => {
			mainWindow.webContents.toggleDevTools();
			console.log('üõ†Ô∏è DevTools acionado via Ctrl+Shift+I');
		});
	}

	// Come√ßar a ouvir / Parar de ouvir (Ctrl+D)
	globalShortcut.register('Control+D', () => {
		mainWindow.webContents.send('CMD_TOGGLE_AUDIO');
	});

	// Enviar pergunta ao GPT (Ctrl+Enter)
	globalShortcut.register('Control+Enter', () => {
		mainWindow.webContents.send('CMD_ASK_GPT');
	});

	// Navegacao de perguntas (Ctrl+Shift+ArrowUp)
	globalShortcut.register('Control+Shift+Up', () => {
		mainWindow.webContents.send('CMD_NAVIGATE_QUESTIONS', 'up');
	});

	// Navegacao de perguntas (Ctrl+Shift+ArrowDown)
	globalShortcut.register('Control+Shift+Down', () => {
		mainWindow.webContents.send('CMD_NAVIGATE_QUESTIONS', 'down');
	});

	// üì∏ Atalhos para screenshots
	globalShortcut.register('Control+Shift+F', () => {
		mainWindow.webContents.send('CMD_CAPTURE_SCREENSHOT');
	});

	// üîç Atalho para analisar screenshots
	globalShortcut.register('Control+Shift+G', () => {
		mainWindow.webContents.send('CMD_ANALYZE_SCREENSHOTS');
	});

	console.log('‚úÖ Atalhos de screenshot registrados');
});

/* ================================
   FINALIZA√á√ÉO DO APP
=============================== */
app.on('will-quit', () => {
	globalShortcut.unregisterAll();
	// üî• NOVO: Encerra servidor Whisper ao fechar app
	stopWhisperServer();
});
