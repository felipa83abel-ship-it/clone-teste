# An√°lise Detalhada do Modo Entrevista - Fluxo de Streaming

**Data**: 29/12/2025  
**Status**: Diagn√≥stico Completo + Plano de A√ß√£o

---

## üìä Estado Atual vs Ideal

### Compara√ß√£o: Arquitetura Proposta vs Implementa√ß√£o Real

```
IDEAL (Seu Requisito):
[√Åudio 100ms] ‚Üí [STT Streaming] ‚Üí [Texto parcial] ‚Üí [GPT Streaming] ‚Üí [Resposta]
   (cont√≠nuo)     (real-time)      (imediato)       (cont√≠nuo)        (tipo-chat)

ATUAL:
[√Åudio 60ms em chunks] ‚Üí [Agrupamento 120ms] ‚Üí [STT Parcial N√ÉO-STREAMING]
                              ‚Üì                        ‚Üì
                        [Blob 3-27KB]        [Whisper retorna vazio]
                                                      ‚Üì
                                        [Espera ~20s por blob >= 78KB]
                                                      ‚Üì
                                          [Finalmente texto aparece]
                                                      ‚Üì
                                          [GPT chamado AP√ìS fim]
```

---

## üîç Raiz do Problema

### Limita√ß√£o: OpenAI Whisper API

- **N√ÉO suporta streaming nativo**
- Requer blob de √°udio completo
- M√≠nimo efetivo: ~15-20KB (n√£o 800 bytes)
- Lat√™ncia: 0.5-2s por requisi√ß√£o
- Blobs < 15KB: frequentemente retornam vazio

### Logs Comprovam:

```
Tentativa 1: 27.4 KB ‚Üí ‚ö†Ô∏è Transcri√ß√£o vazia
Tentativa 2: 8.8 KB  ‚Üí ‚ö†Ô∏è Transcri√ß√£o vazia
Tentativa 3: 9.7 KB  ‚Üí ‚ö†Ô∏è Transcri√ß√£o vazia
Tentativa 4: 78.9 KB ‚Üí ‚úÖ "Paro, vamos l√°..."
Tentativa 5: 185.2 KB ‚Üí ‚úÖ Texto completo
```

---

## üéØ Solu√ß√µes Propostas (Incrementais)

### **N√çVEL 1: R√°pido (1-2 horas)**

**Objetivo**: Reduzir vazios e aparecer texto parcial mais cedo

#### 1.1 Aumentar Threshold de STT

```javascript
// renderer.js - linha ~32
const MIN_OUTPUT_AUDIO_SIZE_INTERVIEW = 15000; // Era 800 bytes!
```

**Por qu√™?**: Evita 90% das chamadas vazias de Whisper  
**Trade-off**: Lat√™ncia de parcial sobe de 1s para 3-5s  
**Esperado**: "Paro, vamos l√°" aparece em ~5s (vs 20s agora)

#### 1.2 Aumentar Janela de Agrupamento

```javascript
// renderer.js - linha ~1254
outputPartialTimer = setTimeout(async () => {
	// ... existente
}, 800); // Era 120ms
```

**Por qu√™?**: Acumula mais √°udio antes de enviar para STT  
**Resultado**: Menos requisi√ß√µes, mais acuradas

#### 1.3 Aumentar Rate-Limit

```javascript
// renderer.js - linha ~30
const PARTIAL_MIN_INTERVAL_MS = 3000; // Era 700ms
```

**Por qu√™?**: Evita sobrecarregar Whisper com requisi√ß√µes simult√¢neas  
**Resultado**: Mais est√°vel, menos timeouts

---

### **N√çVEL 2: M√©dio (2-4 horas)**

**Objetivo**: Resposta GPT come√ßa enquanto usu√°rio ainda fala

#### 2.1 Integrar GPT Streaming em Parciais

```javascript
// Em transcribeOutputPartial(), ap√≥s "outputPartialText" atualizar:
if (
	outputPartialText.length >= 50 &&
	isQuestionReady(outputPartialText) &&
	!gptPartialStarted // Nova flag
) {
	gptPartialStarted = true;
	console.log('ü§ñ Iniciando GPT Streaming com parcial...');
	askGptStreaming(outputPartialText);
	// ask-gpt-stream j√° existe!
}
```

#### 2.2 Novo Estado Global

```javascript
// Adicionar ap√≥s linha ~123:
let gptPartialStarted = false;
let partialGptUpdateCount = 0;

// Resetar em resetInterviewTurnState():
gptPartialStarted = false;
partialGptUpdateCount = 0;
```

---

### **N√çVEL 3: Avan√ßado (4-8 horas)**

**Objetivo**: Detec√ß√£o inteligente de "fim da frase"

#### 3.1 Implementar VAD (Voice Activity Detection) Simples

```javascript
// Pseudoc√≥digo em transcribeOutputPartial:
let outputPartialLastUpdate = null;

if (partialText && partialText.trim().length > 0) {
	outputPartialLastUpdate = Date.now();

	// Detecta sil√™ncio = fim da frase
	const silenceDetected = () => {
		if (!outputPartialLastUpdate) return false;
		return Date.now() - outputPartialLastUpdate > 1500; // 1.5s sem updates
	};

	if (silenceDetected() && outputPartialText.length > 20) {
		closeCurrentQuestion(); // Encerra mais cedo
	}
}
```

#### 3.2 Sliding Window para Contexto

```javascript
// Buffer com sobreposi√ß√£o:
let audioChunkBuffer = [];
const WINDOW_MS = 800;
const OVERLAP_MS = 200;

// A cada timer:
const now = Date.now();
audioChunkBuffer = audioChunkBuffer.filter(chunk => now - chunk.addedAt < WINDOW_MS);

// Manter √∫ltimos 200ms para overlap
if (totalSize(audioChunkBuffer) >= 15000) {
	const toSend = [...audioChunkBuffer];
	audioChunkBuffer = audioChunkBuffer.slice(-Math.ceil(toSend.length * 0.2));
	send(toSend);
}
```

---

## üìà Resultados Esperados por N√≠vel

| N√≠vel       | Mudan√ßa        | Lat√™ncia Parcial | Vazios STT | Resposta GPT  |
| ----------- | -------------- | ---------------- | ---------- | ------------- |
| **Atual**   | -              | 20-30s           | 70%        | Ap√≥s fim      |
| **N√≠vel 1** | Thresholds ‚Üë   | 5-8s             | 10%        | Ap√≥s fim      |
| **N√≠vel 2** | +GPT Streaming | 5-8s             | 10%        | Enquanto fala |
| **N√≠vel 3** | +VAD+Overlap   | 3-5s             | <5%        | Enquanto fala |

---

## ‚ö†Ô∏è Limita√ß√µes Inescap√°veis

1. **Whisper n√£o streameia**: Cada requisi√ß√£o = 500-2000ms
2. **OpenAI rate-limits**: ~60 req/min com throttling
3. **Rede**: Lat√™ncia WiFi/internet afeta timestamps

**Alternativa Real Streaming** (futuro):

- `Deepgram.ai`: Whisper streaming real (https://deepgram.com)
- `Google Speech-to-Text`: Streaming nativo
- Custo: ~$0.50-2.00 por hora vs $0.02 OpenAI

---

## ‚úÖ Checklist Execut√°vel

- [ ] Nivel 1.1: Aumentar `MIN_OUTPUT_AUDIO_SIZE_INTERVIEW` para 15000
- [ ] Nivel 1.2: Aumentar `outputPartialTimer` para 800ms
- [ ] Nivel 1.3: Aumentar `PARTIAL_MIN_INTERVAL_MS` para 3000
- [ ] **Testar**: Parcial "Paro, vamos l√°" deve aparecer em ~5-8s
- [ ] Nivel 2.1: Integrar `askGptStreaming` em parciais
- [ ] Nivel 2.2: Adicionar `gptPartialStarted` flag
- [ ] **Testar**: Resposta deve come√ßar enquanto fala
- [ ] Nivel 3.1: Implementar VAD simples (1500ms timeout)
- [ ] Nivel 3.2: Sliding window com overlap 200ms
- [ ] **Testar e Ajustar**: Variar thresholds conforme rede/microfone

---

## üìù Pr√≥ximos Passos

**Imediato (agora)**:

1. Aplicar N√çVEL 1 (3 mudan√ßas simples)
2. Testar com mesmo √°udio
3. Colar novo log

**Se ainda houver vazios ap√≥s N√≠vel 1**:

1. Aumentar mais `MIN_OUTPUT_AUDIO_SIZE_INTERVIEW` para 20000
2. Aumentar `PARTIAL_MIN_INTERVAL_MS` para 5000

**Se lat√™ncia ainda alta**:

1. Implementar N√≠vel 2 (GPT Streaming)
2. Depois N√≠vel 3 (VAD)
