/* ================================ */
//	IMPORTES E DEPENDÃŠNCIAS
/* ================================ */

const { ipcRenderer } = require('electron');
const { marked } = require('marked');
const hljs = require('highlight.js');
const { startAudioDeepgram, stopAudioDeepgram, switchDeviceDeepgram } = require('./stt/stt-deepgram.js'); // reorganizado em pasta stt/
const { startAudioVosk, stopAudioVosk, switchDeviceVosk } = require('./stt/stt-vosk.js'); // reorganizado em pasta stt/
const { startAudioWhisper, stopAudioWhisper, switchDeviceWhisper } = require('./stt/stt-whisper.js'); // reorganizado em pasta stt/
const {
	startAudioVolumeMonitor,
	stopAudioVolumeMonitor,
	switchAudioVolumeDevice,
} = require('./audio/volume-audio-monitor.js');

/* ================================ */
//	ðŸŽ¯ NOVAS CLASSES (RefatoraÃ§Ã£o Fase 2)
/* ================================ */
const AppState = require('./state/AppState.js');
const EventBus = require('./events/EventBus.js');
const Logger = require('./utils/Logger.js');
const mockRunner = require('./mock-runner.js'); // ðŸŽ­ Mock para teste em MODE_DEBUG
const STTStrategy = require('./strategies/STTStrategy.js');
const LLMManager = require('./llm/LLMManager.js');
const openaiHandler = require('./llm/handlers/openai-handler.js');
const geminiHandler = require('./llm/handlers/gemini-handler.js');
const { validateLLMRequest, handleLLMStream, handleLLMBatch } = require('./handlers/llmHandlers.js');

// ðŸŽ¯ INSTANCIAR
const appState = new AppState();
const eventBus = new EventBus();
const sttStrategy = new STTStrategy();
const llmManager = new LLMManager();

// ðŸŽ¯ REGISTRAR LLMs
llmManager.register('openai', openaiHandler);
llmManager.register('gemini', geminiHandler);
// NOSONAR // Futuro: llmManager.register('anthropic', require('./llm/handlers/anthropic-handler.js'));

// ðŸŽ¯ REGISTRAR LISTENERS DA EVENTBUS (para LLM)
eventBus.on('answerStreamChunk', data => {
	emitUIChange('onAnswerStreamChunk', {
		questionId: data.questionId,
		turnId: data.turnId, // ðŸ”¥ Passar turnId para UI
		token: data.token,
		accum: data.accum,
	});
});

eventBus.on('llmStreamEnd', data => {
	Logger.info('LLM Stream finalizado', { questionId: data.questionId });

	// ðŸ”¥ MARCAR COMO RESPONDIDA - essencial para bloquear re-perguntas
	answeredQuestions.add(data.questionId);

	// ðŸ”¥ [MODO ENTREVISTA] Pergunta jÃ¡ foi promovida em finalizeCurrentQuestion
	// Aqui sÃ³ limpamos o CURRENT para prÃ³xima pergunta
	if (ModeController.isInterviewMode()) {
		appState.interview.gptAnsweredTurnId = appState.interview.interviewTurnId;
		resetCurrentQuestion();
		renderCurrentQuestion();
	}

	emitUIChange('onAnswerStreamEnd', {});
});

eventBus.on('llmBatchEnd', data => {
	Logger.info('LLM Batch finalizado', { questionId: data.questionId, responseLength: data.response?.length || 0 });

	// ðŸ”¥ MARCAR COMO RESPONDIDA - essencial para bloquear re-perguntas
	answeredQuestions.add(data.questionId);

	emitUIChange('onAnswerBatchEnd', {
		questionId: data.questionId,
		response: data.response,
	});
});

eventBus.on('error', error => {
	Logger.error('Erro na eventBus', { error });
	updateStatusMessage(`âŒ ${error}`);
});

/* ================================ */
//	PROTEÃ‡ÃƒO CONTRA CAPTURA DE TELA
/* ================================ */

/**
 * ProteÃ§Ã£o contra captura de tela externa
 * Desabilita/limita APIs usadas por Zoom, Teams, Meet, OBS, Discord, Snipping Tool, etc.
 */
(function protectAgainstScreenCapture() {
	// âœ… Desabilita getDisplayMedia (usado por Zoom, Meet, Teams para capturar)
	if (navigator && navigator.mediaDevices && navigator.mediaDevices.getDisplayMedia) {
		const originalGetDisplayMedia = navigator.mediaDevices.getDisplayMedia.bind(navigator.mediaDevices);
		navigator.mediaDevices.getDisplayMedia = async function (...args) {
			console.warn('ðŸ” BLOQUEADO: Tentativa de usar getDisplayMedia (captura de tela externa)');
			throw new Error('Screen capture not available in this window');
		};
	}

	// âœ… Desabilita captureStream (usado para captura de janela)
	if (window.HTMLCanvasElement && window.HTMLCanvasElement.prototype.captureStream) {
		Object.defineProperty(window.HTMLCanvasElement.prototype, 'captureStream', {
			value: function () {
				console.warn('ðŸ” BLOQUEADO: Tentativa de usar Canvas.captureStream()');
				throw new Error('Capture stream not available');
			},
			writable: false,
			configurable: false,
		});
	}

	// âœ… Intercepta getUserMedia para avisar sobre tentativas de captura de Ã¡udio
	if (navigator && navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
		const originalGetUserMedia = navigator.mediaDevices.getUserMedia.bind(navigator.mediaDevices);
		navigator.mediaDevices.getUserMedia = async function (constraints) {
			if (constraints && constraints.video) {
				console.warn('ðŸ” AVISO: Tentativa de usar getUserMedia com vÃ­deo detectada');
				// Ainda permite Ã¡udio, mas bloqueia vÃ­deo para captura
				if (constraints.video) {
					delete constraints.video;
				}
			}
			return originalGetUserMedia(constraints);
		};
	}

	console.log('âœ… ProteÃ§Ã£o contra captura externa ativada');
})();

/* ================================ */
//	CONSTANTES
/* ================================ */

const YOU = 'VocÃª';
const OTHER = 'Outros';

// Modos de operaÃ§Ã£o
const MODES = {
	NORMAL: 'NORMAL',
	INTERVIEW: 'INTERVIEW',
};

// ðŸ”„ modo atual (default = comportamento atual)
let CURRENT_MODE = MODES.NORMAL;

// Controlador de modo
const ModeController = {
	/**
	 * Verifica se estÃ¡ em modo entrevista
	 * @returns {boolean} true se modo entrevista
	 */
	isInterviewMode() {
		return CURRENT_MODE === MODES.INTERVIEW;
	},
};

const ENABLE_INTERVIEW_TIMING_DEBUG_METRICS = true; // â† desligar depois se nÃ£o quiser mostrar time = false
const CURRENT_QUESTION_ID = 'CURRENT'; // ID da pergunta atual

const SYSTEM_PROMPT = `
VocÃª Ã© um assistente para entrevistas tÃ©cnicas de Java. Responda como candidato.
Regras de resposta (priorize sempre estas):
- Seja natural e conciso: responda em no mÃ¡ximo 1â€“2 frases curtas.
- Use linguagem coloquial e direta, como alguÃ©m explicando rapidamente verbalmente.
- Evite listas longas, exemplos extensos ou parÃ¡grafos detalhados.
- NÃ£o comece com cumprimentos ou palavras de preenchimento (ex.: "Claro", "Ok").
- Quando necessÃ¡rio, entregue um exemplo mÃ­nimo de 1 linha apenas.
`;

/* ================================ */
//	ESTADO GLOBAL
/* ================================ */

let APP_CONFIG = {
	MODE_DEBUG: false, // â† alterado via config-manager.js (true = modo mock)
};

// Estado de execuÃ§Ã£o do STT
let appState.audio.isRunning = false;

// Screenshots capturados
let appState.audio.capturedScreenshots = []; // Array de { filepath, filename, timestamp }
let appState.audio.isCapturing = false;
let appState.audio.isAnalyzing = false;

// Drag and Drop da janela
let appState.window.isDraggingWindow = false;

// ðŸ”¥ MODIFICADO: STT model vem da config agora (removido USE_LOCAL_WHISPER)
let appState.metrics = {
	audioStartTime: null,
	gptStartTime: null,
	gptFirstTokenTime: null,
	gptEndTime: null,
	totalTime: null,
	audioSize: 0,
};

// ðŸ”¥ REMOVED: inputStream, inputAnalyser, outputStream, outputAnalyser
// Agora usamos audio-volume-monitor.js para monitoramento de volume
// quando usuÃ¡rio estÃ¡ na seÃ§Ã£o "Ãudio e Tela" (sem transcriÃ§Ã£o ativa)

/* ðŸ§  PERGUNTAS */
let appState.interview.currentQuestion = {
	text: '',
	lastUpdate: 0,
	finalized: false,
	promotedToHistory: false,
	turnId: null, // ðŸ”¥ ID Ãºnico para cada pergunta (incrementa quando nova fala chega)
	lastUpdateTime: null,
	createdAt: null,
	finalText: '',
	interimText: '',
};
let appState.history = [];
const answeredQuestions = new Set(); // ðŸ”’ Armazena respostas jÃ¡ geradas (questionId -> true)
let appState.selectedId = null;
let appState.interview.interviewTurnId = 0;
let appState.interview.gptAnsweredTurnId = null;
let appState.interview.gptRequestedTurnId = null;
let appState.interview.gptRequestedQuestionId = null; // ðŸ”¥ [IMPORTANTE] Rastreia QUAL pergunta foi realmente solicitada ao GPT
let appState.interview.lastAskedQuestionNormalized = null;

/* ================================ */
//	SISTEMA DE CALLBACKS E UI ELEMENTS
/* ================================ */

/**
 * Callbacks/Observers registrados pela UI (config-manager.js)
 * renderer.js Ã© "cego" para DOM - config-manager se inscreve em mudanÃ§as
 */
const UICallbacks = {
	onError: null, // ðŸ”¥ NOVO: Para mostrar erros de validaÃ§Ã£o
	onTranscriptAdd: null,
	onCurrentQuestionUpdate: null,
	onQuestionsHistoryUpdate: null,
	onStatusUpdate: null,
	onInputVolumeUpdate: null,
	onOutputVolumeUpdate: null,
	onMockBadgeUpdate: null,
	onDOMElementsReady: null, // callback para pedir elementos ao config-manager
	onListenButtonToggle: null,
	onAnswerSelected: null,
	onClearAllSelections: null,
	onScrollToQuestion: null,
	onTranscriptionCleared: null,
	onAnswersCleared: null,
	onAnswerStreamChunk: null,
	onAnswerIdUpdate: null,
	onModeSelectUpdate: null,
	onAnswerStreamEnd: null,
	onPlaceholderFulfill: null,
	onPlaceholderUpdate: null,
	onUpdateInterim: null,
	onClearInterim: null,
	onScreenshotBadgeUpdate: null,
	onAudioDeviceChanged: null,
};

/**
 * Registra callback para evento de UI
 * @param {string} eventName - Nome do evento
 * @param {function} callback - FunÃ§Ã£o a ser chamada quando evento ocorre
 */
function onUIChange(eventName, callback) {
	if (UICallbacks.hasOwnProperty(eventName)) {
		UICallbacks[eventName] = callback;
		console.log(`ðŸ“¡ UI callback registrado em renderer.js: ${eventName}`);
	}
}

/**
 * Emite evento de UI para config-manager
 * @param {string} eventName - Nome do evento
 * @param {any} data - Dados do evento
 */
function emitUIChange(eventName, data) {
	if (UICallbacks[eventName] && typeof UICallbacks[eventName] === 'function') {
		UICallbacks[eventName](data);
	} else {
		console.warn(`âš ï¸ DEBUG: Nenhum callback registrado para '${eventName}'`);
	}
}

/**
 * Elementos UI solicitados por callback
 * config-manager.js fornece esses elementos via registerUIElements()
 */
let UIElements = {
	inputSelect: null,
	outputSelect: null,
	listenBtn: null,
	statusText: null,
	transcriptionBox: null,
	currentQuestionBox: null,
	currentQuestionTextBox: null,
	questionsHistoryBox: null,
	answersHistoryBox: null,
	askBtn: null,
	inputVu: null,
	outputVu: null,
	inputVuHome: null,
	outputVuHome: null,
	mockToggle: null,
	mockBadge: null,
	interviewModeSelect: null,
	btnClose: null,
	btnToggleClick: null,
	dragHandle: null,
	darkToggle: null,
	opacityRange: null,
};

/**
 * Registra elementos UI no renderer
 * config-manager.js chama isso para registrar elementos
 * @param {object} elements - Mapeamento de elementos UI
 */
function registerUIElements(elements) {
	UIElements = { ...UIElements, ...elements };
	console.log('âœ… UI Elements registrados no renderer.js');
}

/* ================================ */
//	MONITORAMENTO DE VOLUME
/* ================================ */

/**
 * Escuta evento de mudanÃ§a de dispositivo
 * Emitido pelo config-manager
 */
eventBus.on('audioDeviceChanged', async data => {
	try {
		const sttModel = getConfiguredSTTModel();
		Logger.info('audioDeviceChanged', { model: sttModel, type: data.type });

		if (!data || !data.type) {
			Logger.warn('Dados invÃ¡lidos para mudanÃ§a de dispositivo', data);
			return;
		}

		if (!appState.audio.isRunning) {
			Logger.warn('STT nÃ£o estÃ¡ ativo, ignorando mudanÃ§a de dispositivo');
			return;
		}

		await sttStrategy.switchDevice(sttModel, data.type, data.deviceId);
	} catch (error) {
		Logger.error('Erro ao processar mudanÃ§a de dispositivo', { error: error.message });
	}
});

/* Compatibilidade: antigo onUIChange tambÃ©m suporta audioDeviceChanged */

/* ================================ */
//	FUNÃ‡Ã•ES UTILITÃRIAS (HELPERS)
/* ================================ */

/**
 * ObtÃ©m o modelo STT configurado via config-manager
 * @returns {string} Nome do modelo STT ou 'error'
 */
function getConfiguredSTTModel() {
	try {
		if (!window.configManager || !window.configManager.config) {
			console.warn('âš ï¸ configManager nÃ£o disponÃ­vel no escopo global');
			return 'error'; // fallback
		}

		const config = window.configManager.config;
		const activeProvider = config.api?.activeProvider;
		const sttModel = config.api?.[activeProvider]?.selectedSTTModel;

		if (!sttModel) {
			console.warn(`âš ï¸ Modelo STT nÃ£o configurado para ${activeProvider}`);
			return 'error'; // fallback
		}

		return sttModel;
	} catch (err) {
		console.error('âŒ Erro ao obter modelo STT da config:', err);
		return 'error'; // fallback
	}
}

/**
 * Finaliza pergunta adicionando "?" se necessÃ¡rio
 * @param {string} t - Texto da pergunta
 * @returns {string} Pergunta finalizada
 */
function finalizeQuestion(t) {
	Logger.debug('InÃ­cio da funÃ§Ã£o: "finalizeQuestion"');
	Logger.debug('Fim da funÃ§Ã£o: "finalizeQuestion"');
	return t.trim().endsWith('?') ? t.trim() : t.trim() + '?';
}

/**
 * Reseta o estado da pergunta atual (CURRENT)
 */
function resetCurrentQuestion() {
	Logger.debug('InÃ­cio da funÃ§Ã£o: "resetCurrentQuestion"');

	appState.interview.currentQuestion = {
		text: '',
		lastUpdate: 0,
		finalized: false,
		promotedToHistory: false,
		isBeingAnswered: false,
		lastUpdateTime: null,
		createdAt: null,
		finalText: '',
		interimText: '',
	};

	Logger.debug('Fim da funÃ§Ã£o: "resetCurrentQuestion"');
}

/**
 * Renderiza o histÃ³rico de perguntas
 */
function renderQuestionsHistory() {
	Logger.debug('InÃ­cio da funÃ§Ã£o: "renderQuestionsHistory"');

	// ðŸ”¥ Gera dados estruturados - config-manager renderiza no DOM
	const historyData = [...appState.history].reverse().map(q => {
		let label = q.text;
		if (ENABLE_INTERVIEW_TIMING_DEBUG_METRICS && q.lastUpdateTime) {
			const time = new Date(q.lastUpdateTime).toLocaleTimeString();
			label = `â±ï¸ ${time} â€” ${label}`;
		}

		return {
			id: q.id,
			turnId: q.turnId, // ðŸ”¥ Incluir turnId para exibiÃ§Ã£o visual
			text: label,
			isIncomplete: q.incomplete,
			isAnswered: q.answered,
			isSelected: q.id === appState.selectedId,
		};
	});

	emitUIChange('onQuestionsHistoryUpdate', historyData);

	scrollToSelectedQuestion();

	Logger.debug('Fim da funÃ§Ã£o: "renderQuestionsHistory"');
}

/**
 * Retorna o texto da pergunta selecionada (CURRENT ou do histÃ³rico)
 * @returns {string} Texto da pergunta selecionada
 */
function getSelectedQuestionText() {
	Logger.debug('InÃ­cio da funÃ§Ã£o: "getSelectedQuestionText"');
	Logger.debug('Fim da funÃ§Ã£o: "getSelectedQuestionText"');

	// 1ï¸âƒ£ Se existe seleÃ§Ã£o explÃ­cita
	if (appState.selectedId === CURRENT_QUESTION_ID) {
		return appState.interview.currentQuestion.text;
	}

	if (appState.selectedId) {
		const q = appState.history.find(q => q.id === appState.selectedId);
		if (q?.text) return q.text;
	}

	// 2ï¸âƒ£ Fallback: CURRENT (se tiver texto)
	if (appState.interview.currentQuestion.text && appState.interview.currentQuestion.text.trim().length > 0) {
		return appState.interview.currentQuestion.text;
	}

	return '';
}

/**
 * Normaliza texto para comparaÃ§Ã£o
 * Remove pontuaÃ§Ã£o, converte para lowercase, remove espaÃ§os extras
 * @param {string} t - Texto a normalizar
 * @returns {string} Texto normalizado
 */
function normalizeForCompare(t) {
	Logger.debug('InÃ­cio da funÃ§Ã£o: "normalizeForCompare"');
	Logger.debug('Fim da funÃ§Ã£o: "normalizeForCompare"');
	return (t || '')
		.toLowerCase()
		.replace(/[?!.\n\r]/g, '')
		.replace(/\s+/g, ' ')
		.trim();
}

/**
 * Atualiza a mensagem de status na UI
 * @param {string} message - Mensagem de status
 */
function updateStatusMessage(message) {
	Logger.debug('InÃ­cio da funÃ§Ã£o: "updateStatusMessage"');
	emitUIChange('onStatusUpdate', { message });
	Logger.debug('Fim da funÃ§Ã£o: "updateStatusMessage"');
}

/**
 * Verifica se uma pergunta jÃ¡ foi respondida pelo ID
 * @param {string} questionId - ID da pergunta
 * @returns {boolean} true se pergunta jÃ¡ foi respondida
 */
function findAnswerByQuestionId(questionId) {
	Logger.debug('InÃ­cio da funÃ§Ã£o: "findAnswerByQuestionId"');

	if (!questionId) {
		// ID invÃ¡lido
		Logger.debug('Fim da funÃ§Ã£o: "findAnswerByQuestionId"');
		return false;
	}

	Logger.debug('Fim da funÃ§Ã£o: "findAnswerByQuestionId"');
	return answeredQuestions.has(questionId);
}

/**
 * Promove pergunta atual para histÃ³rico
 * @param {string} text - Texto da pergunta
 */

/**
 * Limpa todas as seleÃ§Ãµes visuais
 */
function clearAllSelections() {
	// Emite evento para o controller limpar as seleÃ§Ãµes visuais
	emitUIChange('onClearAllSelections', {});
}

/**
 * ObtÃ©m IDs navegÃ¡veis de perguntas (CURRENT + histÃ³rico)
 * ðŸ”¥ ORDEM: CURRENT primeiro, depois histÃ³rico em ordem REVERSA (visualmente correto)
 * Porque o histÃ³rico Ã© renderizado com reverse(), entÃ£o a ordem navegÃ¡vel deve ser:
 * [CURRENT, ID_Ãºltimo, ID_penÃºltimo, ..., ID_primeiro]
 * @returns {array} Array de IDs navegÃ¡veis
 */

/* ================================ */
//	ðŸŽ¯ REGISTRAR STTs (RefatoraÃ§Ã£o Fase 2)
/* ================================ */

// Registrar STTs no sttStrategy
sttStrategy.register('deepgram', {
	start: startAudioDeepgram,
	stop: stopAudioDeepgram,
	switchDevice: switchDeviceDeepgram,
});

sttStrategy.register('vosk', {
	start: startAudioVosk,
	stop: stopAudioVosk,
	switchDevice: switchDeviceVosk,
});

sttStrategy.register('whisper-cpp-local', {
	start: startAudioWhisper,
	stop: stopAudioWhisper,
	switchDevice: switchDeviceWhisper,
});

sttStrategy.register('whisper-1', {
	start: startAudioWhisper,
	stop: stopAudioWhisper,
	switchDevice: switchDeviceWhisper,
});

/* ================================ */
//	CONTROLE DE ÃUDIO
/* ================================ */

/**
 * Inicia captura de Ã¡udio
 */
async function startAudio() {
	const sttModel = getConfiguredSTTModel();
	Logger.info('startAudio', { model: sttModel });

	try {
		await sttStrategy.start(sttModel, UIElements);
	} catch (error) {
		Logger.error('Erro ao iniciar Ã¡udio', { error: error.message });
		throw error;
	}
}

/**
 * Para captura de Ã¡udio
 */
async function stopAudio() {
	// Fecha pergunta atual se estava aberta
	if (appState.interview.currentQuestion.text) closeCurrentQuestionForced();

	const sttModel = getConfiguredSTTModel();
	Logger.info('stopAudio', { model: sttModel });

	try {
		await sttStrategy.stop(sttModel);
	} catch (error) {
		Logger.error('Erro ao parar Ã¡udio', { error: error.message });
	}
}

/**
 * Reinicia pipeline de Ã¡udio
 */

/**
 * Toggle do botÃ£o de iniciar/parar escuta (Ctrl+D)
 */
async function listenToggleBtn() {
	Logger.debug('InÃ­cio da funÃ§Ã£o: "listenToggleBtn"');

	if (!appState.audio.isRunning) {
		console.log('ðŸŽ¤ listenToggleBtn: Tentando INICIAR escuta...');

		// ðŸ”¥ VALIDAÃ‡ÃƒO 1: Modelo de IA ativo
		const { active: hasModel, model: activeModel } = hasActiveModel();
		Logger.debug(`ðŸ“Š DEBUG: hasModel = ${hasModel}, activeModel = ${activeModel}`, false);

		if (!hasModel) {
			const errorMsg = 'Ative um modelo de IA antes de comeÃ§ar a ouvir';
			console.warn(`âš ï¸ ${errorMsg}`);
			emitUIChange('onError', errorMsg);
			return;
		}

		// ðŸ”¥ VALIDAÃ‡ÃƒO 2: Dispositivo de Ã¡udio de SAÃDA (obrigatÃ³rio para ouvir a reuniÃ£o)
		const hasOutputDevice = UIElements.outputSelect?.value;
		Logger.debug(`ðŸ“Š DEBUG: hasOutputDevice = ${hasOutputDevice}`, false);

		if (!hasOutputDevice) {
			const errorMsg = 'Selecione um dispositivo de Ã¡udio (output) para ouvir a reuniÃ£o';
			console.warn(`âš ï¸ ${errorMsg}`);
			console.log('ðŸ“¡ DEBUG: Emitindo onError:', errorMsg);
			emitUIChange('onError', errorMsg);
			return;
		}
	}

	// Inverte o estado de appState.audio.isRunning
	appState.audio.isRunning = !appState.audio.isRunning;
	const buttonText = appState.audio.isRunning ? 'Parar a Escuta... (Ctrl+d)' : 'ComeÃ§ar a Ouvir... (Ctrl+d)';
	const statusMsg = appState.audio.isRunning ? 'Status: ouvindo...' : 'Status: parado';

	// Emite o evento 'onListenButtonToggle' para atualizar o botÃ£o de escuta
	emitUIChange('onListenButtonToggle', {
		appState.audio.isRunning,
		buttonText,
	});

	// Atualiza o status da escuta na tela
	updateStatusMessage(statusMsg);

	await (appState.audio.isRunning ? startAudio() : stopAudio());

	Logger.debug('Fim da funÃ§Ã£o: "listenToggleBtn"');
}

/**
 * Verifica se hÃ¡ um modelo de IA ativo na configuraÃ§Ã£o
 * @returns {object} { active: boolean, model: string|null }
 */
function hasActiveModel() {
	Logger.debug('InÃ­cio da funÃ§Ã£o: "hasActiveModel"');
	if (!window.configManager) {
		console.warn('âš ï¸ ConfigManager nÃ£o inicializado ainda');
		return { active: false, model: null };
	}

	const config = window.configManager.config;
	if (!config || !config.api) {
		console.warn('âš ï¸ Config ou api nÃ£o disponÃ­vel');
		return { active: false, model: null };
	}

	// Verifica se algum modelo estÃ¡ ativo e retorna o nome
	const providers = ['openai', 'google', 'openrouter', 'custom'];
	for (const provider of providers) {
		if (config.api[provider] && config.api[provider].enabled === true) {
			console.log(`âœ… Modelo ativo encontrado: ${provider}`);
			return { active: true, model: provider };
		}
	}

	console.warn('âš ï¸ Nenhum modelo ativo encontrado');

	Logger.debug('Fim da funÃ§Ã£o: "hasActiveModel"');
	return { active: false, model: null };
}

/* ================================ */
//	RENDERIZAÃ‡ÃƒO E NAVEGAÃ‡ÃƒO DE UI
/* ================================ */

/**
 * Renderiza a pergunta atual (CURRENT)
 */
function renderCurrentQuestion() {
	Logger.debug('InÃ­cio da funÃ§Ã£o: "renderCurrentQuestion"');

	// Se nÃ£o hÃ¡ texto, emite vazio
	if (!appState.interview.currentQuestion.text) {
		emitUIChange('onCurrentQuestionUpdate', { text: '', isSelected: false });
		return;
	}

	let label = appState.interview.currentQuestion.text;

	// Adiciona timestamp se modo debug mÃ©tricas ativo
	if (ENABLE_INTERVIEW_TIMING_DEBUG_METRICS && appState.interview.currentQuestion.lastUpdateTime) {
		const time = new Date(appState.interview.currentQuestion.lastUpdateTime).toLocaleTimeString();
		label = `â±ï¸ ${time} â€” ${label}`;
	}

	// ðŸ”¥ Gera dados estruturados - config-manager renderiza no DOM
	const questionData = {
		text: label,
		isSelected: appState.selectedId === CURRENT_QUESTION_ID,
		rawText: appState.interview.currentQuestion.text,
		createdAt: appState.interview.currentQuestion.createdAt,
		lastUpdateTime: appState.interview.currentQuestion.lastUpdateTime,
	};

	// Emite evento para o config-manager renderizar no DOM
	emitUIChange('onCurrentQuestionUpdate', questionData);

	Logger.debug('Fim da funÃ§Ã£o: "renderCurrentQuestion"');
}

/**
 * Manipula clique em pergunta
 * @param {string} questionId - ID da pergunta selecionada
 */
function handleQuestionClick(questionId) {
	Logger.debug('InÃ­cio da funÃ§Ã£o: "handleQuestionClick"');
	appState.selectedId = questionId;
	clearAllSelections();
	renderQuestionsHistory();
	renderCurrentQuestion();

	// âš ï¸ CURRENT nunca bloqueia resposta
	if (questionId !== CURRENT_QUESTION_ID) {
		const existingAnswer = findAnswerByQuestionId(questionId);

		if (existingAnswer) {
			emitUIChange('onAnswerSelected', {
				questionId: questionId,
				shouldScroll: true,
			});

			updateStatusMessage('ðŸ“Œ Essa pergunta jÃ¡ foi respondida');
			Logger.debug('Fim da funÃ§Ã£o: "handleQuestionClick" (pergunta jÃ¡ respondida, sem re-perguntar)');
			return; // ðŸ”¥ CRÃTICO: Retornar aqui, nÃ£o chamar askLLM()
		}
	}

	// Se for uma pergunta do histÃ³rico marcada como incompleta, nÃ£o enviar automaticamente ao GPT
	if (questionId !== CURRENT_QUESTION_ID) {
		const q = appState.history.find(q => q.id === questionId);
		if (q && q.incomplete) {
			updateStatusMessage('âš ï¸ Pergunta incompleta â€” pressione o botÃ£o de responder para enviar ao GPT');
			console.log('â„¹ï¸ pergunta incompleta selecionada â€” aguarda envio manual:', q.text);
			Logger.debug('Fim da funÃ§Ã£o: "handleQuestionClick" (pergunta incompleta)');
			return; // ðŸ”¥ CRÃTICO: Retornar aqui tambÃ©m
		}
	}

	if (
		ModeController.isInterviewMode() &&
		appState.selectedId === CURRENT_QUESTION_ID &&
		appState.interview.gptAnsweredTurnId === appState.interview.interviewTurnId
	) {
		updateStatusMessage('â›” GPT jÃ¡ respondeu esse turno');
		console.log('â›” GPT jÃ¡ respondeu esse turno');
		Logger.debug('Fim da funÃ§Ã£o: "handleQuestionClick" (GPT jÃ¡ respondeu)');
		return; // ðŸ”¥ CRÃTICO: Retornar aqui
	}

	// â“ Ainda nÃ£o respondida â†’ promover CURRENT se necessÃ¡rio e chamar GPT
	// ðŸ”¥ Se for CURRENT, promover para histÃ³rico ANTES de chamar askLLM
	if (questionId === CURRENT_QUESTION_ID) {
		if (!appState.interview.currentQuestion.text || !appState.interview.currentQuestion.text.trim()) {
			updateStatusMessage('âš ï¸ Pergunta vazia - nada a responder');
			Logger.debug('Fim da funÃ§Ã£o: "handleQuestionClick" (pergunta vazia)');
			return;
		}

		// Promover CURRENT para histÃ³rico se ainda nÃ£o foi promovido
		if (!appState.interview.currentQuestion.finalized) {
			appState.interview.currentQuestion.text = finalizeQuestion(appState.interview.currentQuestion.text);
			appState.interview.currentQuestion.lastUpdateTime = Date.now();
			appState.interview.currentQuestion.finalized = true;

			// ðŸ”¥ [CRÃTICO] Incrementa turnId APENAS na hora de promover (nÃ£o na primeira fala)
			appState.interview.interviewTurnId++;
			appState.interview.currentQuestion.turnId = appState.interview.interviewTurnId;

			const newId = String(appState.history.length + 1);
			appState.history.push({
				id: newId,
				text: appState.interview.currentQuestion.text,
				turnId: appState.interview.currentQuestion.turnId,
				createdAt: appState.interview.currentQuestion.createdAt || Date.now(),
				lastUpdateTime: appState.interview.currentQuestion.lastUpdateTime || Date.now(),
			});

			appState.interview.currentQuestion.promotedToHistory = true;
			resetCurrentQuestion();
			appState.selectedId = newId;
			renderQuestionsHistory();
			renderCurrentQuestion();

			Logger.debug('ðŸ”¥ CURRENT promovido para histÃ³rico via handleQuestionClick', { newId }, false);

			// Chamar askLLM com o novo ID promovido
			askLLM(newId);
			Logger.debug('Fim da funÃ§Ã£o: "handleQuestionClick" (CURRENT promovido e askLLM chamado)');
			return;
		}
	}

	// â“ Ainda nÃ£o respondida â†’ chama GPT (click ou atalho)
	askLLM();

	Logger.debug('Fim da funÃ§Ã£o: "handleQuestionClick"');
}

/**
 * Aplica opacidade na interface
 * MOVIDA PARA: config-manager.js
 * @deprecated Usar ConfigManager.applyOpacity(value) em vez disso
 */

/**
 * Rola a lista de perguntas para a pergunta selecionada
 */
function scrollToSelectedQuestion() {
	emitUIChange('onScrollToQuestion', {
		questionId: appState.selectedId,
	});
}

/**
 * ConfiguraÃ§Ã£o do Marked.js para renderizaÃ§Ã£o de Markdown
 */
marked.setOptions({
	html: true, // ðŸ”¥ Permite renderizaÃ§Ã£o de HTML (nÃ£o escapa entidades)
	breaks: true,
	gfm: true, // GitHub Flavored Markdown
	highlight: function (code, lang) {
		if (lang && hljs.getLanguage(lang)) {
			return hljs.highlight(code, { language: lang }).value;
		}
		return hljs.highlightAuto(code).value;
	},
});

/* ================================ */
//	CONSOLIDAÃ‡ÃƒO E FINALIZAÃ‡ÃƒO DE PERGUNTAS
/* ================================ */

/**
 * Fluxo para consolidar transcriÃ§Ãµes no CURRENT
 * Concatena transcriÃ§Ã£o interims e finais
 * @param {string} author - Autor da fala (YOU ou OTHER)
 * @param {string} text - Texto da fala
 * @param {object} options - OpÃ§Ãµes (isInterim, shouldFinalizeAskCurrent)
 */
function handleCurrentQuestion(author, text, options = {}) {
	Logger.debug('InÃ­cio da funÃ§Ã£o: "handleCurrentQuestion"');

	const cleaned = text.replace(/ÃŠ+|hum|ahn/gi, '').trim();

	// Usa o tempo exato que chegou no renderer (Date.now)
	const now = Date.now();

	// Apenas consolida falas no CURRENT do OTHER
	if (author === OTHER) {
		// Se nÃ£o existe texto ainda, marca tempo de criaÃ§Ã£o
		if (!appState.interview.currentQuestion.text) {
			appState.interview.currentQuestion.createdAt = now;
			// ðŸ”¥ NÃƒO incrementa turnId aqui - serÃ¡ feito ao promover para histÃ³rico
		}

		appState.interview.currentQuestion.lastUpdateTime = now;
		appState.interview.currentQuestion.lastUpdate = now;

		Logger.debug('appState.interview.currentQuestion antes: ', { ...appState.interview.currentQuestion }, false);

		// LÃ³gica de consolidaÃ§Ã£o para evitar duplicaÃ§Ãµes
		if (options.isInterim) {
			// Para interims: substituir o interim atual (Deepgram envia versÃµes progressivas)
			appState.interview.currentQuestion.interimText = cleaned;
		} else {
			// Para finais: limpar interim e ACUMULAR no finalText
			appState.interview.currentQuestion.interimText = '';
			appState.interview.currentQuestion.finalText = (appState.interview.currentQuestion.finalText ? appState.interview.currentQuestion.finalText + ' ' : '') + cleaned;
		}

		Logger.debug('appState.interview.currentQuestion durante: ', { ...appState.interview.currentQuestion }, false);

		// Atualizar o texto total
		appState.interview.currentQuestion.text =
			appState.interview.currentQuestion.finalText.trim() + (appState.interview.currentQuestion.interimText ? ' ' + appState.interview.currentQuestion.interimText : '');

		Logger.debug('appState.interview.currentQuestion depois: ', { ...appState.interview.currentQuestion }, false);

		// ðŸŸ¦ CURRENT vira seleÃ§Ã£o padrÃ£o ao receber fala
		if (!appState.selectedId) {
			appState.selectedId = CURRENT_QUESTION_ID;
			clearAllSelections();
		}

		// Adiciona TUDO Ã  conversa visual em tempo real ao elemento "currentQuestionText"
		renderCurrentQuestion();

		// SÃ³ finaliza se estivermos em silÃªncio e NÃƒO for um interim
		if (options.shouldFinalizeAskCurrent && !options.isInterim) {
			Logger.debug('ðŸŸ¢ ********  EstÃ¡ em silÃªncio, feche a pergunta e chame o GPT ðŸ¤– ******** ðŸŸ¢', true);

			// fecha/finaliza a pergunta atual
			finalizeCurrentQuestion();
		}
	}

	Logger.debug('Fim da funÃ§Ã£o: "handleCurrentQuestion"');
}

/**
 * Finaliza a pergunta atual para histÃ³rico
 */
function finalizeCurrentQuestion() {
	Logger.debug('InÃ­cio da funÃ§Ã£o: "finalizeCurrentQuestion"');

	// Se nÃ£o hÃ¡ texto, ignorar
	if (!appState.interview.currentQuestion.text || !appState.interview.currentQuestion.text.trim()) {
		console.log('âš ï¸ finalizeCurrentQuestion: Sem texto para finalizar');
		return;
	}

	// ðŸ”’ GUARDA ABSOLUTA: Se a pergunta jÃ¡ foi finalizada, NÃƒO faÃ§a nada.
	if (appState.interview.currentQuestion.finalized) {
		console.log('â›” finalizeCurrentQuestion ignorado â€” pergunta jÃ¡ finalizada');
		return;
	}

	// âš ï¸ No modo entrevista: PROMOVER ANTES de chamar LLM
	if (ModeController.isInterviewMode()) {
		appState.interview.currentQuestion.text = finalizeQuestion(appState.interview.currentQuestion.text);
		appState.interview.currentQuestion.lastUpdateTime = Date.now();
		appState.interview.currentQuestion.finalized = true;

		// ðŸ”¥ [NOVO] PROMOVER PARA HISTÃ“RICO ANTES DE CHAMAR LLM
		// Isso garante que o texto estÃ¡ seguro e imutÃ¡vel durante resposta do GPT
		const newId = String(appState.history.length + 1);

		// ðŸ”¥ [CRÃTICO] Incrementa turnId APENAS na hora de promover (nÃ£o na primeira fala)
		appState.interview.interviewTurnId++;
		appState.interview.currentQuestion.turnId = appState.interview.interviewTurnId;

		appState.history.push({
			id: newId,
			text: appState.interview.currentQuestion.text,
			turnId: appState.interview.currentQuestion.turnId, // ðŸ”¥ Incluir turnId na entrada do histÃ³rico
			createdAt: appState.interview.currentQuestion.createdAt || Date.now(),
			lastUpdateTime: appState.interview.currentQuestion.lastUpdateTime || Date.now(),
		});

		appState.interview.currentQuestion.promotedToHistory = true;

		// ðŸ”¥ [CRÃTICO] LIMPAR CURRENT LOGO APÃ“S PROMOVER
		// NÃ£o espera nem o render nem o LLM
		resetCurrentQuestion();

		// garante seleÃ§Ã£o lÃ³gica
		appState.selectedId = newId;
		renderQuestionsHistory();
		renderCurrentQuestion(); // ðŸ”¥ Renderiza CURRENT limpo

		// ðŸ”¥ [NOVO] Chamar GPT DEPOIS que pergunta foi promovida e salva
		// chama GPT automaticamente se ainda nÃ£o respondeu este turno
		if (appState.interview.gptRequestedTurnId !== appState.interview.interviewTurnId && appState.interview.gptAnsweredTurnId !== appState.interview.interviewTurnId) {
			askLLM(newId); // Passar ID promovido para LLM
		}

		Logger.debug('Fim da funÃ§Ã£o: "finalizeCurrentQuestion"');
		return;
	}

	//  âš ï¸ No modo normal - trata perguntas que parecem incompletas
	if (!ModeController.isInterviewMode()) {
		console.log('âš ï¸ No modo normal detectado â€” promovendo ao histÃ³rico sem chamar GPT:', appState.interview.currentQuestion.text);

		// promoteCurrentToHistory(appState.interview.currentQuestion.text);
		const newId = String(appState.history.length + 1);
		appState.history.push({
			id: newId,
			text: appState.interview.currentQuestion.text,
			turnId: appState.interview.currentQuestion.turnId,
			createdAt: appState.interview.currentQuestion.createdAt || Date.now(),
			lastUpdateTime: appState.interview.currentQuestion.lastUpdateTime || appState.interview.currentQuestion.createdAt || Date.now(),
		});

		appState.selectedId = newId;
		resetCurrentQuestion();
		renderQuestionsHistory();
		renderCurrentQuestion(); // ðŸ”¥ Renderiza CURRENT limpo

		Logger.debug('Fim da funÃ§Ã£o: "finalizeCurrentQuestion"');
		return;
	}
}

/**
 * ForÃ§a o fechamento da pergunta atual, promovendo-a ao histÃ³rico
 */
function closeCurrentQuestionForced() {
	Logger.debug('InÃ­cio da funÃ§Ã£o: "closeCurrentQuestionForced"');

	// log temporario para testar a aplicaÃ§Ã£o sÃ³ remover depois
	console.log('ðŸšª Fechando pergunta:', appState.interview.currentQuestion.text);

	if (!appState.interview.currentQuestion.text) return;

	appState.history.push({
		id: crypto.randomUUID(),
		text: finalizeQuestion(appState.interview.currentQuestion.text),
		createdAt: appState.interview.currentQuestion.createdAt || Date.now(),
	});

	appState.interview.currentQuestion.text = '';
	appState.selectedId = null; // ðŸ‘ˆ libera seleÃ§Ã£o
	renderQuestionsHistory();
	renderCurrentQuestion();

	Logger.debug('Fim da funÃ§Ã£o: "closeCurrentQuestionForced"');
}

/* ================================ */
//	SISTEMA GPT E STREAMING
/* ================================ */

/**
 * Envia pergunta selecionada ao LLM (qualquer provider)
 * âœ… REFATORADA: agora Ã© simples e legÃ­vel!
 * âœ… CENTRALIZADA: Uma Ãºnica funÃ§Ã£o para todos os LLMs
 * âœ… NÃ£o hÃ¡ duplicaÃ§Ã£o de askLLM() por LLM
 * @param {string} questionId - ID da pergunta a responder (padrÃ£o: appState.selectedId)
 */
async function askLLM(questionId = null) {
	try {
		const CURRENT_QUESTION_ID = 'CURRENT';
		const targetQuestionId = questionId || appState.selectedId;

		// 1. Validar (antigo validateAskGptRequest)
		const {
			questionId: validatedId,
			text,
			isCurrent,
		} = validateLLMRequest(appState, targetQuestionId, getSelectedQuestionText);
		Logger.info('Pergunta vÃ¡lida', { questionId: validatedId, textLength: text.length });

		// Rastreamento antigo (compatibilidade)
		const normalizedText = normalizeForCompare(text);
		appState.metrics.gptStartTime = Date.now();

		if (isCurrent) {
			appState.interview.gptRequestedTurnId = appState.interview.interviewTurnId;
			appState.interview.gptRequestedQuestionId = CURRENT_QUESTION_ID;
			appState.interview.lastAskedQuestionNormalized = normalizedText;
		}

		// 2. Rotear por modo (nÃ£o por LLM!)
		const isInterviewMode = ModeController.isInterviewMode();

		// Obter turnId da pergunta para passar ao LLM
		const questionEntry = appState.history.find(q => q.id === targetQuestionId);
		const turnId = questionEntry?.turnId || null;

		if (isInterviewMode) {
			await handleLLMStream(appState, validatedId, text, SYSTEM_PROMPT, eventBus, llmManager, turnId);
		} else {
			await handleLLMBatch(appState, validatedId, text, SYSTEM_PROMPT, eventBus, llmManager);
		}
		// O llmManager sabe qual LLM usar (OpenAI, Gemini, etc)
		// Sem duplicaÃ§Ã£o de cÃ³digo!
	} catch (error) {
		Logger.error('Erro em askLLM', { error: error.message });
		eventBus.emit('error', error.message);
		updateStatusMessage(`âŒ ${error.message}`);
	}
}

/**
 * Log detalhado das mÃ©tricas de tempo da transcriÃ§Ã£o
 */
function logTranscriptionMetrics() {
	if (!appState.metrics.audioStartTime) return;

	const gptTime = appState.metrics.gptEndTime - appState.metrics.gptStartTime;
	const totalTime = appState.metrics.totalTime;

	console.log(`ðŸ“Š ================================`);
	console.log(`ðŸ“Š MÃ‰TRICAS DE TEMPO DETALHADAS:`);
	console.log(`ðŸ“Š ================================`);
	console.log(`ðŸ“Š TAMANHO ÃUDIO: ${appState.metrics.audioSize} bytes`);
	console.log(`ðŸ“Š GPT: ${gptTime}ms`);
	console.log(`ðŸ“Š TOTAL: ${totalTime}ms`);
	console.log(`ðŸ“Š GPT % DO TOTAL: ${Math.round((gptTime / totalTime) * 100)}%`);
	console.log(`ðŸ“Š ================================`);

	// Reset para prÃ³xima mediÃ§Ã£o
	appState.metrics = {
		audioStartTime: null,
		gptStartTime: null,
		gptEndTime: null,
		totalTime: null,
		audioSize: 0,
	};
}

/* ================================ */
//	SCREENSHOT E ANÃLISE
/* ================================ */

/**
 * Captura screenshot discretamente e armazena em memÃ³ria
 */
async function captureScreenshot() {
	if (appState.audio.isCapturing) {
		console.log('â³ Captura jÃ¡ em andamento...');
		return;
	}

	appState.audio.isCapturing = true;
	updateStatusMessage('ðŸ“¸ Capturando tela...');

	try {
		const result = await ipcRenderer.invoke('CAPTURE_SCREENSHOT');

		if (!result.success) {
			console.warn('âš ï¸ Falha na captura:', result.error);
			updateStatusMessage(`âŒ ${result.error}`);
			emitUIChange('onScreenshotBadgeUpdate', {
				count: appState.audio.capturedScreenshots.length,
				visible: appState.audio.capturedScreenshots.length > 0,
			});
			return;
		}

		// âœ… Armazena referÃªncia do screenshot
		appState.audio.capturedScreenshots.push({
			filepath: result.filepath,
			filename: result.filename,
			timestamp: result.timestamp,
			size: result.size,
		});

		console.log(`âœ… Screenshot capturado: ${result.filename}`);
		console.log(`ðŸ“¦ Total em memÃ³ria: ${appState.audio.capturedScreenshots.length}`);

		// Atualiza UI
		updateStatusMessage(`âœ… ${appState.audio.capturedScreenshots.length} screenshot(s) capturado(s)`);
		emitUIChange('onScreenshotBadgeUpdate', {
			count: appState.audio.capturedScreenshots.length,
			visible: true,
		});
	} catch (error) {
		console.error('âŒ Erro ao capturar screenshot:', error);
		updateStatusMessage('âŒ Erro na captura');
	} finally {
		appState.audio.isCapturing = false;
	}
}

/**
 * Envia screenshots para anÃ¡lise com OpenAI Vision
 */
async function analyzeScreenshots() {
	if (appState.audio.isAnalyzing) {
		Logger.info('AnÃ¡lise jÃ¡ em andamento');
		return;
	}

	if (appState.audio.capturedScreenshots.length === 0) {
		Logger.warn('Nenhum screenshot para analisar');
		updateStatusMessage('âš ï¸ Nenhum screenshot para analisar (capture com Ctrl+Shift+F)');
		return;
	}

	appState.audio.isAnalyzing = true;
	updateStatusMessage(`ðŸ” Analisando ${appState.audio.capturedScreenshots.length} screenshot(s)...`);

	try {
		// Extrai caminhos dos arquivos
		const filepaths = appState.audio.capturedScreenshots.map(s => s.filepath);

		Logger.info('Enviando para anÃ¡lise', { count: filepaths.length });

		// Envia para main.js
		const result = await ipcRenderer.invoke('ANALYZE_SCREENSHOTS', filepaths);

		if (!result.success) {
			Logger.error('Falha na anÃ¡lise', { error: result.error });
			updateStatusMessage(`âŒ ${result.error}`);
			return;
		}

		// âœ… Renderiza resposta do GPT
		const questionText = `ðŸ“¸ AnÃ¡lise de ${appState.audio.capturedScreenshots.length} screenshot(s)`;
		const questionId = String(appState.history.length + 1);

		// Adiciona "pergunta" ao histÃ³rico ANTES de renderizar respostas
		appState.history.push({
			id: questionId,
			text: questionText,
			createdAt: Date.now(),
			lastUpdateTime: Date.now(),
			answered: true,
		});

		// âœ… MARCA COMO RESPONDIDA (importante para clique nÃ£o gerar duplicata)
		answeredQuestions.add(questionId);

		renderQuestionsHistory();

		// âœ… RENDERIZA VIA EVENTBUS (consistente com LLM)
		// Divide anÃ¡lise em tokens e emite como se fosse stream
		const analysisText = result.analysis;
		const tokens = analysisText.split(/(\s+|[.,!?;:\-\(\)\[\]{}\n])/g).filter(t => t.length > 0);

		Logger.info('Simulando stream', { tokenCount: tokens.length });

		// Emite tokens via eventBus (consistente com askLLM)
		let accumulated = '';
		for (const token of tokens) {
			accumulated += token;

			eventBus.emit('answerStreamChunk', {
				questionId: questionId,
				token: token,
				accum: accumulated,
			});

			// Pequeno delay entre tokens para simular streaming real
			await new Promise(resolve => setTimeout(resolve, 2));
		}

		Logger.info('AnÃ¡lise concluÃ­da');
		updateStatusMessage('âœ… AnÃ¡lise concluÃ­da');

		// ðŸ—‘ï¸ Limpa screenshots apÃ³s anÃ¡lise
		Logger.info('Limpando screenshots', { count: appState.audio.capturedScreenshots.length });
		appState.audio.capturedScreenshots = [];

		// Atualiza badge
		emitUIChange('onScreenshotBadgeUpdate', {
			count: 0,
			visible: false,
		});

		// ForÃ§a limpeza no sistema
		await ipcRenderer.invoke('CLEANUP_SCREENSHOTS');
	} catch (error) {
		Logger.error('Erro ao analisar screenshots', { error: error.message });
		updateStatusMessage('âŒ Erro na anÃ¡lise');
	} finally {
		appState.audio.isAnalyzing = false;
	}
}

/**
 * Limpa todos os screenshots armazenados
 */
function clearScreenshots() {
	if (appState.audio.capturedScreenshots.length === 0) return;

	console.log(`ðŸ—‘ï¸ Limpando ${appState.audio.capturedScreenshots.length} screenshot(s)...`);
	appState.audio.capturedScreenshots = [];

	updateStatusMessage('âœ… Screenshots limpos');
	emitUIChange('onScreenshotBadgeUpdate', {
		count: 0,
		visible: false,
	});

	// ForÃ§a limpeza no sistema
	ipcRenderer.invoke('CLEANUP_SCREENSHOTS').catch(err => {
		console.warn('âš ï¸ Erro na limpeza:', err);
	});
}

/* ================================ */
//	RESET COMPLETO
/* ================================ */

/**
 * Libera a thread para o navegador processar eventos
 * @param {number} ms - Milissegundos para aguardar (default 0 = prÃ³ximo frame)
 */
function releaseThread(ms = 0) {
	return new Promise(resolve => setTimeout(resolve, ms));
}

/**
 * Reseta todo o estado do app
 * Quebrado em chunks para nÃ£o bloquear a UI thread
 */
async function resetAppState() {
	console.log('ðŸ§¹ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
	console.log('ðŸ§¹ INICIANDO RESET COMPLETO DO APP');
	console.log('ðŸ§¹ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

	try {
		// 1ï¸âƒ£ CHUNK 1: Parar autoplay e Ã¡udio
		mockAutoPlayActive = false;
		mockScenarioIndex = 0;
		if (appState.audio.isRunning) {
			console.log('ðŸŽ¤ Parando captura de Ã¡udio...');
			appState.audio.isRunning = false;
		}
		console.log('âœ… Autoplay do mock parado');
		await releaseThread();

		// 2ï¸âƒ£ CHUNK 2: Limpar perguntas e respostas
		appState.interview.currentQuestion = {
			text: '',
			lastUpdate: 0,
			finalized: false,
			promotedToHistory: false,
			turnId: null,
			lastUpdateTime: null,
			createdAt: null,
			finalText: '',
			interimText: '',
		};
		appState.history = [];
		answeredQuestions.clear();
		appState.selectedId = null;
		appState.interview.lastAskedQuestionNormalized = null;
		console.log('âœ… Perguntas e respostas limpas');
		await releaseThread();

		// 3ï¸âƒ£ CHUNK 3: Limpar estado GPT e mÃ©tricas
		appState.interview.interviewTurnId = 0;
		appState.interview.gptAnsweredTurnId = null;
		appState.interview.gptRequestedTurnId = null;
		appState.interview.gptRequestedQuestionId = null;
		appState.metrics = {
			audioStartTime: null,
			gptStartTime: null,
			gptEndTime: null,
			totalTime: null,
			audioSize: 0,
		};
		console.log('âœ… Estado de entrevista resetado');
		console.log('âœ… MÃ©tricas resetadas');
		await releaseThread();

		// 4ï¸âƒ£ CHUNK 4: Limpar screenshots
		if (appState.audio.capturedScreenshots.length > 0) {
			console.log(`ðŸ—‘ï¸ Limpando ${appState.audio.capturedScreenshots.length} screenshot(s)...`);
			appState.audio.capturedScreenshots = [];
			emitUIChange('onScreenshotBadgeUpdate', {
				count: 0,
				visible: false,
			});
			// ForÃ§a limpeza no sistema (async, nÃ£o bloqueia)
			try {
				await ipcRenderer.invoke('CLEANUP_SCREENSHOTS');
			} catch (err) {
				console.warn('âš ï¸ Erro ao limpar screenshots no sistema:', err);
			}
		}
		console.log('âœ… Screenshots limpos');
		await releaseThread();

		// 5ï¸âƒ£ CHUNK 5: Limpar flags
		appState.audio.isCapturing = false;
		appState.audio.isAnalyzing = false;
		console.log('âœ… Flags resetadas');
		await releaseThread();

		// 6ï¸âƒ£ CHUNK 6: Atualizar UI - Perguntas
		emitUIChange('onCurrentQuestionUpdate', {
			text: '',
			isSelected: false,
		});
		emitUIChange('onQuestionsHistoryUpdate', []);
		console.log('âœ… Perguntas UI limpa');
		await releaseThread();

		// 7ï¸âƒ£ CHUNK 7: Atualizar UI - TranscriÃ§Ãµes e Respostas
		emitUIChange('onTranscriptionCleared');
		emitUIChange('onAnswersCleared');
		console.log('âœ… TranscriÃ§Ãµes e respostas UI limpas');
		await releaseThread();

		// 8ï¸âƒ£ CHUNK 8: Atualizar UI - BotÃ£o Listen
		emitUIChange('onListenButtonToggle', {
			appState.audio.isRunning: false,
			buttonText: 'ðŸŽ¤ ComeÃ§ar a Ouvir... (Ctrl+D)',
		});
		console.log('âœ… BotÃ£o listen resetado');
		await releaseThread();

		// 9ï¸âƒ£ CHUNK 9: Atualizar UI - Status
		emitUIChange('onStatusUpdate', {
			status: 'ready',
			message: 'âœ… Pronto',
		});
		console.log('âœ… Status atualizado');
		await releaseThread();

		// ðŸ”Ÿ CHUNK 10: Limpar seleÃ§Ãµes
		clearAllSelections();
		console.log('âœ… SeleÃ§Ãµes limpas');
		await releaseThread();

		// 1ï¸âƒ£1ï¸âƒ£ LOG FINAL
		console.log('âœ… â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
		console.log('âœ… RESET COMPLETO CONCLUÃDO COM SUCESSO');
		console.log('âœ… â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

		return true;
	} catch (error) {
		console.error('âŒ Erro ao resetar app:', error);
		return false;
	}
}

/**
 * FunÃ§Ã£o auxiliar para liberar a thread do navegador
 * Usada em resetAppState() para quebrar operaÃ§Ãµes longas em chunks
 */

//	DEBUG LOG RENDERER
/* ================================ */

/**
 * Log de debug padronizado para renderer
 * Ãšltimo argumento opcional Ã© booleano para mostrar ou nÃ£o o log
 * @param {...any} args - Argumentos a logar
 */

/* ================================ */
//	EXPORTAÃ‡ÃƒO PUBLIC API (RendererAPI)
/* ================================ */

/**
 * API PÃºblica exposta do Renderer
 * MÃ©todos pÃºblicos que podem ser chamados de fora
 */
const RendererAPI = {
	// Ãudio - GravaÃ§Ã£o
	listenToggleBtn,
	askLLM,
	// ðŸ”¥ Estado de transcriÃ§Ã£o (usado pelo audio-volume-monitor.js)
	get appState.audio.isRunning() {
		return appState.audio.isRunning;
	},

	// Ãudio - Monitoramento de volume
	startAudioVolumeMonitor,
	stopAudioVolumeMonitor,
	switchAudioVolumeDevice,

	// Entrevista - Reset (centralizado em resetAppState)
	resetAppState,

	// Modo
	changeMode: mode => {
		CURRENT_MODE = mode;
	},
	getMode: () => CURRENT_MODE,

	// Questions
	handleCurrentQuestion,
	handleQuestionClick,

	// ðŸ”¥ NOVO: Expor appState.interview.selectedQuestionId para atalhos em config-manager.js
	get appState.selectedId() {
		return appState.selectedId;
	},

	// UI
	// ðŸ”¥ MOVED: applyOpacity foi para config-manager.js
	updateMockBadge: show => {
		emitUIChange('onMockBadgeUpdate', { visible: show });
	},
	setMockToggle: checked => {
		APP_CONFIG.MODE_DEBUG = checked;
		// UI serÃ¡ atualizada via emitUIChange
	},
	setModeSelect: mode => {
		emitUIChange('onModeSelectUpdate', { mode });
	},

	// Drag
	/**
	 * Inicializa drag handle para movimento de janela
	 * MOVIDA PARA: config-manager.js
	 * @deprecated Usar ConfigManager.initDragHandle(dragHandle) em vez disso
	 */

	// Click-through
	setClickThrough: enabled => {
		ipcRenderer.send('SET_CLICK_THROUGH', enabled);
	},
	/**
	 * Atualiza botÃ£o de click-through
	 * @param {boolean} enabled - Se click-through estÃ¡ ativo
	 * @param {element} btnToggle - BotÃ£o a atualizar
	 */
	updateClickThroughButton: (enabled, btnToggle) => {
		if (!btnToggle) return;
		btnToggle.style.opacity = enabled ? '0.5' : '1';
		btnToggle.title = enabled
			? 'Click-through ATIVO (clique para desativar)'
			: 'Click-through INATIVO (clique para ativar)';
		console.log('ðŸŽ¨ BotÃ£o atualizado - opacity:', btnToggle.style.opacity);
	},

	// UI Registration
	registerUIElements: elements => {
		registerUIElements(elements);
	},
	onUIChange: (eventName, callback) => {
		onUIChange(eventName, callback);
	},
	// Emit UI changes (para config-manager enviar eventos para renderer)
	emitUIChange,

	// API Key
	setAppConfig: config => {
		APP_CONFIG = config;
		// ðŸŽ­ Inicializa mock interceptor se MODE_DEBUG estiver ativo
		if (APP_CONFIG.MODE_DEBUG) {
			mockRunner.initMockInterceptor({
				emitUIChange,
				captureScreenshot,
				analyzeScreenshots,
				APP_CONFIG,
			});
			Logger.info('âœ… Mock interceptor inicializado para MODE_DEBUG');
		}
	},
	getAppConfig: () => APP_CONFIG,

	// Navegacao de perguntas (Ctrl+Shift+ArrowUp/Down via globalShortcut IPC)
	/**
	 * Navega entre perguntas
	 * @param {string} direction - 'up' ou 'down'
	 */
	navigateQuestions: direction => {
		const all = getNavigableQuestionIds();
		if (all.length === 0) return;

		let index = all.indexOf(appState.selectedId);
		if (index === -1) {
			// Nenhuma seleÃ§Ã£o: comeÃ§a do comeÃ§o ou do fim
			index = direction === 'up' ? all.length - 1 : 0;
		} else {
			// ðŸ”¥ CORRIGIDO: LÃ³gica normal (agora que getNavigableQuestionIds retorna ordem visual correta)
			// 'up' = subir visualmente = diminuir Ã­ndice
			// 'down' = descer visualmente = aumentar Ã­ndice
			index += direction === 'up' ? -1 : 1;
			index = Math.max(0, Math.min(index, all.length - 1));
		}

		appState.selectedId = all[index];
		clearAllSelections();
		renderQuestionsHistory();
		renderCurrentQuestion();

		if (APP_CONFIG.MODE_DEBUG) {
			const msg = direction === 'up' ? 'ðŸ§ª Ctrl+ArrowUp detectado (teste)' : 'ðŸ§ª Ctrl+ArrowDown detectado (teste)';
			updateStatusMessage(msg);
			console.log('ðŸ“Œ Atalho Selecionou:', appState.selectedId);
		}
	},

	// IPC Listeners
	onApiKeyUpdated: callback => {
		ipcRenderer.on('API_KEY_UPDATED', callback);
	},
	onToggleAudio: callback => {
		// ComeÃ§ar a ouvir / Parar de ouvir (Ctrl+D)
		ipcRenderer.on('CMD_TOGGLE_AUDIO', callback);
	},
	onAskGpt: callback => {
		ipcRenderer.on('CMD_ASK_GPT', callback);
	},
	onGptStreamChunk: callback => {
		ipcRenderer.on('GPT_STREAM_CHUNK', callback);
	},
	onGptStreamEnd: callback => {
		ipcRenderer.on('GPT_STREAM_END', callback);
	},
	/**
	 * Envia erro do renderer para main
	 * @param {error} error - Erro a enviar
	 */
	sendRendererError: error => {
		try {
			console.error('RENDERER ERROR', error.error || error.message || error);
			ipcRenderer.send('RENDERER_ERROR', {
				message: String(error.message || error),
				stack: error.error?.stack || null,
			});
		} catch (err) {
			console.error('Falha ao enviar RENDERER_ERROR', err);
		}
	},

	// ðŸ“¸ NOVO: Screenshot functions
	captureScreenshot,
	analyzeScreenshots,
	clearScreenshots,
	getScreenshotCount: () => appState.audio.capturedScreenshots.length,

	// ðŸ“¸ NOVO: Screenshot shortcuts
	onCaptureScreenshot: callback => {
		ipcRenderer.on('CMD_CAPTURE_SCREENSHOT', callback);
	},
	onAnalyzeScreenshots: callback => {
		ipcRenderer.on('CMD_ANALYZE_SCREENSHOTS', callback);
	},
	// Navegacao de perguntas (Ctrl+Shift+ArrowUp/Down via globalShortcut)
	onNavigateQuestions: callback => {
		ipcRenderer.on('CMD_NAVIGATE_QUESTIONS', (_, direction) => {
			callback(direction);
		});
	},
};

if (typeof module !== 'undefined' && module.exports) {
	// Node.js / CommonJS export
	module.exports = RendererAPI;
}

// ðŸŽ­ Exporta para o escopo global (usado em mocks e testes)
if (typeof globalThis !== 'undefined') {
	globalThis.RendererAPI = RendererAPI; // ðŸŽ­ Exporta API para escopo global
	globalThis.runMockAutoPlay = () => mockRunner.runMockAutoPlay(); // ðŸŽ­ Exportar Mock autoplay (via mock-runner)
}

/* ================================ */
//	LISTENER DO BOTÃƒO RESET
/* ================================ */

/**
 * Adiciona listener ao botÃ£o de reset apÃ³s o DOM carregar

 * docListener do botÃ£o de reset
 * MOVIDO PARA: config-manager.js (initEventListeners)
 * @deprecated Registrado em config-manager.js
 */
