/* ===============================
   IMPORTS
=============================== */
const { ipcRenderer } = require('electron');
const { marked } = require('marked');
const hljs = require('highlight.js');

/* ===============================
   CONSTANTES
=============================== */

const YOU = 'Voc√™';
const OTHER = 'Outros';

const ENABLE_INTERVIEW_TIMING_DEBUG = true; // ‚Üê desligar depois = false
const QUESTION_IDLE_TIMEOUT = 300; // reduzido para diminuir lat√™ncia percebida
const CURRENT_QUESTION_ID = 'CURRENT';

const INPUT_SPEECH_THRESHOLD = 20; //
const INPUT_SILENCE_TIMEOUT = 100; // 1600 300
const MIN_INPUT_AUDIO_SIZE = 1000; // normal 1000
const MIN_INPUT_AUDIO_SIZE_INTERVIEW = 350; // 350

const OUTPUT_SPEECH_THRESHOLD = 8; // detecta fala mais cedo 8
const OUTPUT_SILENCE_TIMEOUT = 250; // menos espera no fim 250
const MIN_OUTPUT_AUDIO_SIZE = 2500; // normal 2500
const MIN_OUTPUT_AUDIO_SIZE_INTERVIEW = 400; // reduzido para detectar perguntas mais cedo

const OUTPUT_ENDING_PHRASES = ['tchau', 'tchau tchau', 'obrigado', 'valeu', 'falou', 'beleza', 'ok'];

const SYSTEM_PROMPT = `
Voc√™ √© um assistente para entrevistas t√©cnicas de Java. Responda como candidato.
Regras de resposta (priorize sempre estas):
- Seja natural e conciso: responda em no m√°ximo 1‚Äì2 frases curtas.
- Use linguagem coloquial e direta, como algu√©m explicando rapidamente verbalmente.
- Evite listas longas, exemplos extensos ou par√°grafos detalhados.
- N√£o comece com cumprimentos ou palavras de preenchimento (ex.: "Claro", "Ok").
- Quando necess√°rio, entregue um exemplo m√≠nimo de 1 linha apenas.
`;

/* ===============================
   ESTADO GLOBAL
=============================== */

let APP_CONFIG = {
	MODE_DEBUG: false,
};

// ü™ü Estado do Drag and Drop da janela
let isDraggingWindow = false;

let isRunning = false;
let audioContext;
let mockInterviewRunning = false;

/* üé§ INPUT (VOC√ä) */
let inputStream;
let inputAnalyser;
let inputData;
let inputRecorder;
let inputChunks = [];
let inputSpeaking = false;
let inputSilenceTimer = null;
let inputPartialChunks = [];
let inputPartialTimer = null;

/* üîä OUTPUT (OUTROS) */
let outputStream;
let outputAnalyser;
let outputData;
let outputRecorder;
let outputChunks = [];
let outputSpeaking = false;
let outputSilenceTimer = null;
let outputPartialChunks = [];
let outputPartialTimer = null;
let outputPartialText = '';

// üî• NOVO: IDs para rastrear e parar os loops de animation
let inputVolumeAnimationId = null;
let outputVolumeAnimationId = null;

/* üß† PERGUNTAS */
let currentQuestion = { text: '', lastUpdate: 0, finalized: false };
let questionsHistory = [];
let selectedQuestionId = null;
let interviewTurnId = 0;
let gptAnsweredTurnId = null;
let gptRequestedTurnId = null;
let lastSentQuestionText = '';
let autoCloseQuestionTimer = null;
let lastInputStartAt = null;
let lastInputStopAt = null;
let lastOutputStartAt = null;
let lastOutputStopAt = null;
let lastInputPlaceholderEl = null;
let lastOutputPlaceholderEl = null;

/* ===============================
   CALLBACKS / OBSERVERS SYSTEM
   renderer.js √© "cego" para DOM
   config-manager.js se inscreve em mudan√ßas
=============================== */

const UICallbacks = {
	onError: null, // üî• NOVO: Para mostrar erros de valida√ß√£o
	onTranscriptAdd: null,
	onCurrentQuestionUpdate: null,
	onQuestionsHistoryUpdate: null,
	onAnswerAdd: null,
	onStatusUpdate: null,
	onInputVolumeUpdate: null,
	onOutputVolumeUpdate: null,
	onMockBadgeUpdate: null,
	onDOMElementsReady: null, // callback para pedir elementos ao config-manager
	onListenButtonToggle: null,
	onAnswerSelected: null,
	onClearAllSelections: null,
	onScrollToQuestion: null,
	onTranscriptionCleared: null,
	onAnswersCleared: null,
	onAnswerStreamChunk: null,
	onModeSelectUpdate: null,
	onPlaceholderFulfill: null,
};

// Fun√ß√£o para config-manager se inscrever em eventos
function onUIChange(eventName, callback) {
	if (UICallbacks.hasOwnProperty(eventName)) {
		UICallbacks[eventName] = callback;
		console.log(`üì° UI callback registrado: ${eventName}`);
	}
}

// Dispara um callback com dados
function emitUIChange(eventName, data) {
	//console.log(`üì° DEBUG: emitUIChange('${eventName}', ${typeof data === 'object' ? JSON.stringify(data) : data})`);
	if (UICallbacks[eventName] && typeof UICallbacks[eventName] === 'function') {
		//console.log(`‚úÖ DEBUG: Callback encontrado para '${eventName}', disparando...`);
		UICallbacks[eventName](data);
	} else {
		console.warn(`‚ö†Ô∏è DEBUG: Nenhum callback registrado para '${eventName}'`);
	}
}

/* ===============================
   ELEMENTOS UI - Solicitado por callback
   (config-manager.js fornece esses elementos)
=============================== */

let UIElements = {
	inputSelect: null,
	outputSelect: null,
	listenBtn: null,
	statusText: null,
	transcriptionBox: null, // Mantido para compatibilidade, mas pode receber 'conversation'
	currentQuestionBox: null,
	currentQuestionTextBox: null,
	questionsHistoryBox: null,
	answersHistoryBox: null,
	askBtn: null,
	inputVu: null,
	outputVu: null,
	mockToggle: null,
	mockBadge: null,
	interviewModeSelect: null,
	btnClose: null,
	btnToggleClick: null,
	dragHandle: null,
	darkToggle: null,
	opacitySlider: null,
};

// config-manager.js chama isso para registrar elementos
function registerUIElements(elements) {
	UIElements = { ...UIElements, ...elements };
	console.log('‚úÖ UI Elements registrados no renderer');
}

/* ===============================
   MODO / ORQUESTRADOR
=============================== */

const MODES = {
	NORMAL: 'NORMAL',
	INTERVIEW: 'INTERVIEW',
};

// üîÑ modo atual (default = comportamento atual)
let CURRENT_MODE = MODES.NORMAL;

// üéº controlador central de estrat√©gia
const ModeController = {
	isInterviewMode() {
		return CURRENT_MODE === MODES.INTERVIEW;
	},

	isInterview() {
		return CURRENT_MODE === MODES.INTERVIEW;
	},

	// ‚è±Ô∏è MediaRecorder.start(timeslice)
	mediaRecorderTimeslice() {
		if (!this.isInterview()) return null;

		// OUTPUT pode ser mais agressivo que INPUT
		return 60; // reduzido para janelas parciais mais responsivas
	},

	// üéß transcri√ß√£o incremental
	allowPartialTranscription() {
		return this.isInterview();
	},

	// ü§ñ GPT streaming
	allowGptStreaming() {
		return this.isInterview();
	},

	// üì¶ tamanho m√≠nimo de √°udio aceito
	minInputAudioSize(defaultSize) {
		return this.isInterview() ? Math.min(400, defaultSize) : defaultSize;
	},
};

/* ===============================
   HELPERS PUROS
=============================== */

function finalizeQuestion(t) {
	return t.trim().endsWith('?') ? t.trim() : t.trim() + '?';
}

function normalizeForCompare(t) {
	return (t || '')
		.toLowerCase()
		.replace(/[?!.\n\r]/g, '')
		.replace(/\s+/g, ' ')
		.trim();
}

function looksLikeQuestion(t) {
	const s = t.toLowerCase().trim();

	// precisa ter ? OU come√ßar com palavra t√≠pica de pergunta
	const questionStarters = [
		'o que',
		'por que',
		'porque',
		'como',
		'qual',
		'quais',
		'quando',
		'onde',
		'fale',
		'me fale',
		'me explica',
		'me explique',
		'me diga',
		'diga',
		'voc√™',
		'explique',
		'descreva',
		'j√°',
		'tu j√°',
	];

	return s.includes('?') || questionStarters.some(q => s.startsWith(q));
}

function isGarbageSentence(t) {
	const s = t.toLowerCase();
	return ['obrigado', 'at√© a pr√≥xima', 'finalizando'].some(w => s.includes(w));
}

// Encurta uma resposta em markdown para at√© `maxSentences` senten√ßas.
function shortenAnswer(markdownText, maxSentences = 2) {
	if (!markdownText) return markdownText;

	// remove blocos de c√≥digo temporariamente para evitar cortes ruins
	const codeBlocks = [];
	const withoutCode = markdownText.replace(/```[\s\S]*?```/g, match => {
		codeBlocks.push(match);
		return `__CODEBLOCK_${codeBlocks.length - 1}__`;
	});

	// remove inline code
	const tmp = withoutCode.replace(/`([^`]*)`/g, '$1');

	// extrai senten√ßas por pontua√ß√£o final
	const parts = tmp.split(/(?<=[\.\?!])\s+/);

	const take = parts.slice(0, maxSentences).join(' ').trim();

	// restaura blocos de c√≥digo, caso existam (apendados ao final)
	let result = take;
	if (codeBlocks.length) {
		result += '\n\n' + codeBlocks.join('\n\n');
	}

	// garante pontua√ß√£o final
	if (!/[\.\?!]$/.test(result)) result = result + '.';

	return result;
}

function isIncompleteQuestion(t) {
	if (!t) return false;
	const s = t.trim();
	// casos √≥bvios: cont√©m retic√™ncias (..., ‚Ä¶) ‚Äî normalmente placeholders ou cortes
	if (s.includes('...') || s.includes('‚Ä¶')) return true;

	// termina com fragmento muito curto seguido de pontua√ß√£o (ex: "O que √© a...")
	// ou termina com apenas 1-3 letras antes do fim (sinal de corte)
	if (/\b\w{1,3}[\.]{0,3}$/.test(s) && /\.\.{1,3}$/.test(s)) return true;

	// termina com palavra muito curta e sem contexto (ex: endsWith ' a' )
	if (/\b[a-z]{1,2}$/.test(s.toLowerCase())) return true;

	return false;
}

function getNavigableQuestionIds() {
	const ids = [];

	// CURRENT s√≥ entra se tiver texto
	if (currentQuestion.text && currentQuestion.text.trim().length > 0) {
		ids.push(CURRENT_QUESTION_ID);
	}

	// Hist√≥rico (mais recente primeiro)
	ids.push(
		...questionsHistory
			.slice()
			.reverse()
			.map(q => q.id),
	);

	return ids;
}

function findAnswerByQuestionId(questionId) {
	// Rastreia respostas internamente (n√£o acessa DOM)
	// Mant√©m um mapa de questionId -> answerData
	// Por enquanto, retorna null se n√£o encontrado
	return null;
}

function promoteCurrentToHistory(text) {
	console.log('üìö promovendo pergunta para hist√≥rico:', text);

	// evita duplica√ß√£o no hist√≥rico: se a √∫ltima entrada √© igual (normalizada), n√£o adiciona
	const last = questionsHistory.length ? questionsHistory[questionsHistory.length - 1] : null;
	if (last && normalizeForCompare(last.text) === normalizeForCompare(text)) {
		console.log('üîï pergunta igual j√° presente no hist√≥rico ‚Äî pulando promo√ß√£o');

		// limpa CURRENT mas preserva sele√ß√£o conforme antes
		const prevSelected = selectedQuestionId;
		currentQuestion = { text: '', lastUpdate: 0, finalized: false };
		if (prevSelected === null || prevSelected === CURRENT_QUESTION_ID) {
			selectedQuestionId = CURRENT_QUESTION_ID;
		} else {
			selectedQuestionId = prevSelected;
		}

		renderQuestionsHistory();
		renderCurrentQuestion();
		return;
	}

	const newId = crypto.randomUUID();

	questionsHistory.push({
		id: newId,
		text,
		createdAt: currentQuestion.createdAt || Date.now(),
	});

	// preserva sele√ß√£o do usu√°rio: se n√£o havia sele√ß√£o expl√≠cita ou estava no CURRENT,
	// mant√©m a sele√ß√£o no CURRENT para que o novo CURRENT seja principal.
	const prevSelected = selectedQuestionId;

	currentQuestion = { text: '', lastUpdate: 0, finalized: false };

	if (prevSelected === null || prevSelected === CURRENT_QUESTION_ID) {
		selectedQuestionId = CURRENT_QUESTION_ID;
	} else {
		// usu√°rio tinha selecionado algo no hist√≥rico ‚Äî preserva essa sele√ß√£o
		selectedQuestionId = prevSelected;
	}

	renderQuestionsHistory();
	renderCurrentQuestion();
}

function isQuestionReady(text) {
	if (!ModeController.isInterviewMode()) return true;

	const trimmed = text.trim();

	// üî• entrevistas podem ter perguntas curtas ("O que √© POO")
	if (trimmed.length < 10) return false;

	// ignora despedidas
	if (isEndingPhrase(trimmed)) return false;

	// heur√≠stica simples de pergunta
	const questionIndicators = [
		'o que',
		'por que',
		'porque',
		'como',
		'qual',
		'quais',
		'quando',
		'onde',
		'fale',
		'me fale',
		'me explica',
		'me explique',
		'me diga',
		'diga',
		'voc√™',
		'explique',
		'descreva',
		'j√°',
		'tu j√°',
	];

	const lower = trimmed.toLowerCase();

	const hasIndicator = questionIndicators.some(q => lower.includes(q));

	const hasQuestionMark = trimmed.includes('?');

	// s√≥ dispara se houver ind√≠cio real
	return hasIndicator || hasQuestionMark;
}

function resetInterviewRuntimeState() {
	outputPartialChunks = [];
	outputPartialText = '';

	if (outputPartialTimer) {
		clearTimeout(outputPartialTimer);
		outputPartialTimer = null;
	}

	console.log('‚ôªÔ∏è Estado do modo entrevista resetado');
}

function isEndingPhrase(text) {
	const normalized = text.toLowerCase().trim();
	return OUTPUT_ENDING_PHRASES.some(p => normalized === p);
}

/* ===============================
   DISPOSITIVOS / CONTROLE DE √ÅUDIO
=============================== */

async function startAudio() {
	if (!UIElements.inputSelect?.value && !UIElements.outputSelect?.value) {
		updateStatusMessage('Status: selecione um dispositivo');
		return;
	}

	audioContext = new AudioContext();

	if (UIElements.inputSelect?.value) await startInput();
	if (UIElements.outputSelect?.value) await startOutput();
}

async function stopAudio() {
	if (currentQuestion.text) closeCurrentQuestionForced();

	inputRecorder?.state === 'recording' && inputRecorder.stop();
	outputRecorder?.state === 'recording' && outputRecorder.stop();
}

async function restartAudioPipeline() {
	stopAudio();
	stopInputMonitor();
	stopOutputMonitor();

	// üî• reinicia pipeline, mas N√ÉO liga escuta
	if (UIElements.inputSelect?.value || UIElements.outputSelect?.value) {
		await startAudio();
	}
}

/* ===============================
   AUDIO - INPUT (VOC√ä)
=============================== */

// üî• NOVO: Inicia apenas monitoramento de volume (sem gravar)
async function startInputVolumeMonitoring() {
	if (APP_CONFIG.MODE_DEBUG) {
		console.log('üé§ Monitoramento de volume entrada (modo teste)...');
		return Promise.resolve();
	}

	if (!UIElements.inputSelect?.value) {
		console.log('‚ö†Ô∏è Nenhum dispositivo input selecionado');
		return Promise.resolve();
	}

	// üî• NOVO: Se j√° tem stream ativa, n√£o faz nada
	if (inputStream && inputAnalyser) {
		console.log('‚ÑπÔ∏è Monitoramento de volume entrada j√° ativo');
		return Promise.resolve();
	}

	if (!audioContext) {
		audioContext = new AudioContext();
	}

	try {
				console.log('üîÑ Iniciando stream de √°udio (input)...');
		inputStream = await navigator.mediaDevices.getUserMedia({
			audio: { deviceId: { exact: UIElements.inputSelect.value } },
		});

		const source = audioContext.createMediaStreamSource(inputStream);

		inputAnalyser = audioContext.createAnalyser();
		inputAnalyser.fftSize = 256;
		inputData = new Uint8Array(inputAnalyser.frequencyBinCount);
		source.connect(inputAnalyser);

		console.log('‚úÖ Monitoramento de volume de entrada iniciado com sucesso');
		updateInputVolume(); // üî• Inicia o loop de atualiza√ß√£o
	} catch (error) {
		console.error('‚ùå Erro ao iniciar monitoramento de volume de entrada:', error);
		inputStream = null;
		inputAnalyser = null;
	}
}

// üî• NOVO: Inicia apenas monitoramento de volume para output (sem gravar)
async function startOutputVolumeMonitoring() {
	if (APP_CONFIG.MODE_DEBUG) {
		console.log('üîä Monitoramento de volume sa√≠da (modo teste)...');
		return Promise.resolve();
	}

	if (!UIElements.outputSelect?.value) {
		console.log('‚ö†Ô∏è Nenhum dispositivo output selecionado');
		return Promise.resolve();
	}

	// üî• NOVO: Se j√° tem stream ativa, n√£o faz nada
	if (outputStream && outputAnalyser) {
		console.log('‚ÑπÔ∏è Monitoramento de volume sa√≠da j√° ativo');
		return Promise.resolve();
	}

	if (!audioContext) {
		audioContext = new AudioContext();
	}

			console.log('üîÑ Iniciando stream de √°udio (output)...');
	try {
		outputStream = await navigator.mediaDevices.getUserMedia({
			audio: { deviceId: { exact: UIElements.outputSelect.value } },
		});

		const source = audioContext.createMediaStreamSource(outputStream);

		outputAnalyser = audioContext.createAnalyser();
		outputAnalyser.fftSize = 256;
		outputData = new Uint8Array(outputAnalyser.frequencyBinCount);
		source.connect(outputAnalyser);

		console.log('‚úÖ Monitoramento de volume de sa√≠da iniciado com sucesso');
		updateOutputVolume(); // üî• Inicia o loop de atualiza√ß√£o
	} catch (error) {
		console.error('‚ùå Erro ao iniciar monitoramento de volume de sa√≠da:', error);
		outputStream = null;
		outputAnalyser = null;
	}
}

/* ===============================
   AUDIO - INPUT (VOC√ä)
=============================== */

async function startInput() {
    if (APP_CONFIG.MODE_DEBUG) {
        const text = 'Iniciando monitoramento de entrada de √°udio (modo teste)...';
        addTranscript('Voc√™', text);
        return;
    }

    if (!UIElements.inputSelect?.value) return;

    if (!audioContext) {
        audioContext = new AudioContext();
    }

    // CR√çTICO: Evita recriar recorder E stream se j√° existem
    if (inputRecorder && inputRecorder.state !== 'inactive') {
        console.log('‚ÑπÔ∏è inputRecorder j√° existe e est√° ativo, pulando reconfigura√ß√£o');
        return;
    }

    // Se j√° existe stream mas precisa reconfigurar, limpa primeiro
    if (inputStream) {
        console.log('üßπ Limpando stream de entrada anterior antes de recriar');
        inputStream.getTracks().forEach(t => t.stop());
        inputStream = null;
    }

    try {
        inputStream = await navigator.mediaDevices.getUserMedia({
            audio: { deviceId: { exact: UIElements.inputSelect.value } },
        });

        const source = audioContext.createMediaStreamSource(inputStream);

        inputAnalyser = audioContext.createAnalyser();
        inputAnalyser.fftSize = 256;
        inputData = new Uint8Array(inputAnalyser.frequencyBinCount);
        source.connect(inputAnalyser);

        // recorder SEMPRE existe
        inputRecorder = new MediaRecorder(inputStream, {
            mimeType: 'audio/webm;codecs=opus',
        });

        inputRecorder.ondataavailable = e => {
            console.log('üî• input.ondataavailable - chunk tamanho:', e.data?.size || e.data?.byteLength || 'n/a');

            inputChunks.push(e.data);

            // MODO ENTREVISTA ‚Äì gancho futuro (ainda inativo)
            if (ModeController.allowPartialTranscription()) {
                console.log('üß© handlePartialInputChunk chamado (input)');
                handlePartialInputChunk(e.data);
            }
        };
        
        inputRecorder.onstop = () => {
            console.log('‚èπÔ∏è inputRecorder.onstop chamado');

            // marca o momento exato em que a grava√ß√£o parou
            lastInputStopAt = Date.now();
            console.log('‚è±Ô∏è input stopped at', new Date(lastInputStopAt).toLocaleTimeString());

            // adiciona placeholder visual para indicar que estamos aguardando a transcri√ß√£o
            // usa startAt se dispon√≠vel para mostrar o hor√°rio inicial enquanto aguarda
            const timeForPlaceholder = lastInputStartAt || lastInputStopAt;
            lastInputPlaceholderEl = addTranscript(YOU, '...', timeForPlaceholder);
            if (lastInputPlaceholderEl) {
                lastInputPlaceholderEl.dataset.stopAt = lastInputStopAt;
                if (lastInputStartAt) lastInputPlaceholderEl.dataset.startAt = lastInputStartAt;
            }

            transcribeInput();
        };

        // Inicia loop de volume apenas se n√£o estiver rodando
        if (!inputVolumeAnimationId) {
            updateInputVolume();
        }
        
        console.log('‚úÖ startInput: Configurado com sucesso');
    } catch (error) {
        console.error('‚ùå Erro em startInput:', error);
        inputStream = null;
        inputRecorder = null;
        throw error;
    }
}

function updateInputVolume() {
    // CR√çTICO: Verifica se deve continuar ANTES de fazer qualquer processamento
    if (!inputAnalyser || !inputData) {
        console.log('‚ö†Ô∏è updateInputVolume: analyser ou data n√£o dispon√≠vel, parando loop');
        if (inputVolumeAnimationId) {
            cancelAnimationFrame(inputVolumeAnimationId);
            inputVolumeAnimationId = null;
        }
        emitUIChange('onInputVolumeUpdate', { percent: 0 });
        return;
    }

    try {
        inputAnalyser.getByteFrequencyData(inputData);
        const avg = inputData.reduce((a, b) => a + b, 0) / inputData.length;
        const percent = Math.min(100, Math.round((avg / 80) * 100));

        // Emite evento em vez de atualizar DOM diretamente
        emitUIChange('onInputVolumeUpdate', { percent });

        if (avg > INPUT_SPEECH_THRESHOLD && inputRecorder && isRunning) {
            if (!inputSpeaking) {
                inputSpeaking = true;
                inputChunks = [];

                const slice = ModeController.mediaRecorderTimeslice();
                lastInputStartAt = Date.now();
                console.log(
                    'üéôÔ∏è iniciando grava√ß√£o de entrada (inputRecorder.start) - startAt',
                    new Date(lastInputStartAt).toLocaleTimeString(),
                );
                slice ? inputRecorder.start(slice) : inputRecorder.start();
            }
            if (inputSilenceTimer) {
                clearTimeout(inputSilenceTimer);
                inputSilenceTimer = null;
            }
        } else if (inputSpeaking && !inputSilenceTimer && inputRecorder) {
            inputSilenceTimer = setTimeout(() => {
                inputSpeaking = false;
                inputSilenceTimer = null;
                console.log('‚èπÔ∏è parando grava√ß√£o de entrada por sil√™ncio (inputRecorder.stop)');
                if (inputRecorder && inputRecorder.state === 'recording') {
                    inputRecorder.stop();
                }
            }, INPUT_SILENCE_TIMEOUT);
        }
    } catch (error) {
        console.error('‚ùå Erro em updateInputVolume:', error);
        if (inputVolumeAnimationId) {
            cancelAnimationFrame(inputVolumeAnimationId);
            inputVolumeAnimationId = null;
        }
        emitUIChange('onInputVolumeUpdate', { percent: 0 });
        return;
    }

    // Continua o loop apenas se tudo estiver OK
    inputVolumeAnimationId = requestAnimationFrame(updateInputVolume);
}

function stopInputMonitor() {
    console.log('üõë stopInputMonitor: Parando monitoramento de entrada...');
    
    // 1. Para o loop de animation PRIMEIRO
    if (inputVolumeAnimationId) {
        cancelAnimationFrame(inputVolumeAnimationId);
        inputVolumeAnimationId = null;
        console.log('‚úÖ Loop de anima√ß√£o de entrada cancelado');
    }

    // 2. Para o recorder se estiver gravando
    if (inputRecorder) {
        if (inputRecorder.state === 'recording') {
            console.log('‚èπÔ∏è Parando recorder de entrada...');
            inputRecorder.stop();
        }
        inputRecorder = null;
    }

    // 3. Fecha a stream
    if (inputStream) {
        inputStream.getTracks().forEach(t => {
            t.stop();
            console.log('‚úÖ Track de entrada parada:', t.label);
        });
        inputStream = null;
    }

    // 4. Limpa analyser e dados
    inputAnalyser = null;
    inputData = null;
    
    // 5. Reseta estado
    inputSpeaking = false;
    if (inputSilenceTimer) {
        clearTimeout(inputSilenceTimer);
        inputSilenceTimer = null;
    }
    
    // 6. Atualiza UI
    emitUIChange('onInputVolumeUpdate', { percent: 0 });
    
    console.log('‚úÖ stopInputMonitor: Conclu√≠do');
    return Promise.resolve();
}

/* ===============================
   AUDIO - OUTPUT (OUTROS) - VIA VOICEMEETER
=============================== */

async function startOutput() {
    if (APP_CONFIG.MODE_DEBUG) {
        const text = 'Iniciando monitoramento de sa√≠da de √°udio (modo teste)...';
        addTranscript('Outros', text);
        return;
    }

    if (!UIElements.outputSelect?.value) return;

    if (!audioContext) {
        audioContext = new AudioContext();
    }

    // CR√çTICO: Evita recriar recorder E stream se j√° existem
    if (outputRecorder && outputRecorder.state !== 'inactive') {
        console.log('‚ÑπÔ∏è outputRecorder j√° existe e est√° ativo, pulando reconfigura√ß√£o');
        return;
    }

    // Se j√° existe stream mas precisa reconfigurar, limpa primeiro
    if (outputStream) {
        console.log('üßπ Limpando stream de sa√≠da anterior antes de recriar');
        outputStream.getTracks().forEach(t => t.stop());
        outputStream = null;
    }

    try {
        outputStream = await navigator.mediaDevices.getUserMedia({
            audio: { deviceId: { exact: UIElements.outputSelect.value } },
        });

        const source = audioContext.createMediaStreamSource(outputStream);

        outputAnalyser = audioContext.createAnalyser();
        outputAnalyser.fftSize = 256;
        outputData = new Uint8Array(outputAnalyser.frequencyBinCount);
        source.connect(outputAnalyser);

        // recorder SEMPRE existe
        outputRecorder = new MediaRecorder(outputStream, {
            mimeType: 'audio/webm;codecs=opus',
        });

        outputRecorder.ondataavailable = e => {
            console.log('üî• output.ondataavailable - chunk tamanho:', e.data?.size || e.data?.byteLength || 'n/a');

            outputChunks.push(e.data);

            // MODO ENTREVISTA ‚Äì gancho futuro para OUTPUT
            if (ModeController.allowPartialTranscription()) {
                console.log('üß© handlePartialOutputChunk chamado (output)');
                handlePartialOutputChunk(e.data);
            }
        };

        outputRecorder.onstop = () => {
            console.log('‚èπÔ∏è outputRecorder.onstop chamado');

            // marca o momento exato em que a grava√ß√£o parou
            lastOutputStopAt = Date.now();
            console.log('‚è±Ô∏è output stopped at', new Date(lastOutputStopAt).toLocaleTimeString());

            // placeholder para mostrar que estamos aguardando transcri√ß√£o
            const timeForPlaceholder = lastOutputStartAt || lastOutputStopAt;
            lastOutputPlaceholderEl = addTranscript(OTHER, '...', timeForPlaceholder);
            if (lastOutputPlaceholderEl) {
                lastOutputPlaceholderEl.dataset.stopAt = lastOutputStopAt;
                if (lastOutputStartAt) lastOutputPlaceholderEl.dataset.startAt = lastOutputStartAt;
            }

            transcribeOutput();
        };

        // Inicia loop de volume apenas se n√£o estiver rodando
        if (!outputVolumeAnimationId) {
            updateOutputVolume();
        }
        
        console.log('‚úÖ startOutput: Configurado com sucesso');
    } catch (error) {
        console.error('‚ùå Erro em startOutput:', error);
        outputStream = null;
        outputRecorder = null;
        throw error;
    }
}

function updateOutputVolume() {
    // CR√çTICO: Verifica se deve continuar ANTES de fazer qualquer processamento
    if (!outputAnalyser || !outputData) {
        console.log('‚ö†Ô∏è updateOutputVolume: analyser ou data n√£o dispon√≠vel, parando loop');
        if (outputVolumeAnimationId) {
            cancelAnimationFrame(outputVolumeAnimationId);
            outputVolumeAnimationId = null;
        }
        emitUIChange('onOutputVolumeUpdate', { percent: 0 });
        return;
    }

    try {
        outputAnalyser.getByteFrequencyData(outputData);
        const avg = outputData.reduce((a, b) => a + b, 0) / outputData.length;
        const percent = Math.min(100, Math.round((avg / 60) * 100));

        // Emite evento em vez de atualizar DOM diretamente
        emitUIChange('onOutputVolumeUpdate', { percent });

        if (avg > OUTPUT_SPEECH_THRESHOLD && outputRecorder && isRunning) {
            if (!outputSpeaking) {
                outputSpeaking = true;
                outputChunks = [];

                const slice = ModeController.mediaRecorderTimeslice();
                lastOutputStartAt = Date.now();
                console.log(
                    'üìä iniciando grava√ß√£o de sa√≠da (outputRecorder.start) - startAt',
                    new Date(lastOutputStartAt).toLocaleTimeString(),
                );
                slice ? outputRecorder.start(slice) : outputRecorder.start();
            }
            if (outputSilenceTimer) {
                clearTimeout(outputSilenceTimer);
                outputSilenceTimer = null;
            }
        } else if (outputSpeaking && !outputSilenceTimer && outputRecorder) {
            outputSilenceTimer = setTimeout(() => {
                outputSpeaking = false;
                outputSilenceTimer = null;
                console.log('‚èπÔ∏è parando grava√ß√£o de sa√≠da por sil√™ncio (outputRecorder.stop)');
                if (outputRecorder && outputRecorder.state === 'recording') {
                    outputRecorder.stop();
                }
            }, OUTPUT_SILENCE_TIMEOUT);
        }
    } catch (error) {
        console.error('‚ùå Erro em updateOutputVolume:', error);
        if (outputVolumeAnimationId) {
            cancelAnimationFrame(outputVolumeAnimationId);
            outputVolumeAnimationId = null;
        }
        emitUIChange('onOutputVolumeUpdate', { percent: 0 });
        return;
    }

    // Continua o loop apenas se tudo estiver OK
    outputVolumeAnimationId = requestAnimationFrame(updateOutputVolume);
}

function stopOutputMonitor() {
    console.log('üõë stopOutputMonitor: Parando monitoramento de sa√≠da...');
    
    // 1. Para o loop de animation PRIMEIRO
    if (outputVolumeAnimationId) {
        cancelAnimationFrame(outputVolumeAnimationId);
        outputVolumeAnimationId = null;
        console.log('‚úÖ Loop de anima√ß√£o de sa√≠da cancelado');
    }

    // 2. Para o recorder se estiver gravando
    if (outputRecorder) {
        if (outputRecorder.state === 'recording') {
            console.log('‚èπÔ∏è Parando recorder de sa√≠da...');
            outputRecorder.stop();
        }
        outputRecorder = null;
    }

    // 3. Fecha a stream
    if (outputStream) {
        outputStream.getTracks().forEach(t => {
            t.stop();
            console.log('‚úÖ Track de sa√≠da parada:', t.label);
        });
        outputStream = null;
    }

    // 4. Limpa analyser e dados
    outputAnalyser = null;
    outputData = null;
    
    // 5. Reseta estado
    outputSpeaking = false;
    if (outputSilenceTimer) {
        clearTimeout(outputSilenceTimer);
        outputSilenceTimer = null;
    }
    
    // 6. Atualiza UI
    emitUIChange('onOutputVolumeUpdate', { percent: 0 });
    
    console.log('‚úÖ stopOutputMonitor: Conclu√≠do');
    return Promise.resolve();
}

/* ===============================
   MODO ENTREVISTA - GANCHO INPUT
=============================== */

async function handlePartialInputChunk(blobChunk) {
	if (!ModeController.isInterviewMode()) return;

	// ignora ru√≠do
	if (blobChunk.size < 200) return;

	inputPartialChunks.push(blobChunk);

	if (inputPartialTimer) clearTimeout(inputPartialTimer);

	inputPartialTimer = setTimeout(async () => {
		if (!inputPartialChunks.length) return;

		const blob = new Blob(inputPartialChunks, { type: 'audio/webm' });
		inputPartialChunks = [];

		try {
			const buffer = Buffer.from(await blob.arrayBuffer());
			const partialText = (await ipcRenderer.invoke('transcribe-audio-partial', buffer))?.trim();

			if (partialText && !isGarbageSentence(partialText)) {
				addTranscript(YOU, partialText);
				handleSpeech(YOU, partialText);
			}
		} catch (err) {
			console.warn('‚ö†Ô∏è erro na transcri√ß√£o parcial (INPUT)', err);
		}
	}, 180); // janela curta (reduzida de 250 -> 180)
}

/* ===============================
   MODO ENTREVISTA - GANHO REAL OUTPUT
=============================== */

function handlePartialOutputChunk(blobChunk) {
	if (!ModeController.isInterviewMode()) return;

	// evita blobs pequenos demais (sem header v√°lido)
	if (blobChunk.size < 800) return;

	outputPartialChunks.push(blobChunk);

	if (outputPartialTimer) clearTimeout(outputPartialTimer);

	outputPartialTimer = setTimeout(async () => {
		if (!outputPartialChunks.length) return;

		const blob = new Blob(outputPartialChunks, { type: 'audio/webm' });
		outputPartialChunks = [];

		try {
			const partialText = await transcribeOutputPartial(blob);

			if (partialText && !isGarbageSentence(partialText)) {
				outputPartialText += ' ' + partialText;

				// üî• dispara GPT mais cedo
				if (ModeController.isInterviewMode() && isQuestionReady(outputPartialText)) {
					const newText = outputPartialText.trim();

					// evita reprocessar a mesma pergunta
					if (newText === currentQuestion.text) {
						console.log('üîÅ ignorando nova transcri√ß√£o igual √† currentQuestion');
						return;
					}

					// marca in√≠cio real do turno se ainda n√£o marcado
					if (!currentQuestion.text) {
						currentQuestion.createdAt = Date.now();
						interviewTurnId++; // novo turno detectado
					}

					currentQuestion.text = newText;
					currentQuestion.lastUpdate = Date.now();
					currentQuestion.finalized = false;

					selectedQuestionId = CURRENT_QUESTION_ID;
					renderCurrentQuestion();

					// log temporario para testar a aplica√ß√£o s√≥ remover depois
					console.log('üß† currentQuestion (parcial):', currentQuestion.text);
					console.log('üéØ interviewTurnId:', interviewTurnId);
					console.log('ü§ñ gptAnsweredTurnId:', gptAnsweredTurnId);
					console.log('üß™ temporizador de auto-fechamento definido; chamar√° closeCurrentQuestion se necess√°rio');

					// ‚è±Ô∏è agenda fechamento autom√°tico da pergunta
					if (autoCloseQuestionTimer) {
						clearTimeout(autoCloseQuestionTimer);
					}

					autoCloseQuestionTimer = setTimeout(() => {
						console.log('‚è±Ô∏è Auto close question disparado');

						if (
							ModeController.isInterviewMode() &&
							currentQuestion.text &&
							!currentQuestion.finalized &&
							gptAnsweredTurnId !== interviewTurnId
						) {
							closeCurrentQuestion();
						}
					}, QUESTION_IDLE_TIMEOUT);

					//askGpt(); // GPT streaming
				}
			}
		} catch (err) {
			console.warn('‚ö†Ô∏è erro na transcri√ß√£o parcial (OUTPUT)', err);
		}
	}, 120); // üî• janela menor (reduzida de 180 -> 120)
}

/* ===============================
   MODO ENTREVISTA - STT PARCIAL OUTPUT
=============================== */

async function transcribeOutputPartial(blob) {
	const tBlobToBuffer = Date.now();
	const buffer = Buffer.from(await blob.arrayBuffer());
	console.log('timing (partial): bufferConv', Date.now() - tBlobToBuffer, 'ms, size', buffer.length);

	const tSend = Date.now();
	const partial = (await ipcRenderer.invoke('transcribe-audio-partial', buffer))?.trim();
	console.log('timing (partial): ipc_stt_roundtrip', Date.now() - tSend, 'ms');

	console.log('üìù transcri√ß√£o parcial de sa√≠da ->', partial);
	return partial;
}

/* ===============================
   TRANSCRI√á√ÉO
=============================== */

async function transcribeInput() {
	if (!inputChunks.length) return;

	const blob = new Blob(inputChunks, { type: 'audio/webm' });
	console.log('üîÅ transcrever entrada - blob.size:', blob.size); // diagn√≥stico

	// ignora ru√≠do / respira√ß√£o
	const minSize = ModeController.isInterviewMode() ? MIN_INPUT_AUDIO_SIZE_INTERVIEW : MIN_INPUT_AUDIO_SIZE;

	if (blob.size < minSize) return;

	inputChunks = [];

	// medir tempo de convers√£o blob -> buffer
	const tBlobToBuffer = Date.now();
	const buffer = Buffer.from(await blob.arrayBuffer());
	console.log('timing: bufferConv', Date.now() - tBlobToBuffer, 'ms, size', buffer.length);

	// medir tempo IPC + STT (roundtrip)
	const tSend = Date.now();
	const text = (await ipcRenderer.invoke('transcribe-audio', buffer))?.trim();
	console.log('timing: ipc_stt_roundtrip', Date.now() - tSend, 'ms');
	if (!text || isGarbageSentence(text)) return;

	// Se existia um placeholder (timestamp do stop), calcula m√©tricas e emite evento para atualizar
	if (lastInputPlaceholderEl && lastInputPlaceholderEl.dataset) {
		const stop = lastInputPlaceholderEl.dataset.stopAt
			? Number(lastInputPlaceholderEl.dataset.stopAt)
			: lastInputStopAt;
		const start = lastInputPlaceholderEl.dataset.startAt
			? Number(lastInputPlaceholderEl.dataset.startAt)
			: lastInputStartAt || stop;
		const now = Date.now();
		const recordingDuration = stop - start;
		const latency = now - stop;
		const total = now - start;
		const startStr = new Date(start).toLocaleTimeString();
		const stopStr = new Date(stop).toLocaleTimeString();

		// Emite para config-manager atualizar o placeholder com texto final e m√©tricas
		emitUIChange('onPlaceholderFulfill', {
			speaker: YOU,
			text,
			stopStr,
			startStr,
			recordingDuration,
			latency,
			total,
		});

		lastInputPlaceholderEl = null;
		lastInputStopAt = null;
		lastInputStartAt = null;
	} else {
		addTranscript(YOU, text);
	}

	handleSpeech(YOU, text);
}

async function transcribeOutput() {
	if (!outputChunks.length) return;

	const blob = new Blob(outputChunks, { type: 'audio/webm' });
	console.log('üîÅ transcrever sa√≠da - blob.size:', blob.size); // diagn√≥stico adicional

	// ignora ru√≠do / respira√ß√£o
	const minSize = ModeController.isInterviewMode() ? MIN_OUTPUT_AUDIO_SIZE_INTERVIEW : MIN_OUTPUT_AUDIO_SIZE;

	if (blob.size < minSize) return;

	outputChunks = [];

	const tBlobToBuffer = Date.now();
	const buffer = Buffer.from(await blob.arrayBuffer());
	console.log('timing: bufferConv (output)', Date.now() - tBlobToBuffer, 'ms, size', buffer.length);

	const tSend = Date.now();
	const text = (await ipcRenderer.invoke('transcribe-audio', buffer))?.trim();
	console.log('timing: ipc_stt_roundtrip (output)', Date.now() - tSend, 'ms');
	if (!text || isGarbageSentence(text)) return;

	// Se existia um placeholder (timestamp do stop), atualiza esse placeholder com o texto final e lat√™ncia
	if (lastOutputPlaceholderEl && lastOutputPlaceholderEl.dataset) {
		const stop = lastOutputPlaceholderEl.dataset.stopAt
			? Number(lastOutputPlaceholderEl.dataset.stopAt)
			: lastOutputStopAt;
		const start = lastOutputPlaceholderEl.dataset.startAt
			? Number(lastOutputPlaceholderEl.dataset.startAt)
			: lastOutputStartAt || stop;
		const now = Date.now();
		const recordingDuration = stop - start;
		const latency = now - stop;
		const total = now - start;
		const startStr = new Date(start).toLocaleTimeString();
		const stopStr = new Date(stop).toLocaleTimeString();

		// Emite para config-manager atualizar o placeholder com texto final e m√©tricas
		emitUIChange('onPlaceholderFulfill', {
			speaker: OTHER,
			text,
			stopStr,
			startStr,
			recordingDuration,
			latency,
			total,
		});

		lastOutputPlaceholderEl = null;
		lastOutputStopAt = null;
		lastOutputStartAt = null;
	} else {
		addTranscript(OTHER, text);
	}

	handleSpeech(OTHER, text);

	// Se a transcri√ß√£o final indicar claramente uma pergunta, fechar e enviar ao GPT imediatamente
	if (ModeController.isInterviewMode() && isQuestionReady(text)) {
		console.log('üîî transcri√ß√£o final parece pergunta ‚Äî fechando e chamando GPT agora');
		// limpa estado parcial e cancela o temporizador autom√°tico para evitar duplicatas
		outputPartialText = '';
		if (autoCloseQuestionTimer) {
			clearTimeout(autoCloseQuestionTimer);
			autoCloseQuestionTimer = null;
		}
		closeCurrentQuestion();
	}
}

/* ===============================
   CONSOLIDA√á√ÉO DE PERGUNTAS
=============================== */

function handleSpeech(author, text) {
	const cleaned = text.replace(/√ä+|hum|ahn/gi, '').trim();
	console.log('üîä handleSpeech', { author, raw: text, cleaned });
	if (cleaned.length < 3) return;

	const now = Date.now();

	if (author === OTHER) {
		// üëâ Se j√° existe uma pergunta finalizada,
		//    significa que uma NOVA pergunta come√ßou
		if (currentQuestion.finalized) {
			console.log(
				'‚ÑπÔ∏è Quest√£o anterior finalizada ‚Äî promovendo para a hist√≥ria e continuando a processar o novo discurso.',
			);
			promoteCurrentToHistory(currentQuestion.text);
		}

		if (currentQuestion.text && now - currentQuestion.lastUpdate > QUESTION_IDLE_TIMEOUT) {
			closeCurrentQuestion();
		}

		// üß† Detecta in√≠cio de NOVA pergunta e fecha a anterior
		if (
			currentQuestion.text &&
			looksLikeQuestion(cleaned) &&
			now - currentQuestion.lastUpdate > 500 &&
			!currentQuestion.finalized
		) {
			closeCurrentQuestion();
		}

		if (!currentQuestion.text) {
			// evita criar novo turno se a transcri√ß√£o final for igual √† √∫ltima pergunta j√° enviada
			if (lastSentQuestionText && cleaned.trim() === lastSentQuestionText) {
				console.log('üîï transcri√ß√£o igual √† √∫ltima pergunta enviada ‚Äî ignorando novo turno');
				return;
			}
			currentQuestion.createdAt = Date.now();
			interviewTurnId++; // üî• novo turno
		}

		// evita duplica√ß√£o quando a mesma frase parcial/final chega novamente
		if (currentQuestion.text && normalizeForCompare(currentQuestion.text) === normalizeForCompare(cleaned)) {
			console.log('üîÅ speech igual ao currentQuestion ‚Äî ignorando concatena√ß√£o');
		} else {
			currentQuestion.text += (currentQuestion.text ? ' ' : '') + cleaned;
		}
		currentQuestion.lastUpdate = now;

		// üü¶ CURRENT vira sele√ß√£o padr√£o ao receber fala
		if (!selectedQuestionId) {
			selectedQuestionId = CURRENT_QUESTION_ID;
			clearAllSelections();
		}

		renderCurrentQuestion();
	}
}

/* ===============================
   FECHAMENTO DE PERGUNTAS
=============================== */

function closeCurrentQuestion() {
	resetInterviewTurnState();
	console.log('üö™ closeCurrentQuestion called', {
		interviewTurnId,
		gptAnsweredTurnId,
		currentQuestionText: currentQuestion.text,
	});

	// trata perguntas incompletas (retic√™ncias ou fragmentos)
	if (isIncompleteQuestion(currentQuestion.text)) {
		console.log('‚ö†Ô∏è pergunta incompleta detectada ‚Äî promovendo ao hist√≥rico como incompleta:', currentQuestion.text);

		const newId = crypto.randomUUID();
		questionsHistory.push({
			id: newId,
			text: currentQuestion.text,
			createdAt: currentQuestion.createdAt || Date.now(),
			incomplete: true,
		});

		// seleciona a pergunta rec√©m-criada para revis√£o manual
		selectedQuestionId = newId;

		// limpa CURRENT mas preserva sele√ß√£o l√≥gica
		currentQuestion.text = '';
		currentQuestion.finalized = false;

		renderQuestionsHistory();
		renderCurrentQuestion();
		return;
	}

	if (!looksLikeQuestion(currentQuestion.text)) {
		currentQuestion.text = '';
		currentQuestion.finalized = false;
		renderCurrentQuestion();
		return;
	}

	currentQuestion.text = finalizeQuestion(currentQuestion.text);
	currentQuestion.finalized = true;

	renderCurrentQuestion();
	// üî• COMPORTAMENTO POR MODO
	if (ModeController.isInterviewMode()) {
		// MODO ENTREVISTA ‚Äî chama GPT automaticamente (se ainda n√£o requisitado/respondido)
		if (gptRequestedTurnId !== interviewTurnId && gptAnsweredTurnId !== interviewTurnId) {
			selectedQuestionId = CURRENT_QUESTION_ID;
			console.log('‚û°Ô∏è closeCurrentQuestion chamou askGpt (vou enviar para o GPT)', {
				interviewTurnId,
				gptRequestedTurnId,
				gptAnsweredTurnId,
			});
			askGpt();
		} else {
			console.log('‚õî closeCurrentQuestion pulou askGpt porque j√° foi requisitado/respondido este turno', {
				interviewTurnId,
				gptRequestedTurnId,
				gptAnsweredTurnId,
			});
		}
	} else {
		// MODO NORMAL ‚Äî n√£o pergunta automaticamente ao GPT; promove para hist√≥rico e libera CURRENT
		console.log('üîµ modo NORMAL ‚Äî promovendo CURRENT para hist√≥rico sem chamar GPT');
		promoteCurrentToHistory(currentQuestion.text);
	}
}

function closeCurrentQuestionForced() {
	// log temporario para testar a aplica√ß√£o s√≥ remover depois
	console.log('üö™ Fechando pergunta:', currentQuestion.text);

	resetInterviewTurnState();

	if (!currentQuestion.text) return;

	questionsHistory.push({
		id: crypto.randomUUID(),
		text: finalizeQuestion(currentQuestion.text),
		createdAt: currentQuestion.createdAt || Date.now(),
	});

	currentQuestion.text = '';
	selectedQuestionId = null; // üëà libera sele√ß√£o
	renderQuestionsHistory();
	renderCurrentQuestion();
}

function resetInterviewTurnState() {
	outputPartialText = '';
	outputPartialChunks = [];
}

/* ===============================
   VALIDA√á√ÉO DE API KEY
=============================== */

// üî• Verifica o Status da API
async function checkApiKeyStatus() {
	try {
		const status = await ipcRenderer.invoke('GET_OPENAI_API_STATUS');
		console.log('üîë Status da API key:', status);
		return status;
	} catch (error) {
		console.warn('‚ö†Ô∏è N√£o foi poss√≠vel verificar status da API:', error);
		return { initialized: false, hasKey: false };
	}
}

// üî• Inicializa o processo principal com a chave j√° salva no ConfigManager
async function syncApiKeyOnStart() {
	try {
		// üî• O main.js j√° inicializa automaticamente com a chave do secure store
		console.log('üîÑ Verificando status do cliente OpenAI...');

		// üî• VERIFICAR API KEY ANTES DE CONTINUAR
		const status = await checkApiKeyStatus();

		if (status.initialized) {
			console.log('‚úÖ Cliente OpenAI j√° inicializado no main process');
		} else {
			updateStatusMessage('‚ùå API key n√£o configurada. Configure em "API e Modelos" ‚Üí OpenAI');
			console.log('‚ö†Ô∏è Cliente OpenAI n√£o inicializado - Usu√°rio precisa configurar uma chave');
		}
	} catch (err) {
		console.warn('‚ö†Ô∏è syncApiKeyOnStart falhou:', err);
	}
}

/* ===============================
   GPT
=============================== */
async function askGpt() {
	const text = getSelectedQuestionText();

	if (!text || text.trim().length < 5) {
		updateStatusMessage('‚ö†Ô∏è Pergunta vazia ou incompleta');
		return;
	}

	const isCurrent = selectedQuestionId === CURRENT_QUESTION_ID;
	const questionId = isCurrent ? CURRENT_QUESTION_ID : selectedQuestionId;

	// üõ°Ô∏è MODO ENTREVISTA ‚Äî bloqueia duplica√ß√£o APENAS para hist√≥rico
	if (ModeController.isInterviewMode() && !isCurrent) {
		const existingAnswer = findAnswerByQuestionId(questionId);
		if (existingAnswer) {
			emitUIChange('onAnswerAdd', {
				questionId,
				action: 'showExisting',
			});
			updateStatusMessage('üìå Essa pergunta j√° foi respondida');
			return;
		}
	}

	// limpa destaque
	emitUIChange('onAnswerAdd', {
		questionId,
		action: 'clearActive',
	});

	// üî• Apenas emite que precisa adicionar novo answer - config-manager cria DOM
	emitUIChange('onAnswerAdd', {
		questionId,
		action: 'new',
		text,
	});

	// log temporario para testar a aplica√ß√£o s√≥ remover depois
	console.log('ü§ñ askGpt chamado | questionId:', selectedQuestionId);
	console.log('üß™ GPT RECEBERIA:', text);

	console.log('üßæ askGpt diagn√≥stico', {
		textLength: text.length,
		selectedQuestionId,
		isInterviewMode: ModeController.isInterviewMode(),
		interviewTurnId,
		gptAnsweredTurnId,
	});

	// marca que este turno teve uma requisi√ß√£o ao GPT (apenas para CURRENT)
	if (isCurrent) {
		gptRequestedTurnId = interviewTurnId;
		console.log('‚ÑπÔ∏è gptRequestedTurnId definido para turno', gptRequestedTurnId);
		lastSentQuestionText = text.trim();
		console.log('‚ÑπÔ∏è lastSentQuestionText definido:', lastSentQuestionText);
	}

	// üß™ DEBUG
	if (APP_CONFIG.MODE_DEBUG) {
		updateStatusMessage('üß™ Pergunta enviada ao GPT (modo teste)');

		const mock = getMockGptAnswer(text);
		renderGptAnswer(null, mock);

		if (isCurrent && gptRequestedTurnId === interviewTurnId) {
			promoteCurrentToHistory(text);
			resetInterviewTurnState();
		}

		// marca como respondido nesse turno (mock)
		gptAnsweredTurnId = interviewTurnId;
		gptRequestedTurnId = null;
		return;
	}

	// üß† MODO ENTREVISTA ‚Äî STREAMING
	if (ModeController.isInterviewMode()) {
		const gptStartAt = ENABLE_INTERVIEW_TIMING_DEBUG ? Date.now() : null;
		let streamedText = '';

		console.log('‚è≥ enviando para o GPT via stream...');
		ipcRenderer.invoke('ask-gpt-stream', [
			{ role: 'system', content: SYSTEM_PROMPT },
			{ role: 'user', content: text },
		]).catch(err => {
			console.error('‚ùå Erro ao chamar ask-gpt-stream:', err);
			updateStatusMessage('‚ùå Erro ao enviar para GPT');
		});

		const onChunk = (_, token) => {
			streamedText += token;
			emitUIChange('onAnswerStreamChunk', {
				questionId,
				token,
				accum: streamedText,
			});
			console.log('üü¢ GPT_STREAM_CHUNK recebido (token parcial)', token);
		};

		const onEnd = () => {
			console.log('‚úÖ GPT_STREAM_END recebido (stream finalizado)');
			ipcRenderer.removeListener('GPT_STREAM_CHUNK', onChunk);
			ipcRenderer.removeListener('GPT_STREAM_END', onEnd);

			let finalText = streamedText;
			if (ENABLE_INTERVIEW_TIMING_DEBUG && gptStartAt) {
				const endAt = Date.now();
				const elapsed = endAt - gptStartAt;

				const startTime = new Date(gptStartAt).toLocaleTimeString();
				const endTime = new Date(endAt).toLocaleTimeString();

				finalText +=
					`\n\n‚è±Ô∏è GPT iniciou: ${startTime}` + `\n‚è±Ô∏è GPT finalizou: ${endTime}` + `\n‚è±Ô∏è Resposta em ${elapsed}ms`;
			}

			// garante que o turno foi realmente fechado
			const wasRequestedForThisTurn = gptRequestedTurnId === interviewTurnId;

			gptAnsweredTurnId = interviewTurnId;
			gptRequestedTurnId = null;

			// üîí FECHAMENTO AT√îMICO DO CICLO
			if (isCurrent && wasRequestedForThisTurn) {
				const finalHtml = marked.parse(finalText);
				renderGptAnswer(questionId, finalHtml);
				promoteCurrentToHistory(text);
				resetInterviewTurnState();
			} else if (questionId !== CURRENT_QUESTION_ID) {
				const finalHtml = marked.parse(finalText);
				renderGptAnswer(questionId, finalHtml);

				// marca a pergunta como respondida no hist√≥rico (streaming path)
				try {
					const q = questionsHistory.find(x => x.id === questionId);
					if (q) {
						q.answered = true;
						renderQuestionsHistory();
					}
				} catch (err) {
					console.warn('‚ö†Ô∏è falha ao marcar pergunta como respondida (stream):', err);
				}
			}
		};

		ipcRenderer.on('GPT_STREAM_CHUNK', onChunk);
		ipcRenderer.once('GPT_STREAM_END', onEnd);
		return;
	}

	// üîµ MODO NORMAL ‚Äî BATCH
	console.log('‚è≥ enviando para o GPT (batch)...');
	const res = await ipcRenderer.invoke('ask-gpt', [
		{ role: 'system', content: SYSTEM_PROMPT },
		{ role: 'user', content: text },
	]);

	console.log('‚úÖ resposta do GPT recebida (batch)');
	renderGptAnswer(questionId, res);

	const wasRequestedForThisTurn = gptRequestedTurnId === interviewTurnId;

	console.log(
		'‚ÑπÔ∏è gptRequestedTurnId antes do batch:',
		gptRequestedTurnId,
		'wasRequestedForThisTurn:',
		wasRequestedForThisTurn,
	);
	if (isCurrent && wasRequestedForThisTurn) {
		promoteCurrentToHistory(text);
		// ap√≥s promover para o hist√≥rico, a pergunta j√° est√° no hist√≥rico e resposta vinculada
		try {
			// Encontra a √∫ltima pergunta adicionada (que acabamos de promover)
			const q = questionsHistory[questionsHistory.length - 1];
			if (q) {
				q.answered = true;
				renderQuestionsHistory();
			}
		} catch (err) {
			console.warn('‚ö†Ô∏è falha ao marcar pergunta como respondida (batch):', err);
		}
	}

	// marca que o GPT respondeu esse turno (batch)
	gptAnsweredTurnId = interviewTurnId;
	gptRequestedTurnId = null;
}

/* ===============================
   UI (RENDER / SELE√á√ÉO / SCROLL)
=============================== */

function addTranscript(author, text, time) {
	let timeStr;
	if (time) {
		if (typeof time === 'number') timeStr = new Date(time).toLocaleTimeString();
		else if (time instanceof Date) timeStr = time.toLocaleTimeString();
		else timeStr = String(time);
	} else {
		timeStr = new Date().toLocaleTimeString();
	}

	// üî• Apenas EMITE o evento com os dados
	// config-manager.js √© respons√°vel por adicionar ao DOM
	const transcriptData = {
		author,
		text,
		timeStr,
		elementId: 'conversation',
	};

	emitUIChange('onTranscriptAdd', transcriptData);

	// Retorna um objeto proxy que simula um elemento DOM para compatibilidade
	// Usado quando a transcri√ß√£o √© um placeholder que ser√° atualizado depois
	const placeholderProxy = {
		dataset: { 
			startAt: typeof time === 'number' ? time : Date.now(), 
			stopAt: null 
		},
		// Permite que c√≥digo posterior trate como elemento DOM
		classList: {
			add: () => {},
			remove: () => {},
			contains: () => false,
			toggle: () => false,
		}
	};

	return placeholderProxy;
}

function renderCurrentQuestion() {
	if (!currentQuestion.text) {
		emitUIChange('onCurrentQuestionUpdate', { text: '', isSelected: false });
		return;
	}

	let label = currentQuestion.text;

	if (ENABLE_INTERVIEW_TIMING_DEBUG && currentQuestion.createdAt) {
		const time = new Date(currentQuestion.createdAt).toLocaleTimeString();
		label = `‚è±Ô∏è ${time} ‚Äî ${label}`;
	}

	// üî• Apenas EMITE dados - config-manager aplica ao DOM
	const questionData = {
		text: label,
		isSelected: selectedQuestionId === CURRENT_QUESTION_ID,
		rawText: currentQuestion.text,
		createdAt: currentQuestion.createdAt,
	};

	emitUIChange('onCurrentQuestionUpdate', questionData);
}

function renderQuestionsHistory() {
	// üî• Gera dados estruturados - config-manager renderiza no DOM
	const historyData = [...questionsHistory].reverse().map(q => {
		let label = q.text;
		if (ENABLE_INTERVIEW_TIMING_DEBUG && q.createdAt) {
			const time = new Date(q.createdAt).toLocaleTimeString();
			label = `‚è±Ô∏è ${time} ‚Äî ${label}`;
		}

		return {
			id: q.id,
			text: label,
			isIncomplete: q.incomplete,
			isAnswered: q.answered,
			isSelected: q.id === selectedQuestionId,
		};
	});

	emitUIChange('onQuestionsHistoryUpdate', historyData);

	scrollToSelectedQuestion();
}

function clearAllSelections() {
	// Emite evento para o controller limpar as sele√ß√µes visuais
	emitUIChange('onClearAllSelections', {});
}

function scrollToSelectedQuestion() {
	emitUIChange('onScrollToQuestion', {
		questionId: selectedQuestionId,
	});
}

function getSelectedQuestionText() {
	// 1Ô∏è‚É£ Se existe sele√ß√£o expl√≠cita
	if (selectedQuestionId === CURRENT_QUESTION_ID) {
		return currentQuestion.text;
	}

	if (selectedQuestionId) {
		const q = questionsHistory.find(q => q.id === selectedQuestionId);
		if (q?.text) return q.text;
	}

	// 2Ô∏è‚É£ Fallback: CURRENT (se tiver texto)
	if (currentQuestion.text && currentQuestion.text.trim().length > 0) {
		return currentQuestion.text;
	}

	return '';
}

function renderGptAnswer(questionId, markdownText) {
	// üî• Renderiza markdown e retorna HTML - config-manager aplica ao DOM
	const short = shortenAnswer(markdownText, 2);
	const html = marked.parse(short);

	// Encontra texto da pergunta no hist√≥rico ou na pergunta atual
	let questionText = '';
	if (questionId === CURRENT_QUESTION_ID) {
		questionText = currentQuestion?.text || '';
	} else {
		const q = questionsHistory.find(x => x.id === questionId);
		questionText = q?.text || '';
	}

	const answerData = {
		questionText,
		questionId,
		html,
	};

	emitUIChange('onAnswerAdd', answerData);

	// marca a pergunta como respondida no hist√≥rico (se vinculada)
	try {
		if (questionId && questionId !== CURRENT_QUESTION_ID) {
			const q = questionsHistory.find(x => x.id === questionId);
			if (q) {
				q.answered = true;
				renderQuestionsHistory();
			}
		}
	} catch (err) {
		console.warn('‚ö†Ô∏è falha ao marcar pergunta como respondida:', err);
	}
}

function resetInterviewState() {
	currentQuestion = { text: '', lastUpdate: 0, finalized: false };
	questionsHistory = [];
	selectedQuestionId = null;

	// Emit eventos para limpar UI
	emitUIChange('onTranscriptionCleared', {});
	emitUIChange('onAnswersCleared', {});

	clearAllSelections();
	renderQuestionsHistory();
	renderCurrentQuestion();
}

// üî• NOVO: Verifica se existe um modelo de IA ativo e retorna o nome do modelo
function hasActiveModel() {
	if (!window.configManager) {
		console.warn('‚ö†Ô∏è ConfigManager n√£o inicializado ainda');
		return { active: false, model: null };
	}
	
	const config = window.configManager.config;
	if (!config || !config.api) {
		console.warn('‚ö†Ô∏è Config ou api n√£o dispon√≠vel');
		return { active: false, model: null };
	}
	
	// Verifica se algum modelo est√° ativo e retorna o nome
	const providers = ['openai', 'google', 'openrouter', 'custom'];
	for (const provider of providers) {
		if (config.api[provider] && config.api[provider].enabled === true) {
			console.log(`‚úÖ Modelo ativo encontrado: ${provider}`);
			return { active: true, model: provider };
		}
	}
	
	console.warn('‚ö†Ô∏è Nenhum modelo ativo encontrado');
	return { active: false, model: null };
}

async function listenToggleBtn() {
	console.log('üî• DEBUG: listenToggleBtn() chamado!');
	
	// üî• VALIDA√á√ÉO 1: Modelo de IA ativo
	const { active: hasModel, model: activeModel } = hasActiveModel();
	console.log(`üìä DEBUG: hasModel = ${hasModel}, activeModel = ${activeModel}`);
	
	if (!isRunning && !hasModel) {
		const errorMsg = 'Ative um modelo de IA antes de come√ßar a ouvir';
		console.warn(`‚ö†Ô∏è ${errorMsg}`);
		console.log('üì° DEBUG: Emitindo onError:', errorMsg);
		emitUIChange('onError', errorMsg);
		return;
	}
	
	// üî• VALIDA√á√ÉO 2: Dispositivo de √°udio de SA√çDA (obrigat√≥rio para ouvir a reuni√£o)
	const hasOutputDevice = UIElements.outputSelect?.value;
	console.log(`üìä DEBUG: hasOutputDevice = ${hasOutputDevice}`);
	
	if (!isRunning && !hasOutputDevice) {
		const errorMsg = 'Selecione um dispositivo de √°udio (sa√≠da) para ouvir a reuni√£o';
		console.warn(`‚ö†Ô∏è ${errorMsg}`);
		console.log('üì° DEBUG: Emitindo onError:', errorMsg);
		emitUIChange('onError', errorMsg);
		return;
	}

	isRunning = !isRunning;
	const buttonText = isRunning ? 'Stop' : 'Start';
	const statusMsg = isRunning ? 'Status: ouvindo...' : 'Status: parado';

	emitUIChange('onListenButtonToggle', {
		isRunning,
		buttonText,
	});

	updateStatusMessage(statusMsg);
	console.log(`üé§ Listen toggle: ${isRunning ? 'INICIANDO' : 'PARANDO'} (modelo: ${activeModel})`);
	await (isRunning ? startAudio() : stopAudio());
}

function handleQuestionClick(questionId) {
	selectedQuestionId = questionId;
	clearAllSelections();
	renderQuestionsHistory();
	renderCurrentQuestion();

	// ‚ö†Ô∏è CURRENT nunca bloqueia resposta
	if (questionId !== CURRENT_QUESTION_ID) {
		const existingAnswer = findAnswerByQuestionId(questionId);

		if (existingAnswer) {
			emitUIChange('onAnswerSelected', {
				answerId: questionId,
				shouldScroll: true,
			});

			updateStatusMessage('üìå Essa pergunta j√° foi respondida');
			return;
		}
	}

	// Se for uma pergunta do hist√≥rico marcada como incompleta, n√£o enviar automaticamente ao GPT
	if (questionId !== CURRENT_QUESTION_ID) {
		const q = questionsHistory.find(q => q.id === questionId);
		if (q && q.incomplete) {
			updateStatusMessage('‚ö†Ô∏è Pergunta incompleta ‚Äî pressione o bot√£o de responder para enviar ao GPT');
			console.log('‚ÑπÔ∏è pergunta incompleta selecionada ‚Äî aguarda envio manual:', q.text);
			return;
		}
	}

	if (
		ModeController.isInterviewMode() &&
		selectedQuestionId === CURRENT_QUESTION_ID &&
		gptAnsweredTurnId === interviewTurnId
	) {
		updateStatusMessage('‚õî GPT j√° respondeu esse turno');
		console.log('‚õî GPT j√° respondeu esse turno');
		return;
	}

	// ‚ùì Ainda n√£o respondida ‚Üí chama GPT
	askGpt();
}

function applyOpacity(value) {
	const appOpacity = parseFloat(value);

	// aplica opacidade no conte√∫do geral
	document.documentElement.style.setProperty('--app-opacity', appOpacity.toFixed(2));

	// topBar nunca abaixo de 0.75
	const topbarOpacity = Math.max(appOpacity, 0.75);
	document.documentElement.style.setProperty('--app-opacity-75', topbarOpacity.toFixed(2));

	localStorage.setItem('overlayOpacity', appOpacity);

	// logs tempor√°rios para debug
	console.log('üéöÔ∏è Opacity change | app:', value, '| topBar:', topbarOpacity);
}

// üî• Novo: atualizar status sem tocar em DOM
function updateStatusMessage(message) {
	emitUIChange('onStatusUpdate', { message });
}

/* ===============================
   ATALHOS GLOBAIS - MOVED TO CONFIG-MANAGER
=============================== */
// Listeners registrados via config-manager.js

/* ===============================
   MOCK / DEBUG
=============================== */

function startMockInterview() {
	if (mockInterviewRunning) return;
	mockInterviewRunning = true;

	// üî• Emite atualiza√ß√£o do mock badge
	emitUIChange('onMockBadgeUpdate', { visible: true });

	const mockQuestions = [
		'O que √© JVM e para que serve',
		'Qual a diferen√ßa entre JDK e JRE',
		'Explique o que √© Garbage Collector',
		'Como funciona o equals e hashCode',
		'O que √© imutabilidade em Java',
		'Explique o que √© POO',
		'Quais s√£o os pilares da POO',
		'Qual a diferen√ßa entre Spring e Spring Boot',
	];

	let index = 0;

	function sendNext() {
		if (!APP_CONFIG.MODE_DEBUG || index >= mockQuestions.length) {
			mockInterviewRunning = false;
			return;
		}

		const text = mockQuestions[index];
		addTranscript(OTHER, text); // üëà simula fala real
		handleSpeech(OTHER, text); // üëà consolida pergunta

		index++;

		// simula sil√™ncio ‚Üí fechamento da pergunta
		setTimeout(() => {
			closeCurrentQuestion();
		}, QUESTION_IDLE_TIMEOUT);

		// pr√≥xima pergunta depois de um tempo
		setTimeout(sendNext, 6000);
	}

	sendNext();
}

// function getMockGptAnswer() {
// 	return `
// ### ‚úîÔ∏è Resposta

// Em Java, a **POO (Programa√ß√£o Orientada a Objetos)** √© baseada em **4 pilares**:

// - **Encapsulamento**
// - **Heran√ßa**
// - **Polimorfismo**
// - **Abstra√ß√£o**

// ### üí° Exemplo em Java

// \`\`\`java
// public class Pessoa {
// 	private String nome;

// 	public Pessoa(String nome) {
// 		this.nome = nome;
// 	}

// 	public String getNome() {
// 		return nome;
// 	}
// }
// \`\`\`

// üìå **Dica:** use encapsulamento para proteger o estado interno da classe.
// `;
// }

function getMockGptAnswer(question) {
	return `
### ‚úîÔ∏è Resposta simulada

Voc√™ perguntou:

> ${question}

Essa √© uma resposta mock apenas para validar:
- fluxo
- scroll
- sele√ß√£o
- ritmo de uso

`;
}

/* ===============================
   BOOT
=============================== */

marked.setOptions({
	highlight: function (code, lang) {
		if (lang && hljs.getLanguage(lang)) {
			return hljs.highlight(code, { language: lang }).value;
		}
		return hljs.highlightAuto(code).value;
	},
	breaks: true,
});

/* ===============================
   EVENT LISTENERS MOVED TO CONFIG-MANAGER
   darkToggle, opacitySlider, btnClose listeners
=============================== */

/* ===============================
   EVENT LISTENERS MOVED TO CONFIG-MANAGER
   (renderrer.js √© agora apenas Services)
=============================== */

/* ===============================
   DRAG AND DROP DA JANELA - MOVED TO CONFIG-MANAGER
=============================== */
// Drag logic agora est√° em config-manager.js
// Mant√©m as fun√ß√µes abaixo como utilities p√∫blicas:

/* ===============================
   DOMContentLoaded - INITIALIZATION MOVED TO CONFIG-MANAGER
=============================== */
// Controllers now handle DOMContentLoaded initialization
// renderer.js kept only for direct utility calls if needed

/* ===============================
   CLICK-THROUGH - MOVED TO CONFIG-MANAGER
=============================== */

/* ===============================
   GLOBAL ERROR HANDLING - MOVED TO CONFIG-MANAGER
=============================== */

/* ===============================
   PUBLIC API FOR CONFIG-MANAGER
   (Fun√ß√µes que o Controller chama)
=============================== */

// Exporta fun√ß√µes p√∫blicas que o controller pode chamar
const RendererAPI = {
	// √Åudio - Grava√ß√£o
	startInput,
	stopInput: stopInputMonitor,
	startOutput,
	stopOutput: stopOutputMonitor,
	restartAudioPipeline,

	// üî• NOVO: √Åudio - Monitoramento de volume
	startInputVolumeMonitoring,
	startOutputVolumeMonitoring,

	// Entrevista
	listenToggleBtn,
	askGpt,
	resetInterviewState,
	startMockInterview,

	// Modo
	changeMode: (mode) => {
		CURRENT_MODE = mode;
	},
	getMode: () => CURRENT_MODE,

	// Questions
	handleQuestionClick,
	closeCurrentQuestion,

	// UI
	applyOpacity,
	updateMockBadge: (show) => {
		emitUIChange('onMockBadgeUpdate', { visible: show });
	},
	setMockToggle: (checked) => {
		if (UIElements.mockToggle) {
			UIElements.mockToggle.checked = checked;
		}
		APP_CONFIG.MODE_DEBUG = checked;
	},
	setModeSelect: (mode) => {
		emitUIChange('onModeSelectUpdate', { mode });
	},

	// Drag
	initDragHandle: (dragHandle, documentElement) => {
		if (!dragHandle) return;
		const doc = documentElement || document; // fallback para document global
		dragHandle.addEventListener('pointerdown', async event => {
			console.log('ü™ü Drag iniciado (pointerdown)');
			isDraggingWindow = true;
			dragHandle.classList.add('drag-active');

			const _pid = event.pointerId;
			try {
				dragHandle.setPointerCapture && dragHandle.setPointerCapture(_pid);
			} catch (err) {
				console.warn('setPointerCapture falhou:', err);
			}

			setTimeout(() => ipcRenderer.send('START_WINDOW_DRAG'), 40);

			const startBounds = (await ipcRenderer.invoke('GET_WINDOW_BOUNDS')) || { x: 0, y: 0 };
			const startCursor = { x: event.screenX, y: event.screenY };
			let lastAnimation = 0;

			function onPointerMove(ev) {
				const now = performance.now();
				if (now - lastAnimation < 16) return;
				lastAnimation = now;

				const dx = ev.screenX - startCursor.x;
				const dy = ev.screenY - startCursor.y;

				ipcRenderer.send('MOVE_WINDOW_TO', { x: startBounds.x + dx, y: startBounds.y + dy });
			}

			function onPointerUp(ev) {
				try {
					dragHandle.removeEventListener('pointermove', onPointerMove);
					dragHandle.removeEventListener('pointerup', onPointerUp);
				} catch (err) {}

				if (dragHandle.classList.contains('drag-active')) {
					dragHandle.classList.remove('drag-active');
				}

				try {
					dragHandle.releasePointerCapture && dragHandle.releasePointerCapture(_pid);
				} catch (err) {}

				isDraggingWindow = false;
			}

			dragHandle.addEventListener('pointermove', onPointerMove);
			dragHandle.addEventListener('pointerup', onPointerUp, { once: true });
			event.stopPropagation();
		});

		doc.addEventListener('pointerup', () => {
			if (!dragHandle.classList.contains('drag-active')) return;
			console.log('ü™ü Drag finalizado (pointerup)');
			dragHandle.classList.remove('drag-active');
			isDraggingWindow = false;
		});

		dragHandle.addEventListener('pointercancel', () => {
			if (dragHandle.classList.contains('drag-active')) {
				dragHandle.classList.remove('drag-active');
				isDraggingWindow = false;
			}
		});
	},

	// Click-through
	setClickThrough: (enabled) => {
		ipcRenderer.send('SET_CLICK_THROUGH', enabled);
	},
	updateClickThroughButton: (enabled, btnToggle) => {
		if (!btnToggle) return;
		btnToggle.style.opacity = enabled ? '0.5' : '1';
		btnToggle.title = enabled
			? 'Click-through ATIVO (clique para desativar)'
			: 'Click-through INATIVO (clique para ativar)';
		console.log('üé® Bot√£o atualizado - opacity:', btnToggle.style.opacity);
	},

	// UI Registration
	registerUIElements: (elements) => {
		registerUIElements(elements);
	},
	onUIChange: (eventName, callback) => {
		onUIChange(eventName, callback);
	},

	// API Key
	setAppConfig: (config) => {
		APP_CONFIG = config;
	},
	getAppConfig: () => APP_CONFIG,

	// Keyboard shortcuts
	registerKeyboardShortcuts: () => {
		window.addEventListener(
			'keydown',
			e => {
				if (e.ctrlKey && e.shiftKey && (e.code === 'ArrowUp' || e.code === 'ArrowDown')) {
					e.preventDefault();
					e.stopPropagation();

					const all = getNavigableQuestionIds();
					if (all.length === 0) return;

					let index = all.indexOf(selectedQuestionId);
					if (index === -1) {
						index = e.key === 'ArrowUp' ? all.length - 1 : 0;
					} else {
						index += e.key === 'ArrowUp' ? -1 : 1;
						index = Math.max(0, Math.min(index, all.length - 1));
					}

					selectedQuestionId = all[index];
					clearAllSelections();
					renderQuestionsHistory();
					renderCurrentQuestion();

					if (APP_CONFIG.MODE_DEBUG) {
						const msg = e.key === 'ArrowUp' ? 'üß™ Ctrl+ArrowUp detectado (teste)' : 'üß™ Ctrl+ArrowDown detectado (teste)';
						updateStatusMessage(msg);
						console.log('üìå Atalho Selecionou:', selectedQuestionId);
						return;
					}
				}
			},
			true,
		);
	},

	// IPC Listeners
	onApiKeyUpdated: (callback) => {
		ipcRenderer.on('API_KEY_UPDATED', callback);
	},
	onToggleAudio: (callback) => {
		ipcRenderer.on('CMD_TOGGLE_AUDIO', callback);
	},
	onAskGpt: (callback) => {
		ipcRenderer.on('CMD_ASK_GPT', callback);
	},
	onGptStreamChunk: (callback) => {
		ipcRenderer.on('GPT_STREAM_CHUNK', callback);
	},
	onGptStreamEnd: (callback) => {
		ipcRenderer.on('GPT_STREAM_END', callback);
	},
	sendRendererError: (error) => {
		try {
			console.error('RENDERER ERROR', error.error || error.message || error);
			ipcRenderer.send('RENDERER_ERROR', {
				message: String(error.message || error),
				stack: error.error?.stack || null,
			});
		} catch (err) {
			console.error('Falha ao enviar RENDERER_ERROR', err);
		}
	},
};

if (typeof module !== 'undefined' && module.exports) {
	module.exports = RendererAPI;
}

// üî• Expor globalmente para que config-manager possa acessar
if (typeof window !== 'undefined') {
	window.RendererAPI = RendererAPI;
}
