/* ================================ */
//	IMPORTES E DEPEND√äNCIAS
/* ================================ */

const { ipcRenderer } = require('electron');
const { marked } = require('marked');
const hljs = require('highlight.js');
const { startAudioDeepgram, stopAudioDeepgram, switchDeviceDeepgram } = require('./stt/stt-deepgram.js');  // reorganizado em pasta stt/
const { startAudioVosk, stopAudioVosk, switchDeviceVosk } = require('./stt/stt-vosk.js');  // reorganizado em pasta stt/
const { startAudioWhisper, stopAudioWhisper, switchDeviceWhisper } = require('./stt/stt-whisper.js');  // reorganizado em pasta stt/
const {
	startAudioVolumeMonitor,
	stopAudioVolumeMonitor,
	switchAudioVolumeDevice,
} = require('./volume-audio-monitor.js');

/* ================================ */
//	üéØ NOVAS CLASSES (Refatora√ß√£o Fase 2)
/* ================================ */
const AppState = require('./state/AppState.js');
const EventBus = require('./events/EventBus.js');
const Logger = require('./utils/Logger.js');
const STTStrategy = require('./strategies/STTStrategy.js');
const LLMManager = require('./llm/LLMManager.js');
const openaiHandler = require('./llm/handlers/openai-handler.js');
const { validateLLMRequest, handleLLMStream, handleLLMBatch } = require('./handlers/llmHandlers.js');  // antigo validateAskGptRequest, handleAskGptStream, handleAskGptBatch

// üéØ INSTANCIAR
const appState = new AppState();
const eventBus = new EventBus();
const sttStrategy = new STTStrategy();
const llmManager = new LLMManager();

// üéØ REGISTRAR LLMs
llmManager.register('openai', openaiHandler);
// Futuro: llmManager.register('gemini', require('./llm/handlers/gemini-handler.js'));
// Futuro: llmManager.register('anthropic', require('./llm/handlers/anthropic-handler.js'));

// üéØ REGISTRAR LISTENERS DA EVENTBUS (para LLM)
eventBus.on('answerStreamChunk', data => {
	emitUIChange('onAnswerStreamChunk', {
		questionId: data.questionId,
		token: data.token,
		accum: data.accum,
	});
});

eventBus.on('llmStreamEnd', data => {
	Logger.info('LLM Stream finalizado', { questionId: data.questionId });
	emitUIChange('onAnswerStreamEnd', {});
});

eventBus.on('llmBatchEnd', data => {
	Logger.info('LLM Batch finalizado', { questionId: data.questionId, responseLength: data.response?.length || 0 });
	emitUIChange('onAnswerBatchEnd', {
		questionId: data.questionId,
		response: data.response,
	});
});

eventBus.on('error', error => {
	Logger.error('Erro na eventBus', { error });
	updateStatusMessage(`‚ùå ${error}`);
});

/* ================================ */
//	PROTE√á√ÉO CONTRA CAPTURA DE TELA
/* ================================ */

/**
 * Prote√ß√£o contra captura de tela externa
 * Desabilita/limita APIs usadas por Zoom, Teams, Meet, OBS, Discord, Snipping Tool, etc.
 */
(function protectAgainstScreenCapture() {
	// ‚úÖ Desabilita getDisplayMedia (usado por Zoom, Meet, Teams para capturar)
	if (navigator && navigator.mediaDevices && navigator.mediaDevices.getDisplayMedia) {
		const originalGetDisplayMedia = navigator.mediaDevices.getDisplayMedia.bind(navigator.mediaDevices);
		navigator.mediaDevices.getDisplayMedia = async function (...args) {
			console.warn('üîê BLOQUEADO: Tentativa de usar getDisplayMedia (captura de tela externa)');
			throw new Error('Screen capture not available in this window');
		};
	}

	// ‚úÖ Desabilita captureStream (usado para captura de janela)
	if (window.HTMLCanvasElement && window.HTMLCanvasElement.prototype.captureStream) {
		Object.defineProperty(window.HTMLCanvasElement.prototype, 'captureStream', {
			value: function () {
				console.warn('üîê BLOQUEADO: Tentativa de usar Canvas.captureStream()');
				throw new Error('Capture stream not available');
			},
			writable: false,
			configurable: false,
		});
	}

	// ‚úÖ Intercepta getUserMedia para avisar sobre tentativas de captura de √°udio
	if (navigator && navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
		const originalGetUserMedia = navigator.mediaDevices.getUserMedia.bind(navigator.mediaDevices);
		navigator.mediaDevices.getUserMedia = async function (constraints) {
			if (constraints && constraints.video) {
				console.warn('üîê AVISO: Tentativa de usar getUserMedia com v√≠deo detectada');
				// Ainda permite √°udio, mas bloqueia v√≠deo para captura
				if (constraints.video) {
					delete constraints.video;
				}
			}
			return originalGetUserMedia(constraints);
		};
	}

	console.log('‚úÖ Prote√ß√£o contra captura externa ativada');
})();

/* ================================ */
//	CONSTANTES
/* ================================ */

const YOU = 'Voc√™';
const OTHER = 'Outros';

// Modos de opera√ß√£o
const MODES = {
	NORMAL: 'NORMAL',
	INTERVIEW: 'INTERVIEW',
};

// üîÑ modo atual (default = comportamento atual)
let CURRENT_MODE = MODES.NORMAL;

// Controlador de modo
const ModeController = {
	/**
	 * Verifica se est√° em modo entrevista
	 * @returns {boolean} true se modo entrevista
	 */
	isInterviewMode() {
		return CURRENT_MODE === MODES.INTERVIEW;
	},
};

const ENABLE_INTERVIEW_TIMING_DEBUG_METRICS = true; // ‚Üê desligar depois se n√£o quiser mostrar time = false
const CURRENT_QUESTION_ID = 'CURRENT'; // ID da pergunta atual

const SYSTEM_PROMPT = `
Voc√™ √© um assistente para entrevistas t√©cnicas de Java. Responda como candidato.
Regras de resposta (priorize sempre estas):
- Seja natural e conciso: responda em no m√°ximo 1‚Äì2 frases curtas.
- Use linguagem coloquial e direta, como algu√©m explicando rapidamente verbalmente.
- Evite listas longas, exemplos extensos ou par√°grafos detalhados.
- N√£o comece com cumprimentos ou palavras de preenchimento (ex.: "Claro", "Ok").
- Quando necess√°rio, entregue um exemplo m√≠nimo de 1 linha apenas.
`;

/* ================================ */
//	ESTADO GLOBAL
/* ================================ */

let APP_CONFIG = {
	MODE_DEBUG: false, // ‚Üê alterado via config-manager.js (true = modo mock)
};

// Estado de execu√ß√£o do STT
let isRunning = false;

// Screenshots capturados
let capturedScreenshots = []; // Array de { filepath, filename, timestamp }
let isCapturing = false;
let isAnalyzing = false;

// Drag and Drop da janela
let isDraggingWindow = false;

// üî• MODIFICADO: STT model vem da config agora (removido USE_LOCAL_WHISPER)
let transcriptionMetrics = {
	audioStartTime: null,
	gptStartTime: null,
	gptFirstTokenTime: null,
	gptEndTime: null,
	totalTime: null,
	audioSize: 0,
};

// üî• REMOVED: inputStream, inputAnalyser, outputStream, outputAnalyser
// Agora usamos audio-volume-monitor.js para monitoramento de volume
// quando usu√°rio est√° na se√ß√£o "√Åudio e Tela" (sem transcri√ß√£o ativa)

/* üß† PERGUNTAS */
let currentQuestion = {
	text: '',
	lastUpdate: 0,
	finalized: false,
	lastUpdateTime: null,
	createdAt: null,
	finalText: '',
	interimText: '',
};
let questionsHistory = [];
const answeredQuestions = new Set(); // üîí Armazena respostas j√° geradas (questionId -> true)
let selectedQuestionId = null;
let interviewTurnId = 0;
let gptAnsweredTurnId = null;
let gptRequestedTurnId = null;
let gptRequestedQuestionId = null; // üî• [IMPORTANTE] Rastreia QUAL pergunta foi realmente solicitada ao GPT
let lastAskedQuestionNormalized = null;

/* ================================ */
//	SISTEMA DE CALLBACKS E UI ELEMENTS
/* ================================ */

/**
 * Callbacks/Observers registrados pela UI (config-manager.js)
 * renderer.js √© "cego" para DOM - config-manager se inscreve em mudan√ßas
 */
const UICallbacks = {
	onError: null, // üî• NOVO: Para mostrar erros de valida√ß√£o
	onTranscriptAdd: null,
	onCurrentQuestionUpdate: null,
	onQuestionsHistoryUpdate: null,
	onStatusUpdate: null,
	onInputVolumeUpdate: null,
	onOutputVolumeUpdate: null,
	onMockBadgeUpdate: null,
	onDOMElementsReady: null, // callback para pedir elementos ao config-manager
	onListenButtonToggle: null,
	onAnswerSelected: null,
	onClearAllSelections: null,
	onScrollToQuestion: null,
	onTranscriptionCleared: null,
	onAnswersCleared: null,
	onAnswerStreamChunk: null,
	onAnswerIdUpdate: null,
	onModeSelectUpdate: null,
	onAnswerStreamEnd: null,
	onPlaceholderFulfill: null,
	onPlaceholderUpdate: null,
	onUpdateInterim: null,
	onClearInterim: null,
	onScreenshotBadgeUpdate: null,
	onAudioDeviceChanged: null,
};

/**
 * Registra callback para evento de UI
 * @param {string} eventName - Nome do evento
 * @param {function} callback - Fun√ß√£o a ser chamada quando evento ocorre
 */
function onUIChange(eventName, callback) {
	if (UICallbacks.hasOwnProperty(eventName)) {
		UICallbacks[eventName] = callback;
		console.log(`üì° UI callback registrado em renderer.js: ${eventName}`);
	}
}

/**
 * Emite evento de UI para config-manager
 * @param {string} eventName - Nome do evento
 * @param {any} data - Dados do evento
 */
function emitUIChange(eventName, data) {
	if (UICallbacks[eventName] && typeof UICallbacks[eventName] === 'function') {
		UICallbacks[eventName](data);
	} else {
		console.warn(`‚ö†Ô∏è DEBUG: Nenhum callback registrado para '${eventName}'`);
	}
}

/**
 * Elementos UI solicitados por callback
 * config-manager.js fornece esses elementos via registerUIElements()
 */
let UIElements = {
	inputSelect: null,
	outputSelect: null,
	listenBtn: null,
	statusText: null,
	transcriptionBox: null,
	currentQuestionBox: null,
	currentQuestionTextBox: null,
	questionsHistoryBox: null,
	answersHistoryBox: null,
	askBtn: null,
	inputVu: null,
	outputVu: null,
	inputVuHome: null,
	outputVuHome: null,
	mockToggle: null,
	mockBadge: null,
	interviewModeSelect: null,
	btnClose: null,
	btnToggleClick: null,
	dragHandle: null,
	darkToggle: null,
	opacityRange: null,
};

/**
 * Registra elementos UI no renderer
 * config-manager.js chama isso para registrar elementos
 * @param {object} elements - Mapeamento de elementos UI
 */
function registerUIElements(elements) {
	UIElements = { ...UIElements, ...elements };
	console.log('‚úÖ UI Elements registrados no renderer.js');
}

/* ================================ */
//	MONITORAMENTO DE VOLUME
/* ================================ */

/**
 * Escuta evento de mudan√ßa de dispositivo
 * Emitido pelo config-manager
 */
eventBus.on('audioDeviceChanged', async data => {
	try {
		const sttModel = getConfiguredSTTModel();
		Logger.info('audioDeviceChanged', { model: sttModel, type: data.type });  // antigo onAudioDeviceChanged

		if (!data || !data.type) {
			Logger.warn('Dados inv√°lidos para mudan√ßa de dispositivo', data);
			return;
		}

		if (!isRunning) {
			Logger.warn('STT n√£o est√° ativo, ignorando mudan√ßa de dispositivo');
			return;
		}

		await sttStrategy.switchDevice(sttModel, data.type, data.deviceId);
	} catch (error) {
		Logger.error('Erro ao processar mudan√ßa de dispositivo', { error: error.message });  // antigo console.error
	}
});

/* Compatibilidade: antigo onUIChange tamb√©m suporta audioDeviceChanged */
onUIChange('onAudioDeviceChanged', async data => {
	eventBus.emit('audioDeviceChanged', data);
});

/* ================================ */
//	FUN√á√ïES UTILIT√ÅRIAS (HELPERS)
/* ================================ */

/**
 * Obt√©m o modelo STT configurado via config-manager
 * @returns {string} Nome do modelo STT ou 'error'
 */
function getConfiguredSTTModel() {
	try {
		if (!window.configManager || !window.configManager.config) {
			console.warn('‚ö†Ô∏è configManager n√£o dispon√≠vel no escopo global');
			return 'error'; // fallback
		}

		const config = window.configManager.config;
		const activeProvider = config.api?.activeProvider;
		const sttModel = config.api?.[activeProvider]?.selectedSTTModel;

		if (!sttModel) {
			console.warn(`‚ö†Ô∏è Modelo STT n√£o configurado para ${activeProvider}`);
			return 'error'; // fallback
		}

		return sttModel;
	} catch (err) {
		console.error('‚ùå Erro ao obter modelo STT da config:', err);
		return 'error'; // fallback
	}
}

/**
 * Finaliza pergunta adicionando "?" se necess√°rio
 * @param {string} t - Texto da pergunta
 * @returns {string} Pergunta finalizada
 */
function finalizeQuestion(t) {
	debugLogRenderer('In√≠cio da fun√ß√£o: "finalizeQuestion"');
	debugLogRenderer('Fim da fun√ß√£o: "finalizeQuestion"');
	return t.trim().endsWith('?') ? t.trim() : t.trim() + '?';
}

/**
 * Reseta o estado da pergunta atual (CURRENT)
 */
function resetCurrentQuestion() {
	debugLogRenderer('In√≠cio da fun√ß√£o: "resetCurrentQuestion"');

	currentQuestion = {
		text: '',
		lastUpdate: 0,
		finalized: false,
		lastUpdateTime: null,
		createdAt: null,
		finalText: '',
		interimText: '',
	};

	debugLogRenderer('Fim da fun√ß√£o: "resetCurrentQuestion"');
}

/**
 * Renderiza o hist√≥rico de perguntas
 */
function renderQuestionsHistory() {
	debugLogRenderer('In√≠cio da fun√ß√£o: "renderQuestionsHistory"');

	// üî• Gera dados estruturados - config-manager renderiza no DOM
	const historyData = [...questionsHistory].reverse().map(q => {
		let label = q.text;
		if (ENABLE_INTERVIEW_TIMING_DEBUG_METRICS && q.lastUpdateTime) {
			const time = new Date(q.lastUpdateTime).toLocaleTimeString();
			label = `‚è±Ô∏è ${time} ‚Äî ${label}`;
		}

		return {
			id: q.id,
			text: label,
			isIncomplete: q.incomplete,
			isAnswered: q.answered,
			isSelected: q.id === selectedQuestionId,
		};
	});

	emitUIChange('onQuestionsHistoryUpdate', historyData);

	scrollToSelectedQuestion();

	debugLogRenderer('Fim da fun√ß√£o: "renderQuestionsHistory"');
}

/**
 * Retorna o texto da pergunta selecionada (CURRENT ou do hist√≥rico)
 * @returns {string} Texto da pergunta selecionada
 */
function getSelectedQuestionText() {
	debugLogRenderer('In√≠cio da fun√ß√£o: "getSelectedQuestionText"');
	debugLogRenderer('Fim da fun√ß√£o: "getSelectedQuestionText"');

	// 1Ô∏è‚É£ Se existe sele√ß√£o expl√≠cita
	if (selectedQuestionId === CURRENT_QUESTION_ID) {
		return currentQuestion.text;
	}

	if (selectedQuestionId) {
		const q = questionsHistory.find(q => q.id === selectedQuestionId);
		if (q?.text) return q.text;
	}

	// 2Ô∏è‚É£ Fallback: CURRENT (se tiver texto)
	if (currentQuestion.text && currentQuestion.text.trim().length > 0) {
		return currentQuestion.text;
	}

	return '';
}

/**
 * Normaliza texto para compara√ß√£o
 * Remove pontua√ß√£o, converte para lowercase, remove espa√ßos extras
 * @param {string} t - Texto a normalizar
 * @returns {string} Texto normalizado
 */
function normalizeForCompare(t) {
	debugLogRenderer('In√≠cio da fun√ß√£o: "normalizeForCompare"');
	debugLogRenderer('Fim da fun√ß√£o: "normalizeForCompare"');
	return (t || '')
		.toLowerCase()
		.replace(/[?!.\n\r]/g, '')
		.replace(/\s+/g, ' ')
		.trim();
}

/**
 * Atualiza a mensagem de status na UI
 * @param {string} message - Mensagem de status
 */
function updateStatusMessage(message) {
	debugLogRenderer('In√≠cio da fun√ß√£o: "updateStatusMessage"');
	emitUIChange('onStatusUpdate', { message });
	debugLogRenderer('Fim da fun√ß√£o: "updateStatusMessage"');
}

/**
 * Verifica se uma pergunta j√° foi respondida pelo ID
 * @param {string} questionId - ID da pergunta
 * @returns {boolean} true se pergunta j√° foi respondida
 */
function findAnswerByQuestionId(questionId) {
	debugLogRenderer('In√≠cio da fun√ß√£o: "findAnswerByQuestionId"');

	if (!questionId) {
		// ID inv√°lido
		debugLogRenderer('Fim da fun√ß√£o: "findAnswerByQuestionId"');
		return false;
	}

	debugLogRenderer('Fim da fun√ß√£o: "findAnswerByQuestionId"');
	return answeredQuestions.has(questionId);
}

/**
 * Promove pergunta atual para hist√≥rico
 * @param {string} text - Texto da pergunta
 */
function promoteCurrentToHistory(text) {
	debugLogRenderer('In√≠cio da fun√ß√£o: "promoteCurrentToHistory"');

	debugLogRenderer('üìö promovendo pergunta para hist√≥rico:', text, false);

	// evita duplica√ß√£o no hist√≥rico: se a √∫ltima entrada √© igual (normalizada), n√£o adiciona
	const last = questionsHistory.length ? questionsHistory[questionsHistory.length - 1] : null;
	if (last && normalizeForCompare(last.text) === normalizeForCompare(text)) {
		debugLogRenderer('üîï pergunta igual j√° presente no hist√≥rico ‚Äî pulando promo√ß√£o', false);

		// limpa CURRENT mas preserva sele√ß√£o conforme antes
		const prevSelected = selectedQuestionId;
		currentQuestion = {
			text: '',
			lastUpdate: 0,
			finalized: false,
			lastUpdateTime: null,
			createdAt: null,
			finalText: '',
			interimText: '',
		};

		if (prevSelected === null || prevSelected === CURRENT_QUESTION_ID) {
			selectedQuestionId = CURRENT_QUESTION_ID;
		} else {
			selectedQuestionId = prevSelected;
		}

		renderQuestionsHistory();
		renderCurrentQuestion();
		return;
	}

	const newId = String(questionsHistory.length + 1);

	questionsHistory.push({
		id: newId,
		text,
		createdAt: currentQuestion.createdAt || Date.now(),
		lastUpdateTime: currentQuestion.lastUpdateTime || currentQuestion.createdAt || Date.now(),
	});

	// üî• [IMPORTANTE] Migrar resposta de CURRENT para o novo ID no history
	if (answeredQuestions.has(CURRENT_QUESTION_ID)) {
		answeredQuestions.delete(CURRENT_QUESTION_ID);
		answeredQuestions.add(newId);
		debugLogRenderer('üîÑ [IMPORTANTE] Migrada resposta de CURRENT para newId:', newId, false);
	}

	// üî• [CR√çTICO] Atualizar o ID do bloco de resposta no DOM se ele foi criado com CURRENT
	debugLogRenderer(
		'üîÑ [IMPORTANTE] Emitindo onAnswerIdUpdate para atualizar bloco de resposta: CURRENT ‚Üí ',
		newId,
		false,
	);
	emitUIChange('onAnswerIdUpdate', {
		oldId: CURRENT_QUESTION_ID,
		newId: newId,
	});

	// üî• [IMPORTANTE] Se uma pergunta CURRENT foi solicitada ao GPT,
	// atualizar o rastreamento para apontar para o novo ID promovido
	if (gptRequestedQuestionId === CURRENT_QUESTION_ID) {
		gptRequestedQuestionId = newId;
		debugLogRenderer('üîÑ [IMPORTANTE] gptRequestedQuestionId atualizado de CURRENT para newId:', newId, false);
	}

	// preserva sele√ß√£o do usu√°rio: se n√£o havia sele√ß√£o expl√≠cita ou estava no CURRENT,
	// mant√©m a sele√ß√£o no CURRENT para que o novo CURRENT seja principal.
	const prevSelected = selectedQuestionId;

	resetCurrentQuestion();

	if (prevSelected === null || prevSelected === CURRENT_QUESTION_ID) {
		selectedQuestionId = CURRENT_QUESTION_ID;
	} else {
		// usu√°rio tinha selecionado algo no hist√≥rico ‚Äî preserva essa sele√ß√£o
		selectedQuestionId = prevSelected;
	}

	renderQuestionsHistory();
	renderCurrentQuestion();

	debugLogRenderer('Fim da fun√ß√£o: "promoteCurrentToHistory"');
}

/**
 * Limpa todas as sele√ß√µes visuais
 */
function clearAllSelections() {
	// Emite evento para o controller limpar as sele√ß√µes visuais
	emitUIChange('onClearAllSelections', {});
}

/**
 * Obt√©m IDs naveg√°veis de perguntas (CURRENT + hist√≥rico)
 * @returns {array} Array de IDs naveg√°veis
 */
function getNavigableQuestionIds() {
	const ids = [];
	if (currentQuestion.text) ids.push(CURRENT_QUESTION_ID);
	questionsHistory.forEach(q => ids.push(q.id));
	return ids;
}

/* ================================ */
//	üéØ REGISTRAR STTs (Refatora√ß√£o Fase 2)
/* ================================ */

// Registrar STTs no sttStrategy
sttStrategy.register('deepgram', {
	start: startAudioDeepgram,
	stop: stopAudioDeepgram,
	switchDevice: switchDeviceDeepgram,
});

sttStrategy.register('vosk', {
	start: startAudioVosk,
	stop: stopAudioVosk,
	switchDevice: switchDeviceVosk,
});

sttStrategy.register('whisper-cpp-local', {
	start: startAudioWhisper,
	stop: stopAudioWhisper,
	switchDevice: switchDeviceWhisper,
});

sttStrategy.register('whisper-1', {
	start: startAudioWhisper,
	stop: stopAudioWhisper,
	switchDevice: switchDeviceWhisper,
});

/* ================================ */
//	CONTROLE DE √ÅUDIO
/* ================================ */

/**
 * Inicia captura de √°udio
 */
async function startAudio() {
	const sttModel = getConfiguredSTTModel();
	Logger.info('startAudio', { model: sttModel });  // antigo debugLogRenderer

	try {
		await sttStrategy.start(sttModel, UIElements);
	} catch (error) {
		Logger.error('Erro ao iniciar √°udio', { error: error.message });  // antigo console.error
		throw error;
	}
}

/**
 * Para captura de √°udio
 */
async function stopAudio() {
	// Fecha pergunta atual se estava aberta
	if (currentQuestion.text) closeCurrentQuestionForced();

	const sttModel = getConfiguredSTTModel();
	Logger.info('stopAudio', { model: sttModel });  // antigo debugLogRenderer

	try {
		await sttStrategy.stop(sttModel);
	} catch (error) {
		Logger.error('Erro ao parar √°udio', { error: error.message });  // antigo console.error
	}
}

/**
 * Reinicia pipeline de √°udio
 */
async function restartAudioPipeline() {
	debugLogRenderer('In√≠cio da fun√ß√£o: "restartAudioPipeline"');

	stopAudio();

	debugLogRenderer('Fim da fun√ß√£o: "restartAudioPipeline"');
}

/**
 * Toggle do bot√£o de iniciar/parar escuta (Ctrl+D)
 */
async function listenToggleBtn() {
	debugLogRenderer('In√≠cio da fun√ß√£o: "listenToggleBtn"');

	if (!isRunning) {
		console.log('üé§ listenToggleBtn: Tentando INICIAR escuta...');

		// üî• VALIDA√á√ÉO 1: Modelo de IA ativo
		const { active: hasModel, model: activeModel } = hasActiveModel();
		debugLogRenderer(`üìä DEBUG: hasModel = ${hasModel}, activeModel = ${activeModel}`, false);

		if (!hasModel) {
			const errorMsg = 'Ative um modelo de IA antes de come√ßar a ouvir';
			console.warn(`‚ö†Ô∏è ${errorMsg}`);
			emitUIChange('onError', errorMsg);
			return;
		}

		// üî• VALIDA√á√ÉO 2: Dispositivo de √°udio de SA√çDA (obrigat√≥rio para ouvir a reuni√£o)
		const hasOutputDevice = UIElements.outputSelect?.value;
		debugLogRenderer(`üìä DEBUG: hasOutputDevice = ${hasOutputDevice}`, false);

		if (!hasOutputDevice) {
			const errorMsg = 'Selecione um dispositivo de √°udio (output) para ouvir a reuni√£o';
			console.warn(`‚ö†Ô∏è ${errorMsg}`);
			console.log('üì° DEBUG: Emitindo onError:', errorMsg);
			emitUIChange('onError', errorMsg);
			return;
		}
	}

	// Inverte o estado de isRunning
	isRunning = !isRunning;
	const buttonText = isRunning ? 'Parar a Escuta... (Ctrl+d)' : 'Come√ßar a Ouvir... (Ctrl+d)';
	const statusMsg = isRunning ? 'Status: ouvindo...' : 'Status: parado';

	// Emite o evento 'onListenButtonToggle' para atualizar o bot√£o de escuta
	emitUIChange('onListenButtonToggle', {
		isRunning,
		buttonText,
	});

	// Atualiza o status da escuta na tela
	updateStatusMessage(statusMsg);

	await (isRunning ? startAudio() : stopAudio());

	debugLogRenderer('Fim da fun√ß√£o: "listenToggleBtn"');
}

/**
 * Verifica se h√° um modelo de IA ativo na configura√ß√£o
 * @returns {object} { active: boolean, model: string|null }
 */
function hasActiveModel() {
	debugLogRenderer('In√≠cio da fun√ß√£o: "hasActiveModel"');
	if (!window.configManager) {
		console.warn('‚ö†Ô∏è ConfigManager n√£o inicializado ainda');
		return { active: false, model: null };
	}

	const config = window.configManager.config;
	if (!config || !config.api) {
		console.warn('‚ö†Ô∏è Config ou api n√£o dispon√≠vel');
		return { active: false, model: null };
	}

	// Verifica se algum modelo est√° ativo e retorna o nome
	const providers = ['openai', 'google', 'openrouter', 'custom'];
	for (const provider of providers) {
		if (config.api[provider] && config.api[provider].enabled === true) {
			console.log(`‚úÖ Modelo ativo encontrado: ${provider}`);
			return { active: true, model: provider };
		}
	}

	console.warn('‚ö†Ô∏è Nenhum modelo ativo encontrado');

	debugLogRenderer('Fim da fun√ß√£o: "hasActiveModel"');
	return { active: false, model: null };
}

/* ================================ */
//	RENDERIZA√á√ÉO E NAVEGA√á√ÉO DE UI
/* ================================ */

/**
 * Renderiza a pergunta atual (CURRENT)
 */
function renderCurrentQuestion() {
	debugLogRenderer('In√≠cio da fun√ß√£o: "renderCurrentQuestion"');

	// Se n√£o h√° texto, emite vazio
	if (!currentQuestion.text) {
		emitUIChange('onCurrentQuestionUpdate', { text: '', isSelected: false });
		return;
	}

	let label = currentQuestion.text;

	// Adiciona timestamp se modo debug m√©tricas ativo
	if (ENABLE_INTERVIEW_TIMING_DEBUG_METRICS && currentQuestion.lastUpdateTime) {
		const time = new Date(currentQuestion.lastUpdateTime).toLocaleTimeString();
		label = `‚è±Ô∏è ${time} ‚Äî ${label}`;
	}

	// üî• Gera dados estruturados - config-manager renderiza no DOM
	const questionData = {
		text: label,
		isSelected: selectedQuestionId === CURRENT_QUESTION_ID,
		rawText: currentQuestion.text,
		createdAt: currentQuestion.createdAt,
		lastUpdateTime: currentQuestion.lastUpdateTime,
	};

	// Emite evento para o config-manager renderizar no DOM
	emitUIChange('onCurrentQuestionUpdate', questionData);

	debugLogRenderer('Fim da fun√ß√£o: "renderCurrentQuestion"');
}

/**
 * Manipula clique em pergunta
 * @param {string} questionId - ID da pergunta selecionada
 */
function handleQuestionClick(questionId) {
	debugLogRenderer('In√≠cio da fun√ß√£o: "handleQuestionClick"');
	selectedQuestionId = questionId;
	clearAllSelections();
	renderQuestionsHistory();
	renderCurrentQuestion();

	// ‚ö†Ô∏è CURRENT nunca bloqueia resposta
	if (questionId !== CURRENT_QUESTION_ID) {
		const existingAnswer = findAnswerByQuestionId(questionId);

		if (existingAnswer) {
			emitUIChange('onAnswerSelected', {
				questionId: questionId,
				shouldScroll: true,
			});

			updateStatusMessage('üìå Essa pergunta j√° foi respondida');
			return;
		}
	}

	// Se for uma pergunta do hist√≥rico marcada como incompleta, n√£o enviar automaticamente ao GPT
	if (questionId !== CURRENT_QUESTION_ID) {
		const q = questionsHistory.find(q => q.id === questionId);
		if (q && q.incomplete) {
			updateStatusMessage('‚ö†Ô∏è Pergunta incompleta ‚Äî pressione o bot√£o de responder para enviar ao GPT');
			console.log('‚ÑπÔ∏è pergunta incompleta selecionada ‚Äî aguarda envio manual:', q.text);
			return;
		}
	}

	if (
		ModeController.isInterviewMode() &&
		selectedQuestionId === CURRENT_QUESTION_ID &&
		gptAnsweredTurnId === interviewTurnId
	) {
		updateStatusMessage('‚õî GPT j√° respondeu esse turno');
		console.log('‚õî GPT j√° respondeu esse turno');
		return;
	}

	// ‚ùì Ainda n√£o respondida ‚Üí chama GPT (click ou atalho)
	askGpt();

	debugLogRenderer('Fim da fun√ß√£o: "handleQuestionClick"');
}

/**
 * Aplica opacidade na interface
 * MOVIDA PARA: config-manager.js
 * @deprecated Usar ConfigManager.applyOpacity(value) em vez disso
 */

/**
 * Rola a lista de perguntas para a pergunta selecionada
 */
function scrollToSelectedQuestion() {
	emitUIChange('onScrollToQuestion', {
		questionId: selectedQuestionId,
	});
}

/**
 * Configura√ß√£o do Marked.js para renderiza√ß√£o de Markdown
 */
marked.setOptions({
	html: true, // üî• Permite renderiza√ß√£o de HTML (n√£o escapa entidades)
	breaks: true,
	gfm: true, // GitHub Flavored Markdown
	highlight: function (code, lang) {
		if (lang && hljs.getLanguage(lang)) {
			return hljs.highlight(code, { language: lang }).value;
		}
		return hljs.highlightAuto(code).value;
	},
});

/* ================================ */
//	CONSOLIDA√á√ÉO E FINALIZA√á√ÉO DE PERGUNTAS
/* ================================ */

/**
 * Fluxo para consolidar transcri√ß√µes no CURRENT
 * Concatena transcri√ß√£o interims e finais
 * @param {string} author - Autor da fala (YOU ou OTHER)
 * @param {string} text - Texto da fala
 * @param {object} options - Op√ß√µes (isInterim, shouldFinalizeAskCurrent)
 */
function handleCurrentQuestion(author, text, options = {}) {
	debugLogRenderer('In√≠cio da fun√ß√£o: "handleCurrentQuestion"');

	const cleaned = text.replace(/√ä+|hum|ahn/gi, '').trim();

	// Usa o tempo exato que chegou no renderer (Date.now)
	const now = Date.now();

	// Apenas consolida falas no CURRENT do OTHER
	if (author === OTHER) {
		// Se n√£o existe texto ainda, marca tempo de cria√ß√£o e incrementa turno
		if (!currentQuestion.text) {
			currentQuestion.createdAt = now;
			interviewTurnId++;
		}

		currentQuestion.lastUpdateTime = now;
		currentQuestion.lastUpdate = now;

		debugLogRenderer('currentQuestion antes: ', { ...currentQuestion }, false);

		// L√≥gica de consolida√ß√£o para evitar duplica√ß√µes
		if (options.isInterim) {
			// Para interims: substituir o interim atual (Deepgram envia vers√µes progressivas)
			currentQuestion.interimText = cleaned;
		} else {
			// Para finais: limpar interim e ACUMULAR no finalText
			currentQuestion.interimText = '';
			currentQuestion.finalText = (currentQuestion.finalText ? currentQuestion.finalText + ' ' : '') + cleaned;
		}

		debugLogRenderer('currentQuestion durante: ', { ...currentQuestion }, false);

		// Atualizar o texto total
		currentQuestion.text =
			currentQuestion.finalText.trim() + (currentQuestion.interimText ? ' ' + currentQuestion.interimText : '');

		debugLogRenderer('currentQuestion depois: ', { ...currentQuestion }, false);

		// üü¶ CURRENT vira sele√ß√£o padr√£o ao receber fala
		if (!selectedQuestionId) {
			selectedQuestionId = CURRENT_QUESTION_ID;
			clearAllSelections();
		}

		// Adiciona TUDO √† conversa visual em tempo real ao elemento "currentQuestionText"
		renderCurrentQuestion();

		// S√≥ finaliza se estivermos em sil√™ncio e N√ÉO for um interim
		if (options.shouldFinalizeAskCurrent && !options.isInterim) {
			debugLogRenderer('üü¢ ********  Est√° em sil√™ncio, feche a pergunta e chame o GPT ü§ñ ******** üü¢', true);

			// fecha/finaliza a pergunta atual
			finalizeCurrentQuestion();
		}
	}

	debugLogRenderer('Fim da fun√ß√£o: "handleCurrentQuestion"');
}

/**
 * Finaliza a pergunta atual para hist√≥rico
 */
function finalizeCurrentQuestion() {
	debugLogRenderer('In√≠cio da fun√ß√£o: "finalizeCurrentQuestion"');

	// Se n√£o h√° texto, ignorar
	if (!currentQuestion.text || !currentQuestion.text.trim()) {
		console.log('‚ö†Ô∏è finalizeCurrentQuestion: Sem texto para finalizar');
		return;
	}

	// üîí GUARDA ABSOLUTA: Se a pergunta j√° foi finalizada, N√ÉO fa√ßa nada.
	if (currentQuestion.finalized) {
		console.log('‚õî finalizeCurrentQuestion ignorado ‚Äî pergunta j√° finalizada');
		return;
	}

	// ‚ö†Ô∏è No modo entrevista, N√ÉO abortar o fechamento
	if (ModeController.isInterviewMode()) {
		currentQuestion.text = finalizeQuestion(currentQuestion.text);
		currentQuestion.lastUpdateTime = Date.now();
		currentQuestion.finalized = true;

		// garante sele√ß√£o l√≥gica
		selectedQuestionId = CURRENT_QUESTION_ID;

		// chama GPT automaticamente se ainda n√£o respondeu este turno
		if (gptRequestedTurnId !== interviewTurnId && gptAnsweredTurnId !== interviewTurnId) {
			askGpt();
		}

		return;
	}

	//  ‚ö†Ô∏è No modo normal - trata perguntas que parecem incompletas
	if (!ModeController.isInterviewMode()) {
		console.log('‚ö†Ô∏è No modo normal detectado ‚Äî promovendo ao hist√≥rico sem chamar GPT:', currentQuestion.text);

		// promoteCurrentToHistory(currentQuestion.text);
		const newId = String(questionsHistory.length + 1);
		questionsHistory.push({
			id: newId,
			text: currentQuestion.text,
			createdAt: currentQuestion.createdAt || Date.now(),
			lastUpdateTime: currentQuestion.lastUpdateTime || currentQuestion.createdAt || Date.now(),
		});

		selectedQuestionId = newId;
		resetCurrentQuestion();
		renderQuestionsHistory();

		return;
	}
}

/**
 * For√ßa o fechamento da pergunta atual, promovendo-a ao hist√≥rico
 */
function closeCurrentQuestionForced() {
	debugLogRenderer('In√≠cio da fun√ß√£o: "closeCurrentQuestionForced"');

	// log temporario para testar a aplica√ß√£o s√≥ remover depois
	console.log('üö™ Fechando pergunta:', currentQuestion.text);

	if (!currentQuestion.text) return;

	questionsHistory.push({
		id: crypto.randomUUID(),
		text: finalizeQuestion(currentQuestion.text),
		createdAt: currentQuestion.createdAt || Date.now(),
	});

	currentQuestion.text = '';
	selectedQuestionId = null; // üëà libera sele√ß√£o
	renderQuestionsHistory();
	renderCurrentQuestion();

	debugLogRenderer('Fim da fun√ß√£o: "closeCurrentQuestionForced"');
}

/* ================================ */
//	SISTEMA GPT E STREAMING
/* ================================ */

/**
 * Envia pergunta selecionada ao LLM (qualquer provider)
 * ‚úÖ REFATORADA: agora √© simples e leg√≠vel!
 * ‚úÖ CENTRALIZADA: Uma √∫nica fun√ß√£o para todos os LLMs
 * ‚úÖ N√£o h√° duplica√ß√£o de askLLM() por LLM
 */
async function askLLM() {  // antigo askGpt()
	try {
		const CURRENT_QUESTION_ID = 'CURRENT';

		// 1. Validar (antigo validateAskGptRequest)
		const { questionId, text, isCurrent } = validateLLMRequest(
			appState,
			selectedQuestionId,
			getSelectedQuestionText,
		);
		Logger.info('Pergunta v√°lida', { questionId, textLength: text.length });

		// Rastreamento antigo (compatibilidade)
		const normalizedText = normalizeForCompare(text);
		transcriptionMetrics.gptStartTime = Date.now();

		if (isCurrent) {
			gptRequestedTurnId = interviewTurnId;
			gptRequestedQuestionId = CURRENT_QUESTION_ID;
			lastAskedQuestionNormalized = normalizedText;
		}

		// 2. Rotear por modo (n√£o por LLM!)
		const isInterviewMode = ModeController.isInterviewMode();

		if (isInterviewMode) {
			await handleLLMStream(appState, questionId, text, SYSTEM_PROMPT, eventBus, llmManager);  // antigo handleAskGptStream
		} else {
			await handleLLMBatch(appState, questionId, text, SYSTEM_PROMPT, eventBus, llmManager);  // antigo handleAskGptBatch
		}
		// O llmManager sabe qual LLM usar (OpenAI, Gemini, etc)
		// Sem duplica√ß√£o de c√≥digo!
	} catch (error) {
		Logger.error('Erro em askLLM', { error: error.message });
		eventBus.emit('error', error.message);
		updateStatusMessage(`‚ùå ${error.message}`);
	}
}

/**
 * Log detalhado das m√©tricas de tempo da transcri√ß√£o
 */
function logTranscriptionMetrics() {
	if (!transcriptionMetrics.audioStartTime) return;

	const gptTime = transcriptionMetrics.gptEndTime - transcriptionMetrics.gptStartTime;
	const totalTime = transcriptionMetrics.totalTime;

	console.log(`üìä ================================`);
	console.log(`üìä M√âTRICAS DE TEMPO DETALHADAS:`);
	console.log(`üìä ================================`);
	console.log(`üìä TAMANHO √ÅUDIO: ${transcriptionMetrics.audioSize} bytes`);
	console.log(`üìä GPT: ${gptTime}ms`);
	console.log(`üìä TOTAL: ${totalTime}ms`);
	console.log(`üìä GPT % DO TOTAL: ${Math.round((gptTime / totalTime) * 100)}%`);
	console.log(`üìä ================================`);

	// Reset para pr√≥xima medi√ß√£o
	transcriptionMetrics = {
		audioStartTime: null,
		gptStartTime: null,
		gptEndTime: null,
		totalTime: null,
		audioSize: 0,
	};
}

/* ================================ */
//	SCREENSHOT E AN√ÅLISE
/* ================================ */

/**
 * Captura screenshot discretamente e armazena em mem√≥ria
 */
async function captureScreenshot() {
	if (isCapturing) {
		console.log('‚è≥ Captura j√° em andamento...');
		return;
	}

	isCapturing = true;
	updateStatusMessage('üì∏ Capturando tela...');

	try {
		const result = await ipcRenderer.invoke('CAPTURE_SCREENSHOT');

		if (!result.success) {
			console.warn('‚ö†Ô∏è Falha na captura:', result.error);
			updateStatusMessage(`‚ùå ${result.error}`);
			emitUIChange('onScreenshotBadgeUpdate', {
				count: capturedScreenshots.length,
				visible: capturedScreenshots.length > 0,
			});
			return;
		}

		// ‚úÖ Armazena refer√™ncia do screenshot
		capturedScreenshots.push({
			filepath: result.filepath,
			filename: result.filename,
			timestamp: result.timestamp,
			size: result.size,
		});

		console.log(`‚úÖ Screenshot capturado: ${result.filename}`);
		console.log(`üì¶ Total em mem√≥ria: ${capturedScreenshots.length}`);

		// Atualiza UI
		updateStatusMessage(`‚úÖ ${capturedScreenshots.length} screenshot(s) capturado(s)`);
		emitUIChange('onScreenshotBadgeUpdate', {
			count: capturedScreenshots.length,
			visible: true,
		});
	} catch (error) {
		console.error('‚ùå Erro ao capturar screenshot:', error);
		updateStatusMessage('‚ùå Erro na captura');
	} finally {
		isCapturing = false;
	}
}

/**
 * Envia screenshots para an√°lise com OpenAI Vision
 */
async function analyzeScreenshots() {
	if (isAnalyzing) {
		Logger.info('An√°lise j√° em andamento');
		return;
	}

	if (capturedScreenshots.length === 0) {
		Logger.warn('Nenhum screenshot para analisar');
		updateStatusMessage('‚ö†Ô∏è Nenhum screenshot para analisar (capture com Ctrl+Shift+F)');
		return;
	}

	isAnalyzing = true;
	updateStatusMessage(`üîç Analisando ${capturedScreenshots.length} screenshot(s)...`);

	try {
		// Extrai caminhos dos arquivos
		const filepaths = capturedScreenshots.map(s => s.filepath);

		Logger.info('Enviando para an√°lise', { count: filepaths.length });

		// Envia para main.js
		const result = await ipcRenderer.invoke('ANALYZE_SCREENSHOTS', filepaths);

		if (!result.success) {
			Logger.error('Falha na an√°lise', { error: result.error });
			updateStatusMessage(`‚ùå ${result.error}`);
			return;
		}

		// ‚úÖ Renderiza resposta do GPT
		const questionText = `üì∏ An√°lise de ${capturedScreenshots.length} screenshot(s)`;
		const questionId = String(questionsHistory.length + 1);

		// Adiciona "pergunta" ao hist√≥rico ANTES de renderizar respostas
		questionsHistory.push({
			id: questionId,
			text: questionText,
			createdAt: Date.now(),
			lastUpdateTime: Date.now(),
			answered: true,
		});

		// ‚úÖ MARCA COMO RESPONDIDA (importante para clique n√£o gerar duplicata)
		answeredQuestions.add(questionId);

		renderQuestionsHistory();

		// ‚úÖ RENDERIZA VIA EVENTBUS (consistente com LLM)
		// Divide an√°lise em tokens e emite como se fosse stream
		const analysisText = result.analysis;
		const tokens = analysisText.split(/(\s+|[.,!?;:\-\(\)\[\]{}\n])/g).filter(t => t.length > 0);

		Logger.info('Simulando stream', { tokenCount: tokens.length });

		// Emite tokens via eventBus (consistente com askLLM)
		let accumulated = '';
		for (const token of tokens) {
			accumulated += token;

			eventBus.emit('answerStreamChunk', {
				questionId: questionId,
				token: token,
				accum: accumulated,
			});

			// Pequeno delay entre tokens para simular streaming real
			await new Promise(resolve => setTimeout(resolve, 2));
		}

		Logger.info('An√°lise conclu√≠da');
		updateStatusMessage('‚úÖ An√°lise conclu√≠da');

		// üóëÔ∏è Limpa screenshots ap√≥s an√°lise
		Logger.info('Limpando screenshots', { count: capturedScreenshots.length });
		capturedScreenshots = [];

		// Atualiza badge
		emitUIChange('onScreenshotBadgeUpdate', {
			count: 0,
			visible: false,
		});

		// For√ßa limpeza no sistema
		await ipcRenderer.invoke('CLEANUP_SCREENSHOTS');
	} catch (error) {
		Logger.error('Erro ao analisar screenshots', { error: error.message });
		updateStatusMessage('‚ùå Erro na an√°lise');
	} finally {
		isAnalyzing = false;
	}
}

/**
 * Limpa todos os screenshots armazenados
 */
function clearScreenshots() {
	if (capturedScreenshots.length === 0) return;

	console.log(`üóëÔ∏è Limpando ${capturedScreenshots.length} screenshot(s)...`);
	capturedScreenshots = [];

	updateStatusMessage('‚úÖ Screenshots limpos');
	emitUIChange('onScreenshotBadgeUpdate', {
		count: 0,
		visible: false,
	});

	// For√ßa limpeza no sistema
	ipcRenderer.invoke('CLEANUP_SCREENSHOTS').catch(err => {
		console.warn('‚ö†Ô∏è Erro na limpeza:', err);
	});
}

/* ================================ */
//	RESET COMPLETO
/* ================================ */

/**
 * Libera a thread para o navegador processar eventos
 * @param {number} ms - Milissegundos para aguardar (default 0 = pr√≥ximo frame)
 */
function releaseThread(ms = 0) {
	return new Promise(resolve => setTimeout(resolve, ms));
}

/**
 * Reseta todo o estado do app
 * Quebrado em chunks para n√£o bloquear a UI thread
 */
async function resetAppState() {
	console.log('üßπ ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');
	console.log('üßπ INICIANDO RESET COMPLETO DO APP');
	console.log('üßπ ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');

	try {
		// 1Ô∏è‚É£ CHUNK 1: Parar autoplay e √°udio
		mockAutoPlayActive = false;
		mockScenarioIndex = 0;
		if (isRunning) {
			console.log('üé§ Parando captura de √°udio...');
			isRunning = false;
		}
		console.log('‚úÖ Autoplay do mock parado');
		await releaseThread();

		// 2Ô∏è‚É£ CHUNK 2: Limpar perguntas e respostas
		currentQuestion = {
			text: '',
			lastUpdate: 0,
			finalized: false,
			lastUpdateTime: null,
			createdAt: null,
			finalText: '',
			interimText: '',
		};
		questionsHistory = [];
		answeredQuestions.clear();
		selectedQuestionId = null;
		lastAskedQuestionNormalized = null;
		console.log('‚úÖ Perguntas e respostas limpas');
		await releaseThread();

		// 3Ô∏è‚É£ CHUNK 3: Limpar estado GPT e m√©tricas
		interviewTurnId = 0;
		gptAnsweredTurnId = null;
		gptRequestedTurnId = null;
		gptRequestedQuestionId = null;
		transcriptionMetrics = {
			audioStartTime: null,
			gptStartTime: null,
			gptEndTime: null,
			totalTime: null,
			audioSize: 0,
		};
		console.log('‚úÖ Estado de entrevista resetado');
		console.log('‚úÖ M√©tricas resetadas');
		await releaseThread();

		// 4Ô∏è‚É£ CHUNK 4: Limpar screenshots
		if (capturedScreenshots.length > 0) {
			console.log(`üóëÔ∏è Limpando ${capturedScreenshots.length} screenshot(s)...`);
			capturedScreenshots = [];
			emitUIChange('onScreenshotBadgeUpdate', {
				count: 0,
				visible: false,
			});
			// For√ßa limpeza no sistema (async, n√£o bloqueia)
			try {
				await ipcRenderer.invoke('CLEANUP_SCREENSHOTS');
			} catch (err) {
				console.warn('‚ö†Ô∏è Erro ao limpar screenshots no sistema:', err);
			}
		}
		console.log('‚úÖ Screenshots limpos');
		await releaseThread();

		// 5Ô∏è‚É£ CHUNK 5: Limpar flags
		isCapturing = false;
		isAnalyzing = false;
		console.log('‚úÖ Flags resetadas');
		await releaseThread();

		// 6Ô∏è‚É£ CHUNK 6: Atualizar UI - Perguntas
		emitUIChange('onCurrentQuestionUpdate', {
			text: '',
			isSelected: false,
		});
		emitUIChange('onQuestionsHistoryUpdate', []);
		console.log('‚úÖ Perguntas UI limpa');
		await releaseThread();

		// 7Ô∏è‚É£ CHUNK 7: Atualizar UI - Transcri√ß√µes e Respostas
		emitUIChange('onTranscriptionCleared');
		emitUIChange('onAnswersCleared');
		console.log('‚úÖ Transcri√ß√µes e respostas UI limpas');
		await releaseThread();

		// 8Ô∏è‚É£ CHUNK 8: Atualizar UI - Bot√£o Listen
		emitUIChange('onListenButtonToggle', {
			isRunning: false,
			buttonText: 'üé§ Come√ßar a Ouvir... (Ctrl+D)',
		});
		console.log('‚úÖ Bot√£o listen resetado');
		await releaseThread();

		// 9Ô∏è‚É£ CHUNK 9: Atualizar UI - Status
		emitUIChange('onStatusUpdate', {
			status: 'ready',
			message: '‚úÖ Pronto',
		});
		console.log('‚úÖ Status atualizado');
		await releaseThread();

		// üîü CHUNK 10: Limpar sele√ß√µes
		clearAllSelections();
		console.log('‚úÖ Sele√ß√µes limpas');
		await releaseThread();

		// 1Ô∏è‚É£1Ô∏è‚É£ LOG FINAL
		console.log('‚úÖ ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');
		console.log('‚úÖ RESET COMPLETO CONCLU√çDO COM SUCESSO');
		console.log('‚úÖ ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');

		return true;
	} catch (error) {
		console.error('‚ùå Erro ao resetar app:', error);
		return false;
	}
}

/**
 * Fun√ß√£o auxiliar para liberar a thread do navegador
 * Usada em resetAppState() para quebrar opera√ß√µes longas em chunks
 */
function releaseThread(ms = 0) {
	return new Promise(resolve => setTimeout(resolve, ms));
}

/* ================================ */
//	MOCK / DEBUG
/* ================================ */

/**
 * Respostas mockadas por pergunta
 */
const MOCK_RESPONSES = {
	'Mock - O que √© JVM e para que serve?':
		'Mock - A JVM (Java Virtual Machine) √© uma m√°quina virtual que executa bytecode Java. Ela permite que programas Java rodem em qualquer plataforma sem modifica√ß√£o. A JVM gerencia mem√≥ria, garbage collection e fornece um ambiente isolado e seguro para execu√ß√£o de c√≥digo.',
	'Mock - Qual a diferen√ßa entre JDK e JRE?':
		'Mock - JDK (Java Development Kit) √© o kit completo para desenvolvimento, incluindo compilador, ferramentas e bibliotecas. JRE (Java Runtime Environment) cont√©m apenas o necess√°rio para executar aplica√ß√µes Java compiladas. Todo desenvolvedor precisa do JDK, mas usu√°rios finais precisam apenas da JRE.',
	'Mock - O que √© uma classe em Java?':
		'Mock - Uma classe √© o molde ou blueprint para criar objetos. Define atributos (propriedades) e m√©todos (comportamentos). As classes s√£o fundamentais na programa√ß√£o orientada a objetos. Por exemplo, uma classe Carro pode ter atributos como cor e velocidade, e m√©todos como acelerar e frear.',
	'Mock - Explique sobre heran√ßa em Java':
		'Mock - Heran√ßa permite que uma classe herde propriedades e m√©todos de outra classe. A classe filha estende a classe pai usando a palavra-chave extends. Isso promove reutiliza√ß√£o de c√≥digo e cria uma hierarquia de classes. Por exemplo, a classe Bicicleta pode herdar de Veiculo.',
	'Mock - Como funciona polimorfismo?':
		'Mock - Polimorfismo significa muitas formas. Permite que objetos de diferentes tipos respondam a mesma chamada de m√©todo de forma diferente. Pode ser atrav√©s de sobrescrita de m√©todos (heran√ßa) ou interface. Exemplo: diferentes animais implementam o m√©todo fazer_som() diferentemente.',
	'Mock - O que √© encapsulamento?':
		'Mock - Encapsulamento √© o princ√≠pio de ocultar detalhes internos da implementa√ß√£o. Usa modificadores de acesso como private, protected e public. Protege dados e m√©todos cr√≠ticos, permitindo controle sobre como s√£o acessados. √â uma pilar da seguran√ßa e manuten√ß√£o do c√≥digo orientado a objetos.',
};

/**
 * Cen√°rios autom√°ticos para teste
 * screenshotsCount: 0 = sem screenshot, 1 = tira 1 foto, 2 = tira 2 fotos, etc
 */
const MOCK_SCENARIOS = [
	{ question: 'Mock - O que √© JVM e para que serve?', screenshotsCount: 1 },
	{ question: 'Mock - Qual a diferen√ßa entre JDK e JRE?', screenshotsCount: 0 },
	{ question: 'Mock - O que √© uma classe em Java?', screenshotsCount: 0 },
	{ question: 'Mock - Explique sobre heran√ßa em Java', screenshotsCount: 2 },
	{ question: 'Mock - Como funciona polimorfismo?', screenshotsCount: 0 },
	{ question: 'Mock - O que √© encapsulamento?', screenshotsCount: 0 },
];

let mockScenarioIndex = 0;
let mockAutoPlayActive = false;

/**
 * Retorna resposta mockada para pergunta
 * Busca exata ou parcial
 * @param {string} question - Pergunta
 * @returns {string} Resposta mockada
 */
function getMockResponse(question) {
	// Match exato
	if (MOCK_RESPONSES[question]) {
		return MOCK_RESPONSES[question];
	}

	// Match parcial
	for (const [key, value] of Object.entries(MOCK_RESPONSES)) {
		if (question.toLowerCase().includes(key.toLowerCase())) {
			return value;
		}
	}

	// Fallback
	return `Resposta mockada para: "${question}"\n\nEste √© um teste do sistema em modo Mock.`;
}

/**
 * Intercepta chamadas IPC para MOCK quando APP_CONFIG.MODE_DEBUG est√° ativo
 */
const originalInvoke = ipcRenderer.invoke;
ipcRenderer.invoke = function (channel, ...args) {
	// Intercepta an√°lise de screenshots quando MODE_DEBUG
	// IMPORTANTE: CAPTURE_SCREENSHOT √© REAL (tira foto mesmo), ANALYZE_SCREENSHOTS √© MOCK (simula resposta)
	if (channel === 'ANALYZE_SCREENSHOTS' && APP_CONFIG.MODE_DEBUG) {
		console.log('üì∏ [MOCK] Interceptando ANALYZE_SCREENSHOTS...');
		const filepaths = args[0] || [];
		const screenshotCount = filepaths.length;

		// Retorna an√°lise mockada
		const mockAnalysis = `
		## üì∏ An√°lise de ${screenshotCount} Screenshot(s) - MOCK

		### Esta √© uma resposta simulada para o teste do sistema.

		Para resolver o problema apresentado na captura de tela, que √© o "Remove Element" do LeetCode, vamos implementar uma fun√ß√£o em Java que remove todas as ocorr√™ncias de um valor espec√≠fico de um array. A fun√ß√£o deve modificar o array in-place e retornar o novo comprimento do array.

		Resumo do Problema
		Entrada: Um array de inteiros nums e um inteiro val que queremos remover.
		Sa√≠da: O novo comprimento do array ap√≥s remover todas as ocorr√™ncias de val.
		Passos para a Solu√ß√£o
		Iterar pelo array: Vamos percorrer o array e verificar cada elemento.
		Manter um √≠ndice: Usaremos um √≠ndice para rastrear a posi√ß√£o onde devemos colocar os elementos que n√£o s√£o iguais a val.
		Modificar o array in-place: Sempre que encontrarmos um elemento que n√£o √© igual a val, colocamos esse elemento na posi√ß√£o do √≠ndice e incrementamos o √≠ndice.
		Retornar o comprimento: No final, o √≠ndice representar√° o novo comprimento do array.
		Implementa√ß√£o do C√≥digo
		Aqui est√° a implementa√ß√£o em Java:

		class Solution {
			public int removeElement(int[] nums, int val) {
				// Inicializa um √≠ndice para rastrear a nova posi√ß√£o
				int index = 0;

				// Percorre todos os elementos do array
				for (int i = 0; i &lt; nums.length; i++) {
					// Se o elemento atual n√£o √© igual a val
					if (nums[i] != val) {
						// Coloca o elemento na posi√ß√£o do √≠ndice
						nums[index] = nums[i];
						// Incrementa o √≠ndice
						index++;
					}
				}

				// Retorna o novo comprimento do array
				return index;
			}
		}

		Explica√ß√£o do C√≥digo
		Classe e M√©todo: Criamos uma classe chamada Solution e um m√©todo removeElement que recebe um array de inteiros nums e um inteiro val.
		√çndice Inicial: Inicializamos uma vari√°vel index em 0.
		`;

		return Promise.resolve({
			success: true,
			analysis: mockAnalysis,
			filesAnalyzed: screenshotCount,
			timestamp: Date.now(),
		});
	}

	// Intercepta ask-gpt-stream quando MODE_DEBUG
	if (channel === 'ask-gpt-stream' && APP_CONFIG.MODE_DEBUG) {
		console.log('üé≠ [MOCK] Interceptando ask-gpt-stream...');

		// Obt√©m a pergunta do primeiro argumento (array de mensagens)
		const messages = args[0] || [];
		const userMessage = messages.find(m => m.role === 'user');
		const questionText = userMessage ? userMessage.content : 'Pergunta desconhecida';

		// Busca resposta mockada
		const mockResponse = getMockResponse(questionText);

		// Divide em tokens (remove vazios)
		const tokens = mockResponse.split(/(\s+|[.,!?;:\-\(\)\[\]{}\n])/g).filter(t => t.length > 0);

		console.log(`üé≠ [MOCK] Emitindo ${tokens.length} tokens para pergunta: "${questionText.substring(0, 50)}..."`);

		// Fun√ß√£o para emitir tokens com pequeno delay entre eles
		async function emitTokens() {
			let accumulated = '';
			for (let i = 0; i < tokens.length; i++) {
				const token = tokens[i];
				accumulated += token;

				// Emite o evento com delay m√≠nimo
				await new Promise(resolve => {
					setTimeout(() => {
						// ‚úÖ CORRETO: Emite apenas o token como 2¬∫ argumento
						ipcRenderer.emit('GPT_STREAM_CHUNK', null, token);
						resolve();
					}, 5); // 5ms entre tokens
				});
			}

			// Sinaliza fim do stream ap√≥s todos os tokens
			await new Promise(resolve => {
				setTimeout(() => {
					ipcRenderer.emit('GPT_STREAM_END');
					resolve();
				}, 10);
			});
		}

		// Inicia emiss√£o de tokens de forma ass√≠ncrona
		emitTokens().catch(err => {
			console.error('‚ùå Erro ao emitir tokens mock:', err);
		});

		// Retorna promise resolvida imediatamente (esperado pela API)
		return Promise.resolve({ success: true });
	}

	// Todas as outras chamadas passam para o invoke real
	return originalInvoke.call(this, channel, ...args);
};

/**
 * Fun√ß√£o de autoplay autom√°tico para mockar perguntas e respostas
 */
async function runMockAutoPlay() {
	if (mockAutoPlayActive) return;
	mockAutoPlayActive = true;

	while (mockScenarioIndex < MOCK_SCENARIOS.length && APP_CONFIG.MODE_DEBUG && mockAutoPlayActive) {
		const scenario = MOCK_SCENARIOS[mockScenarioIndex];
		console.log(
			`\nüé¨ ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nüé¨ MOCK CEN√ÅRIO ${mockScenarioIndex + 1}/${
				MOCK_SCENARIOS.length
			}\nüé¨ ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê`,
		);

		// FASE 1: Simula captura de √°udio (2-4s)
		console.log(`üé§ [FASE-1] Capturando √°udio da pergunta...`);
		const audioStartTime = Date.now();
		const placeholderId = `placeholder-${audioStartTime}-${Math.random()}`;

		// Emite placeholder
		emitUIChange('onTranscriptAdd', {
			author: 'Outros',
			text: '...',
			timeStr: new Date().toLocaleTimeString(),
			elementId: 'conversation',
			placeholderId: placeholderId,
		});

		// Aguarda captura
		await new Promise(resolve => setTimeout(resolve, 2000 + Math.random() * 2000));

		// üî• CHECK: Se modo debug foi desativado, para imediatamente
		if (!APP_CONFIG.MODE_DEBUG || !mockAutoPlayActive) {
			console.log('üõë [PARADA] Modo debug desativado - parando mock autoplay');
			break;
		}

		const audioEndTime = Date.now();
		console.log(`‚úÖ [FASE-1] √Åudio capturado`);

		// Calcula lat√™ncia (arredonda para inteiro - sem casas decimais)
		const latencyMs = Math.round(800 + Math.random() * 400);
		const totalMs = audioEndTime - audioStartTime + latencyMs;

		// Atualiza placeholder com texto real
		emitUIChange('onPlaceholderFulfill', {
			speaker: 'Outros',
			text: scenario.question,
			startStr: new Date(audioStartTime).toLocaleTimeString(),
			stopStr: new Date(audioEndTime).toLocaleTimeString(),
			recordingDuration: audioEndTime - audioStartTime,
			latency: latencyMs,
			total: totalMs,
			placeholderId: placeholderId,
		});

		// FASE 2: Processa pergunta (handleSpeech + closeCurrentQuestion)
		console.log(`üìù [FASE-2] Processando pergunta...`);
		//handleSpeech(OTHER, scenario.question, { skipAddToUI: true });

		// Aguarda consolida√ß√£o (800ms para garantir que pergunta saia do CURRENT)
		await new Promise(resolve => setTimeout(resolve, 800));

		// üî• CHECK: Se modo debug foi desativado, para imediatamente
		if (!APP_CONFIG.MODE_DEBUG || !mockAutoPlayActive) {
			console.log('üõë [PARADA] Modo debug desativado - parando mock autoplay');
			break;
		}

		// Simula sil√™ncio e fecha pergunta
		console.log(`üîá [FASE-2] Sil√™ncio detectado, fechando pergunta...`);
		//closeCurrentQuestion();

		// FASE 3: askGpt ser√° acionado automaticamente, o interceptor (ask-gpt-stream) que ir√° mockar
		console.log(`ü§ñ [FASE-3] askGpt acionado - mock stream ser√° emitido pelo interceptor`);

		// Aguarda stream terminar (~30ms por token)
		const mockResponse = getMockResponse(scenario.question);
		const estimatedTime = mockResponse.length * 30;
		await new Promise(resolve => setTimeout(resolve, estimatedTime + 1000));

		// üî• CHECK: Se modo debug foi desativado, para imediatamente SEM TIRAR SCREENSHOT
		if (!APP_CONFIG.MODE_DEBUG || !mockAutoPlayActive) {
			console.log('üõë [PARADA] Modo debug desativado - parando sem capturar screenshot');
			break;
		}

		// FASE 4 (Opcional): Captura N screenshots REAIS e depois aciona an√°lise
		if (scenario.screenshotsCount && scenario.screenshotsCount > 0) {
			// FASE 4A: Captura m√∫ltiplos screenshots
			for (let i = 1; i <= scenario.screenshotsCount; i++) {
				// üî• CHECK: Verifica antes de cada screenshot
				if (!APP_CONFIG.MODE_DEBUG || !mockAutoPlayActive) {
					console.log(
						`üõë [PARADA] Modo debug desativado - cancelando captura de screenshot ${i}/${scenario.screenshotsCount}`,
					);
					break;
				}

				console.log(`üì∏ [FASE-4A] Capturando screenshot ${i}/${scenario.screenshotsCount} REAL da resposta...`);
				await captureScreenshot();

				// Delay entre m√∫ltiplas capturas para respeitar cooldown de 2s do main.js
				if (i < scenario.screenshotsCount) {
					console.log(`   ‚è≥ Aguardando 2200ms antes da pr√≥xima captura (cooldown CAPTURE_COOLDOWN)...`);
					await new Promise(resolve => setTimeout(resolve, 2200));
				}
			}

			// üî• CHECK: Verifica antes de an√°lise
			if (!APP_CONFIG.MODE_DEBUG || !mockAutoPlayActive) {
				console.log('üõë [PARADA] Modo debug desativado - cancelando an√°lise de screenshots');
				break;
			}

			// Log de valida√ß√£o: quantas fotos tem antes de analisar
			console.log(
				`üì∏ [PR√â-AN√ÅLISE] Total de screenshots em mem√≥ria: ${capturedScreenshots.length}/${scenario.screenshotsCount}`,
			);

			// FASE 4B: An√°lise dos screenshots capturados
			console.log(`üì∏ [FASE-4B] Analisando ${scenario.screenshotsCount} screenshot(s)...`);
			await analyzeScreenshots();
		}

		mockScenarioIndex++;

		if (mockScenarioIndex < MOCK_SCENARIOS.length) {
			console.log(`\n‚è≥ Aguardando 1s antes do pr√≥ximo cen√°rio...\n`);
			await new Promise(resolve => setTimeout(resolve, 1000));
		}
	}

	console.log('‚úÖ Mock autoplay finalizado');
	mockAutoPlayActive = false;
}

/* ================================ */
//	DEBUG LOG RENDERER
/* ================================ */

/**
 * Log de debug padronizado para renderer
 * √öltimo argumento opcional √© booleano para mostrar ou n√£o o log
 * @param {...any} args - Argumentos a logar
 */
function debugLogRenderer(...args) {
	const maybeFlag = args.at(-1);
	const showLog = typeof maybeFlag === 'boolean' ? maybeFlag : false;

	const nowLog = new Date();
	const timeStr =
		`${nowLog.getHours().toString().padStart(2, '0')}:` +
		`${nowLog.getMinutes().toString().padStart(2, '0')}:` +
		`${nowLog.getSeconds().toString().padStart(2, '0')}.` +
		`${nowLog.getMilliseconds().toString().padStart(3, '0')}`;

	if (showLog) {
		const cleanArgs = typeof maybeFlag === 'boolean' ? args.slice(0, -1) : args;
		// prettier-ignore
		console.log(
			`%c‚è±Ô∏è [${timeStr}] ü™≤ ‚ùØ‚ùØ‚ùØ‚ùØ Debug em renderer.js:`,
			'color: brown; font-weight: bold;', 
			...cleanArgs
		);
	}
}

/* ================================ */
//	EXPORTA√á√ÉO PUBLIC API (RendererAPI)
/* ================================ */

/**
 * API P√∫blica exposta do Renderer
 * M√©todos p√∫blicos que podem ser chamados de fora
 */
const RendererAPI = {
	// √Åudio - Grava√ß√£o
	listenToggleBtn,
	askGpt,
	restartAudioPipeline,

	// üî• Estado de transcri√ß√£o (usado pelo audio-volume-monitor.js)
	get isRunning() {
		return isRunning;
	},

	// √Åudio - Monitoramento de volume
	startAudioVolumeMonitor,
	stopAudioVolumeMonitor,
	switchAudioVolumeDevice,

	// Entrevista - Reset (centralizado em resetAppState)
	resetAppState,

	// Modo
	changeMode: mode => {
		CURRENT_MODE = mode;
	},
	getMode: () => CURRENT_MODE,

	// Questions
	handleCurrentQuestion,
	handleQuestionClick,

	// UI
	// üî• MOVED: applyOpacity foi para config-manager.js
	updateMockBadge: show => {
		emitUIChange('onMockBadgeUpdate', { visible: show });
	},
	setMockToggle: checked => {
		APP_CONFIG.MODE_DEBUG = checked;
		// UI ser√° atualizada via emitUIChange
	},
	setModeSelect: mode => {
		emitUIChange('onModeSelectUpdate', { mode });
	},

	// Drag
	/**
	 * Inicializa drag handle para movimento de janela
	 * MOVIDA PARA: config-manager.js
	 * @deprecated Usar ConfigManager.initDragHandle(dragHandle) em vez disso
	 */

	// Click-through
	setClickThrough: enabled => {
		ipcRenderer.send('SET_CLICK_THROUGH', enabled);
	},
	/**
	 * Atualiza bot√£o de click-through
	 * @param {boolean} enabled - Se click-through est√° ativo
	 * @param {element} btnToggle - Bot√£o a atualizar
	 */
	updateClickThroughButton: (enabled, btnToggle) => {
		if (!btnToggle) return;
		btnToggle.style.opacity = enabled ? '0.5' : '1';
		btnToggle.title = enabled
			? 'Click-through ATIVO (clique para desativar)'
			: 'Click-through INATIVO (clique para ativar)';
		console.log('üé® Bot√£o atualizado - opacity:', btnToggle.style.opacity);
	},

	// UI Registration
	registerUIElements: elements => {
		registerUIElements(elements);
	},
	onUIChange: (eventName, callback) => {
		onUIChange(eventName, callback);
	},
	// Emit UI changes (para config-manager enviar eventos para renderer)
	emitUIChange,

	// API Key
	setAppConfig: config => {
		APP_CONFIG = config;
	},
	getAppConfig: () => APP_CONFIG,

	// Navegacao de perguntas (Ctrl+Shift+ArrowUp/Down via globalShortcut IPC)
	/**
	 * Navega entre perguntas
	 * @param {string} direction - 'up' ou 'down'
	 */
	navigateQuestions: direction => {
		const all = getNavigableQuestionIds();
		if (all.length === 0) return;

		let index = all.indexOf(selectedQuestionId);
		if (index === -1) {
			index = direction === 'up' ? all.length - 1 : 0;
		} else {
			index += direction === 'up' ? -1 : 1;
			index = Math.max(0, Math.min(index, all.length - 1));
		}

		selectedQuestionId = all[index];
		clearAllSelections();
		renderQuestionsHistory();
		renderCurrentQuestion();

		if (APP_CONFIG.MODE_DEBUG) {
			const msg = direction === 'up' ? 'üß™ Ctrl+ArrowUp detectado (teste)' : 'üß™ Ctrl+ArrowDown detectado (teste)';
			updateStatusMessage(msg);
			console.log('üìå Atalho Selecionou:', selectedQuestionId);
		}
	},

	// IPC Listeners
	onApiKeyUpdated: callback => {
		ipcRenderer.on('API_KEY_UPDATED', callback);
	},
	onToggleAudio: callback => {
		// Come√ßar a ouvir / Parar de ouvir (Ctrl+D)
		ipcRenderer.on('CMD_TOGGLE_AUDIO', callback);
	},
	onAskGpt: callback => {
		ipcRenderer.on('CMD_ASK_GPT', callback);
	},
	onGptStreamChunk: callback => {
		ipcRenderer.on('GPT_STREAM_CHUNK', callback);
	},
	onGptStreamEnd: callback => {
		ipcRenderer.on('GPT_STREAM_END', callback);
	},
	/**
	 * Envia erro do renderer para main
	 * @param {error} error - Erro a enviar
	 */
	sendRendererError: error => {
		try {
			console.error('RENDERER ERROR', error.error || error.message || error);
			ipcRenderer.send('RENDERER_ERROR', {
				message: String(error.message || error),
				stack: error.error?.stack || null,
			});
		} catch (err) {
			console.error('Falha ao enviar RENDERER_ERROR', err);
		}
	},

	// üì∏ NOVO: Screenshot functions
	captureScreenshot,
	analyzeScreenshots,
	clearScreenshots,
	getScreenshotCount: () => capturedScreenshots.length,

	// üì∏ NOVO: Screenshot shortcuts
	onCaptureScreenshot: callback => {
		ipcRenderer.on('CMD_CAPTURE_SCREENSHOT', callback);
	},
	onAnalyzeScreenshots: callback => {
		ipcRenderer.on('CMD_ANALYZE_SCREENSHOTS', callback);
	},
	// Navegacao de perguntas (Ctrl+Shift+ArrowUp/Down via globalShortcut)
	onNavigateQuestions: callback => {
		ipcRenderer.on('CMD_NAVIGATE_QUESTIONS', (_, direction) => {
			callback(direction);
		});
	},
};

if (typeof module !== 'undefined' && module.exports) {
	// Node.js / CommonJS export
	module.exports = RendererAPI;
}

// üé≠ Exporta para o escopo global (usado em mocks e testes)
if (typeof globalThis !== 'undefined') {
	globalThis.RendererAPI = RendererAPI; // üé≠ Exporta API para escopo global
	globalThis.runMockAutoPlay = runMockAutoPlay; // üé≠ Exportar Mock autoplay
	globalThis.mockScenarioIndex = 0; // üé≠ √çndice global para cen√°rios
	globalThis.mockAutoPlayActive = false; // üé≠ Flag global para evitar m√∫ltiplas execu√ß√µes
}

/* ================================ */
//	LISTENER DO BOT√ÉO RESET
/* ================================ */

/**
 * Adiciona listener ao bot√£o de reset ap√≥s o DOM carregar

 * docListener do bot√£o de reset
 * MOVIDO PARA: config-manager.js (initEventListeners)
 * @deprecated Registrado em config-manager.js
 */
