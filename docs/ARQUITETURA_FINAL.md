# ğŸ—ï¸ Arquitetura Final do AskMe

## VisÃ£o Geral

Este documento descreve a arquitetura completa do projeto **AskMe** (Electron), organizado seguindo princÃ­pios de **Arquitetura Limpa** e **PadrÃ£o Hexagonal**.

A estrutura separa claramente:
- **Infraestrutura** (bus de eventos, estado global)
- **Services** (adapters que integram com APIs externas e hardware)
- **Controllers** (lÃ³gica da UI, seÃ§Ã£o-especÃ­fica e global)
- **Core** (futuro: lÃ³gica de negÃ³cio agnÃ³stica)

---

## ğŸ“ Estrutura Completa

```
projeto-root/
â”‚
â”œâ”€â”€ ğŸ“˜ infra/                          â† INFRAESTRUTURA (plumbing)
â”‚   â”œâ”€â”€ bus/
â”‚   â”‚   â””â”€â”€ EventBus.js               # Pub/Sub event system (despedalhador central)
â”‚   â””â”€â”€ state/
â”‚       â””â”€â”€ AppState.js               # Estado global da aplicaÃ§Ã£o
â”‚
â”œâ”€â”€ ğŸ”§ services/                       â† SERVICES (adapters que fazem coisas de verdade)
â”‚   â”‚
â”‚   â”œâ”€â”€ stt/                           # Speech-to-Text
â”‚   â”‚   â”œâ”€â”€ STTStrategy.js             # Orquestrador de providers STT
â”‚   â”‚   â”œâ”€â”€ stt-deepgram.js            # Adapter: Deepgram API
â”‚   â”‚   â”œâ”€â”€ stt-vosk.js                # Adapter: Vosk (local, offline)
â”‚   â”‚   â”œâ”€â”€ stt-whisper.js             # Adapter: OpenAI Whisper
â”‚   â”‚   â”œâ”€â”€ vad-engine.js              # Voice Activity Detection (detector de fala)
â”‚   â”‚   â”œâ”€â”€ stt-audio-worklet-processor.js # Processamento de Ã¡udio Web Audio API
â”‚   â”‚   â””â”€â”€ models-stt/                # Modelos dos STT (vosk, whisper)
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/                           # Large Language Models
â”‚   â”‚   â”œâ”€â”€ LLMManager.js              # Orquestrador de providers LLM
â”‚   â”‚   â”œâ”€â”€ llmHandlers.js             # ValidaÃ§Ã£o e orquestraÃ§Ã£o de requisiÃ§Ãµes
â”‚   â”‚   â””â”€â”€ handlers/                  # ImplementaÃ§Ãµes de providers
â”‚   â”‚       â”œâ”€â”€ openai-handler.js      # Adapter: OpenAI API (GPT)
â”‚   â”‚       â”œâ”€â”€ gemini-handler.js      # Adapter: Google Gemini API
â”‚   â”‚       â””â”€â”€ template-handler.js    # Template para novo provider
â”‚   â”‚
â”‚   â””â”€â”€ audio/                         # Audio captura e processamento
â”‚       â”œâ”€â”€ volume-audio-monitor.js    # Monitor de volume de microfone
â”‚       â””â”€â”€ volume-audio-worklet-processor.js # Processamento de Ã¡udio
â”‚
â”œâ”€â”€ ğŸ® controllers/                    â† CONTROLLERS (lÃ³gica de UI)
â”‚   â”‚
â”‚   â”œâ”€â”€ modes/                         # âœ… GLOBAL
â”‚   â”‚   â””â”€â”€ mode-manager.js            # Orquestrador de modos (Normal vs Entrevista)
â”‚   â”‚
â”‚   â”œâ”€â”€ audio/                         # âœ… GLOBAL
â”‚   â”‚   â””â”€â”€ audio-controller.js        # Controlador de captura de Ã¡udio
â”‚   â”‚
â”‚   â”œâ”€â”€ config/                        
â”‚   â”‚   â”œâ”€â”€ handlers/                  # Handlers de configuraÃ§Ã£o
â”‚   â”‚   â”‚   â””â”€â”€ llm-handler.js         # Adaptado de handlers/llmHandlers.js
â”‚   â”‚   â””â”€â”€ ConfigManager.js           # Orquestrador de todos os managers
â”‚   â”‚
â”‚   â””â”€â”€ sections/                      # ğŸ¯ SEÃ‡ÃƒO-ESPECÃFICA (UI dividida por seÃ§Ã£o)
â”‚       â”‚
â”‚       â”œâ”€â”€ home/                      # SeÃ§Ã£o INICIAL (perguntas e respostas)
â”‚       â”‚   â”œâ”€â”€ HomeUIManager.js       # Manager da seÃ§Ã£o home
â”‚       â”‚   â”œâ”€â”€ question-controller.js # LÃ³gica de perguntas
â”‚       â”‚   â””â”€â”€ question-helpers.js    # Helpers para perguntas
â”‚       â”‚
â”‚       â”œâ”€â”€ top-bar/                   # SeÃ§Ã£o TOPO (opacidade, modo, badges)
â”‚       â”‚   â””â”€â”€ TopBarManager.js       # Manager da barra superior
â”‚       â”‚
â”‚       â”œâ”€â”€ api-models/                # SeÃ§Ã£o CONFIGURAÃ‡ÃƒO DE APIs
â”‚       â”‚   â”œâ”€â”€ ApiKeyManager.js       # Gerenciar chaves de API (OpenAI, Gemini)
â”‚       â”‚   â””â”€â”€ ModelSelectionManager.js # Selecionar modelo (GPT-4, Claude, etc)
â”‚       â”‚
â”‚       â”œâ”€â”€ audio-screen/              # SeÃ§Ã£o ÃUDIO E SCREENSHOT
â”‚       â”‚   â”œâ”€â”€ AudioDeviceManager.js  # SeleÃ§Ã£o de dispositivo de Ã¡udio
â”‚       â”‚   â”œâ”€â”€ ScreenConfigManager.js # ConfiguraÃ§Ãµes de screenshot
â”‚       â”‚   â””â”€â”€ screenshot-controller.js # LÃ³gica de captura de tela
â”‚       â”‚
â”‚       â”œâ”€â”€ privacy/                   # SeÃ§Ã£o PRIVACIDADE
â”‚       â”‚   â””â”€â”€ PrivacyConfigManager.js # ConfiguraÃ§Ãµes de privacidade
â”‚       â”‚
â”‚       â”œâ”€â”€ others/                    # SeÃ§Ã£o OUTROS
â”‚       â”‚   â””â”€â”€ OtherConfigManager.js  # ConfiguraÃ§Ãµes diversas
â”‚       â”‚
â”‚       â”œâ”€â”€ info/                      # SeÃ§Ã£o INFORMAÃ‡Ã•ES
â”‚       â”‚   â””â”€â”€ InfoManager.js         # Exibir versÃ£o e info da app
â”‚       â”‚
â”‚       â””â”€â”€ window/                    # SeÃ§Ã£o JANELA
â”‚           â””â”€â”€ WindowUIManager.js     # Gerenciar janela (drag, click-through, close)
â”‚
â”œâ”€â”€ ğŸ“¦ core/                           â† CORE (FUTURO - LÃ³gica agnÃ³stica)
â”‚   â”œâ”€â”€ domain/                        # Tipos e entidades
â”‚   â”‚   â”œâ”€â”€ audio/
â”‚   â”‚   â”œâ”€â”€ stt/
â”‚   â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â””â”€â”€ interview/
â”‚   â”‚
â”‚   â””â”€â”€ usecases/                      # Casos de uso (orquestradores de negÃ³cio)
â”‚       â”œâ”€â”€ audio/
â”‚       â”œâ”€â”€ stt/
â”‚       â”œâ”€â”€ llm/
â”‚       â””â”€â”€ interview/
â”‚
â”œâ”€â”€ utils/                             â† UTILITÃRIOS
â”‚   â””â”€â”€ audio/                         # Audio 
â”‚       â””â”€â”€ samples/                   # Samples/testes de Ã¡udio
â”‚   â”œâ”€â”€ Logger.js                      # Log com mascara de senhas
â”‚   â”œâ”€â”€ SecureLogger.js                # Log seguro (sem expor dados sensÃ­veis)
â”‚   â”œâ”€â”€ ErrorHandler.js                # Tratamento centralizado de erros
â”‚   â”œâ”€â”€ renderer-helpers.js            # Helpers para renderer.js
â”‚   â”œâ”€â”€ ui-elements-registry.js        # Registry de elementos DOM
â”‚   â””â”€â”€ DOM-Registry.js                # Registro dinÃ¢mico de DOM
â”‚
â”œâ”€â”€ types/                             â† TIPOS TYPESCRIPT/JSDoc
â”‚   â”œâ”€â”€ fluent-ffmpeg.d.ts
â”‚   â””â”€â”€ globals.d.ts
â”‚
â”œâ”€â”€ __tests__/                         â† TESTES
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ e2e/
â”‚
â”œâ”€â”€ docs/                              â† DOCUMENTAÃ‡ÃƒO
â”‚   â”œâ”€â”€ ARQUITETURA_FINAL.md          â† VOCÃŠ ESTÃ AQUI
â”‚   â”œâ”€â”€ ANALISE_ESTRUTURA_GLOBAL.md
â”‚   â””â”€â”€ [outras docs]
â”‚
â”œâ”€â”€ main.js                            â† Backend Electron (IPC handlers)
â”œâ”€â”€ renderer.js                        â† Frontend Electron (inicializaÃ§Ã£o)
â”œâ”€â”€ index.html                         â† PÃ¡gina principal
â”œâ”€â”€ styles.css
â””â”€â”€ package.json
```

---

## ğŸ¯ Responsabilidades por Camada

### 1ï¸âƒ£ **infra/** - Infraestrutura (Independente de domÃ­nio)

**O que faz:**
- Oferece serviÃ§os tÃ©cnicos que toda a app usa
- Ã‰ agnÃ³stico: nÃ£o sabe nada sobre LLM, STT, ou UI
- Ã‰ como a "plumbing" elÃ©trica de um prÃ©dio

| Arquivo | Responsabilidade |
|---------|------------------|
| `infra/bus/EventBus.js` | **Pub/Sub para comunicaÃ§Ã£o entre componentes**. Centraliza eventos como `llmStreamChunk`, `audioStarted`, `windowOpacityUpdate`. Desacopla componentes (A nÃ£o precisa conhecer B) |
| `infra/state/AppState.js` | **Estado global Ãºnico da aplicaÃ§Ã£o**. Substitui 15+ variÃ¡veis soltas. Gerencia: audio state, interview history, current question, LLM metrics |

**Exemplo de uso:**
```javascript
// Qualquer arquivo pode usar
globalThis.eventBus.emit('audioStarted', { timestamp: Date.now() });
globalThis.appState.interview.questionsHistory.push(newQuestion);
```

**DecisÃ£o arquitetural**: EventBus Ã© pub/sub PURO (sem filtros). AppState Ã© mutÃ¡vel (por simplicidade, futuro: imutÃ¡vel com Immer.js).

---

### 2ï¸âƒ£ **services/** - Adapters Concretos (Coisas que integram com APIs/Hardware)

A pasta `services/` contÃ©m **adapters** - cÃ³digo que interage com:
- APIs externas (OpenAI, Google Gemini, Deepgram)
- Hardware (microfone, cÃ¢mera)
- Bibliotecas de terceiros

#### **services/stt/** - Provedores Speech-to-Text

| Arquivo | Responsabilidade |
|---------|------------------|
| `STTStrategy.js` | **Orquestrador de providers STT**. Segue padrÃ£o Strategy. Permite trocar de Deepgram para Vosk sem alterar cÃ³digo cliente |
| `stt-deepgram.js` | **Adapter Deepgram**. Chama API Deepgram, converte resposta para formato padrÃ£o |
| `stt-vosk.js` | **Adapter Vosk**. Rode STT offline usando modelo Vosk, sem depender de APIs |
| `stt-whisper.js` | **Adapter OpenAI Whisper**. Chama API Whisper da OpenAI para transcriÃ§Ã£o |
| `vad-engine.js` | **Voice Activity Detection**. Detecta quando usuÃ¡rio PAROU de falar. Usa webrtcvad + fallback por energia RMS |
| `stt-audio-worklet-processor.js` | **Processamento Web Audio API**. Captura chunks de Ã¡udio do microfone |

**Fluxo:** Microfone â†’ `stt-audio-worklet-processor.js` â†’ `vad-engine.js` (detecta fala) â†’ `STTStrategy.js` (escolhe provider) â†’ Provider especÃ­fico (Deepgram/Vosk/Whisper) â†’ TranscriÃ§Ã£o

**ImplementaÃ§Ã£o de novo provider:**
```javascript
// 1. Criar novo arquivo
// services/stt/stt-novo-provider.js
class NovoSTTProvider {
  async start(elements) { /* chama API nova */ }
  async stop() { /* para */ }
  async switchDevice(type, deviceId) { /* troca dispositivo */ }
}

// 2. Registrar em renderer.js
globalThis.stt.register('novo-provider', new NovoSTTProvider());

// 3. Selecionar na UI
```

#### **services/llm/** - Provedores Large Language Models

| Arquivo | Responsabilidade |
|---------|------------------|
| `LLMManager.js` | **Orquestrador de providers LLM**. Gerencia timeout, retry com backoff, erro handling. Suporta mÃºltiplos providers (OpenAI, Gemini, Anthropic) |
| `llmHandlers.js` | **ValidaÃ§Ã£o e orquestraÃ§Ã£o de requisiÃ§Ãµes LLM**. Valida entrada, previne duplicatas, escolhe modo (streaming vs batch) |
| `handlers/openai-handler.js` | **Adapter OpenAI**. Chama API OpenAI GPT (GPT-4, 4o, mini) |
| `handlers/gemini-handler.js` | **Adapter Google Gemini**. Chama API Google Generative AI |
| `handlers/template-handler.js` | **Template para novo provider**. Guia para implementar Anthropic, Cohere, etc |

**Fluxo:** UI seleciona pergunta â†’ `llmHandlers.js` valida â†’ `LLMManager.js` orquestra â†’ Provider especÃ­fico (OpenAI/Gemini) â†’ Chama API â†’ Stream ou Batch â†’ Emite eventos para UI atualizar

**CaracterÃ­sticas:**
- âœ… Timeout configurÃ¡vel (para nÃ£o travar)
- âœ… Retry com backoff exponencial
- âœ… Support para streaming (tokens em tempo real)
- âœ… Fallback se provider falhar

#### **services/audio/** - Captura e Processamento de Ãudio

| Arquivo | Responsabilidade |
|---------|------------------|
| `volume-audio-monitor.js` | **Monitora volume do microfone em tempo real**. Atualiza UI com visualizaÃ§Ã£o de volume |
| `volume-audio-worklet-processor.js` | **Processa chunks de Ã¡udio** via Web Audio API AudioWorklet. Calcula RMS (energia) |

**Fluxo:** Microfone â†’ Web Audio API â†’ `volume-audio-worklet-processor.js` (processa) â†’ `volume-audio-monitor.js` (exibe) â†’ EventBus emite `volumeUpdate` â†’ UI atualiza visualizaÃ§Ã£o

---

### 3ï¸âƒ£ **controllers/** - LÃ³gica de UI

Controllers dividem-se em **GLOBAL** e **SEÃ‡ÃƒO-ESPECÃFICA**.

#### **Global Controllers** (afetam toda a app)

| Arquivo | Responsabilidade |
|---------|------------------|
| `controllers/modes/mode-manager.js` | **Orquestrador de modos (Normal vs Entrevista)**. Modo Normal = faz tudo de uma vez. Modo Entrevista = faz pergunta, aguarda resposta, registra. Controla heurÃ­sticas de silÃªncio, timeout |
| `controllers/audio/audio-controller.js` | **Controlador central de captura de Ã¡udio**. Inicia/para captura, aplica VAD, chama STT provider selecionado, trata erros |

**DecisÃ£o:** Modo e Audio sÃ£o **globais** porque afetam mÃºltiplas seÃ§Ãµes. Se modo muda, afeta home, top-bar, e comportamento geral.

#### **SeÃ§Ã£o-EspecÃ­fica Controllers** (cada seÃ§Ã£o tem seu Manager)

Um **Manager** por seÃ§Ã£o encapsula toda a lÃ³gica UI dessa seÃ§Ã£o:

| SeÃ§Ã£o | Manager | Responsabilidade |
|-------|---------|------------------|
| **home** | `HomeUIManager.js` | Gerencia: input de pergunta, exibiÃ§Ã£o de resposta, histÃ³rico. Listeners: `transcriptAdd`, `llmStreamChunk`, `llmStreamEnd` |
| | `question-controller.js` | LÃ³gica pura: criar pergunta, validar texto, gerar ID |
| | `question-helpers.js` | Helpers: normalizar texto, calcular hash, etc |
| **top-bar** | `TopBarManager.js` | Opacidade do overlay, seleÃ§Ã£o de modo, badges (screenshots, mock mode). Listeners: `windowOpacityUpdate`, `modeSelectUpdate`, `screenshotTaken` |
| **api-models** | `ApiKeyManager.js` | Gerenciar chaves de API (OpenAI, Gemini). Listeners: `apiKeyUpdated`. IPC: `GET_API_KEY`, `SAVE_API_KEY` |
| | `ModelSelectionManager.js` | SeleÃ§Ã£o de modelo LLM (GPT-4, Gemini Pro, etc) |
| **audio-screen** | `AudioDeviceManager.js` | SeleÃ§Ã£o de dispositivo de Ã¡udio (qual microfone usar) |
| | `ScreenConfigManager.js` | ConfiguraÃ§Ãµes de screenshot (incluir/excluir Ã¡reas da tela) |
| | `screenshot-controller.js` | Captura de screenshot via `print-screen` |
| **privacy** | `PrivacyConfigManager.js` | ConfiguraÃ§Ãµes de privacidade (dados Ã© enviados para API, modo mock, etc) |
| **others** | `OtherConfigManager.js` | ConfiguraÃ§Ãµes diversas (dark mode, futuro) |
| **info** | `InfoManager.js` | Exibir versÃ£o da app, links, info |
| **window** | `WindowUIManager.js` | Drag handle (mover janela), click-through (ignorar cliques), botÃ£o fechar. Listeners: `DRAG_START`, `DRAG_END` |

**PadrÃ£o Manager:**
```javascript
class HomeUIManager {
  #initListeners()    // â† Registra listeners PRIMEIRO
  #initElements()     // â† Setup DOM DEPOIS (pode emitir eventos)
  initialize()        // â† Entry point, chama #initListeners()
  reset()             // â† Limpa e reinicializa
}
```

**Por que separar por seÃ§Ã£o?**
- âœ… Cada seÃ§Ã£o Ã© independente (fÃ¡cil remover/adicionar)
- âœ… Reduz acoplamento
- âœ… FÃ¡cil testar uma seÃ§Ã£o isoladamente
- âœ… CÃ³digo mais legÃ­vel (home manager = tudo sobre home)

---

### 4ï¸âƒ£ **core/** - LÃ³gica de NegÃ³cio AgnÃ³stica (FUTURO)

Atualmente vazio, serÃ¡ preenchido quando logic cresce e quer-se remover dependÃªncias de services/UI.

```
core/domain/          # Tipos e entidades
  â”œâ”€â”€ audio/
  â”‚   â”œâ”€â”€ AudioState.js      # Tipo: { isRunning, isCApturing, volume }
  â”‚   â””â”€â”€ AudioTypes.js      # Types: AudioConfig, AudioEvent
  â”œâ”€â”€ stt/
  â”‚   â””â”€â”€ STTState.js        # Tipo: { currentProvider, isBusy }
  â”œâ”€â”€ llm/
  â”‚   â””â”€â”€ LLMState.js        # Tipo: { isRequesting, model, provider }
  â””â”€â”€ interview/
      â””â”€â”€ InterviewState.js  # Tipo: { currentQuestion, answered, history }

core/usecases/        # Casos de uso (lÃ³gica de domÃ­nio)
  â”œâ”€â”€ audio/
  â”‚   â”œâ”€â”€ captureAudio.js    # UseCase: iniciar captura
  â”‚   â””â”€â”€ processAudio.js    # UseCase: processar chunk
  â”œâ”€â”€ stt/
  â”‚   â”œâ”€â”€ transcribeAudio.js # UseCase: transcrever
  â”‚   â””â”€â”€ switchDevice.js    # UseCase: trocar dispositivo
  â”œâ”€â”€ llm/
  â”‚   â”œâ”€â”€ askQuestion.js     # UseCase: fazer pergunta ao LLM
  â”‚   â”œâ”€â”€ streamAnswer.js    # UseCase: receber resposta em streaming
  â”‚   â””â”€â”€ validateQuestion.js # UseCase: validar pergunta
  â””â”€â”€ interview/
      â”œâ”€â”€ startInterview.js  # UseCase: iniciar entrevista
      â”œâ”€â”€ recordQuestion.js  # UseCase: registrar pergunta
      â””â”€â”€ resetInterview.js  # UseCase: resetar estado entrevista
```

**BenefÃ­cio:** Core NÃƒO depende de OpenAI, Deepgram, ou Electron. Pode rodar em Node.js/web puro.

---

## ğŸ”„ Fluxo de Dados: Exemplo Completo

### CenÃ¡rio: UsuÃ¡rio Faz uma Pergunta

```
1. ğŸ¤ CAPTURA DE ÃUDIO (controllers/audio/audio-controller.js)
   â””â”€ Inicia captura via Web Audio API
   â””â”€ Registra vad-engine.js para detectar fala
   â””â”€ Emite: eventBus.emit('audioStarted')

2. ğŸ™ï¸ DETECÃ‡ÃƒO DE SILÃŠNCIO (services/stt/vad-engine.js)
   â””â”€ Analisa frames de Ã¡udio
   â””â”€ Detecta: "usuÃ¡rio parou de falar"
   â””â”€ Emite: eventBus.emit('audioEnded')

3. ğŸ”¤ TRANSCRIÃ‡ÃƒO (services/stt/)
   â””â”€ audio-controller.js chama STTStrategy.js
   â””â”€ STTStrategy.js escolhe provider (Deepgram ou Vosk)
   â””â”€ Provider transcrevÃª = "qual Ã© meu nome?"
   â””â”€ Emite: eventBus.emit('transcriptAvailable', { text: "qual Ã© meu nome?" })

4. â“ REGISTRAR PERGUNTA (controllers/sections/home/)
   â””â”€ HomeUIManager escuta 'transcriptAvailable'
   â””â”€ question-controller.js cria objeto pergunta
   â””â”€ appState.interview.questionsHistory.push(question)
   â””â”€ Renderiza na UI

5. ğŸš€ ENVIAR PARA LLM (controllers/sections/home/ + services/llm/)
   â””â”€ HomeUIManager onclick "Enviar para IA"
   â””â”€ Chama llmHandlers.js validateLLMRequest()
   â””â”€ LLMManager.js orquestra com retry/timeout
   â””â”€ openai-handler.js chama OpenAI API
   â””â”€ Emite: eventBus.emit('llmStreamChunk', { token: "Seu..." })

6. ğŸ“ EXIBIR RESPOSTA (controllers/sections/home/)
   â””â”€ HomeUIManager escuta 'llmStreamChunk'
   â””â”€ Renderiza tokens em tempo real
   â””â”€ Emite: eventBus.emit('llmStreamEnd', { totalTime })

7. ğŸ’¾ REGISTRAR MÃ‰TRICA (infra/state/AppState.js)
   â””â”€ appState.metrics.llmEndTime = Date.now()
   â””â”€ Calcula tempo total
   â””â”€ Pronto para prÃ³xima pergunta
```

**SeparaÃ§Ã£o de responsabilidades:**
- âœ… Audio Ã© responsabilidade de `services/stt/`
- âœ… LLM Ã© responsabilidade de `services/llm/`
- âœ… UI Ã© responsabilidade de `controllers/sections/home/`
- âœ… EventBus conecta tudo sem acoplamento
- âœ… AppState guarda estado consistente

---

## ğŸ§ª Testabilidade

**Unit Test** - Testar lÃ³gica pura:
```javascript
// NÃ£o depende de APIs ou Electron
const { validateLLMRequest } = require('./services/llm/llmHandlers');
const mockState = { interview: { ... } };
const result = validateLLMRequest(mockState, questionId, () => "test");
expect(result.text).toBe("test");
```

**Integration Test** - Testar integraÃ§Ã£o entre layers:
```javascript
// Testa EventBus + AppState
const { testFlowAudioToTranscript } = require('./test-mocks');
await testFlowAudioToTranscript();
// Verifica: EventBus emitiu eventos corretos
// Verifica: AppState atualizou estado
```

**E2E Test** - Testar fluxo completo:
```javascript
// Testa: Electron window + UI + STT + LLM
// Simula usuÃ¡rio dizendo pergunta
// Verifica resposta do LLM aparece na tela
```

---

## ğŸ“Š Matriz de DependÃªncias

```
GLOBAL (tudo depende)
â”œâ”€â”€ infra/            # Bus de eventos + Estado
â””â”€â”€ services/         # STT, LLM, Audio (adapters)

CONTROLLERS (depende de global)
â”œâ”€â”€ controllers/modes/ # Modo (Normal vs Entrevista)
â”œâ”€â”€ controllers/audio/ # Captura de Ã¡udio
â””â”€â”€ controllers/sections/* # Cada seÃ§Ã£o UI

MAIN (Electron backend)
â”œâ”€â”€ Depende de: IPC, Store (persitÃªncia), Logger
â””â”€â”€ IPC para comunicar com renderer (controllers)

CORE (FUTURO - nÃ£o depende de ninguÃ©m)
â”œâ”€â”€ NÃ£o depende de: services, controllers, infra
â”œâ”€â”€ Depende de: tipos JavaScript nativos apenas
â””â”€â”€ Injeta dependÃªncias via funÃ§Ã£o (inversion of control)
```

---

## ğŸ› ï¸ Como Adicionar Novo Provider

### Exemplo: Suporte a Novo STT (ex: AssemblyAI)

**Passo 1:** Criar arquivo `services/stt/stt-assemblyai.js`
```javascript
class AssemblyAIProvider {
  constructor(apiKey) { this.apiKey = apiKey; }
  async start(elements) { /* conecta WebSocket AssemblyAI */ }
  async stop() { /* fecha WebSocket */ }
  async switchDevice(type, deviceId) { /* troca microfone */ }
}
```

**Passo 2:** Registrar em `renderer.js`
```javascript
const assemblyAI = new globalThis.AssemblyAIProvider(apiKey);
globalThis.stt.register('assemblyai', assemblyAI);
```

**Passo 3:** Selecionar na UI (AudioDeviceManager) ou via config

**Resultado:** AplicaÃ§Ã£o funciona com novo provider, nenhum cÃ³digo do core/controllers mudou!

### Exemplo: Suporte a Novo LLM (ex: Anthropic Claude)

**Passo 1:** Criar `services/llm/handlers/anthropic-handler.js`
```javascript
class AnthropicHandler {
  async initialize(apiKey) { this.client = new Anthropic({ apiKey }); }
  async complete(messages, config) { /* chama API */ }
  async stream(messages, config) { /* stream de tokens */ }
}
```

**Passo 2:** Registrar em `renderer.js`
```javascript
globalThis.llmManager.register('anthropic', anthropicHandler);
```

**Passo 3:** Adicionar campo API key na UI (ApiKeyManager)

**Resultado:** App suporta Claude, nada mais muda!

---

## ğŸ“ PrincÃ­pios Aplicados

| PrincÃ­pio | ImplementaÃ§Ã£o |
|-----------|---------------|
| **Single Responsibility** | Cada arquivo tem uma responsabilidade. `LLMManager.js` = orquestraÃ§Ã£o. `openai-handler.js` = adapter OpenAI |
| **Open/Closed** | Aberto para extensÃ£o (novos providers), fechado para modificaÃ§Ã£o (core nÃ£o muda) |
| **Dependency Inversion** | Services registram-se em managers (injeÃ§Ã£o). UI nÃ£o importa services diretamente |
| **Separation of Concerns** | Infra â‰  Services â‰  Controllers. FÃ¡cil trocar um sem quebrar outro |
| **DRY (Don't Repeat Yourself)** | EventBus Ã© Ãºnico ponto de pub/sub. AppState Ã© Ãºnico estado |
| **Layered Architecture** | Cada layer tem responsabilidade clara |

---

## ğŸš€ PrÃ³ximas Melhorias

- [ ] Implementar `core/usecases/` quando lÃ³gica crescer
- [ ] Adicionar imutabilidade a AppState (Immer.js)
- [ ] Error boundaries em cada manager
- [ ] Testes de performance (Vitest + Benchmark)
- [ ] Type checking completo (JSDoc â†’ TypeScript)
- [ ] Logger estruturado (Pino/Winston)

---

## ğŸ“š ReferÃªncias RÃ¡pidas

**Precisa adicionar nova feature?**
1. Feature Ã© global ou seÃ§Ã£o-especÃ­fica?
   - Global â†’ `controllers/{modes,audio}/`
   - SeÃ§Ã£o â†’ `controllers/sections/{nome}/`
2. Integra com API/hardware?
   - SIM â†’ Crie em `services/`
   - NÃƒO â†’ LÃ³gica pura em controller
3. Necessita estado?
   - Centralizar em `infra/state/AppState.js`
4. Precisa comunicar com outro componente?
   - Use `infra/bus/EventBus.js`

**Precisa debugar fluxo?**
1. Procure o evento inicial em `infra/bus/EventBus.js` (grep do nome do evento)
2. Siga o EventBus para quem escuta: grep por `eventBus.on('evento')`
3. Procure em qual manager/controller
4. Trace atÃ© o fim

**Precisa entender um manager?**
1. Procure `#initListeners()` - mostra o que ele escuta
2. Procure `#initElements()` - mostra o que ele renderiza
3. Procure emits - mostra o que ele comunica

---

## ğŸ‘¤ Contato e DÃºvidas

DÃºvidas sobre arquitetura? Revise:
- Este documento (ARQUITETURA_FINAL.md)
- JSDoc comments no inÃ­cio de cada arquivo
- Exemplos de uso nos testes (`__tests__/`)
- Diagramas em `docs/`

**PadrÃ£o:** Quando em dÃºvida, assume que vocÃª quer **desacoplar** cÃ³digo.

---

**VersÃ£o:** 1.0  
**Data:** 27 de Janeiro de 2026  
**Status:** âœ… IMPLEMENTADO

