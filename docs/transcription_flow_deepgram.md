# Fluxo Detalhado de Transcri√ß√£o com Deepgram

Este documento descreve o fluxo passo a passo de cada fun√ß√£o e evento chamado durante o processo de transcri√ß√£o de √°udio usando o Deepgram via WebSocket direto para streaming em tempo real, come√ßando pelo acionamento do bot√£o "Come√ßar a Ouvir" (Ctrl+D). O foco √© no caminho at√© a transcri√ß√£o aparecer na tela, incluindo valida√ß√µes, inicializa√ß√£o de √°udio, captura, envio via WebSocket, processamento da resposta e renderiza√ß√£o.

## 1. Acionamento do Bot√£o "Come√ßar a Ouvir" (Ctrl+D)

- **Arquivo**: `renderer.js`
- **Fun√ß√£o/Evento**: `listenToggleBtn()` (linha ~3249)
- **Descri√ß√£o**: Esta fun√ß√£o √© chamada quando o usu√°rio clica no bot√£o ou pressiona Ctrl+D. Ela realiza valida√ß√µes iniciais antes de iniciar a escuta.
  - Chama `hasActiveModel()` para verificar se h√° modelo IA ativo (retorna { active: true, model: 'deepgram' }).
  - Verifica se dispositivo de √°udio de sa√≠da est√° selecionado (`UIElements.outputSelect?.value`).
  - Se valida√ß√µes falham, emite erro via `emitUIChange('onError', mensagem)` e retorna.
  - Inverte `isRunning` (false ‚Üí true).
  - Atualiza bot√£o via `emitUIChange('onListenButtonToggle', { isRunning: true, buttonText: 'Parar a Escuta...', })`.
  - Chama `updateStatusMessage('Status: ouvindo...')`.
  - Chama `startAudio()`.

## 2. Inicializa√ß√£o da Captura de √Åudio

- **Arquivo**: `renderer.js`
- **Fun√ß√£o/Evento**: `startAudio()` (linha ~1020)
- **Descri√ß√£o**: Coordena in√≠cio da captura detectando modelo STT.
  - Chama `getConfiguredSTTModel()` que l√™ `window.configManager.config.api[provider].selectedSTTModel` (deve ser 'deepgram').
  - Como √© 'deepgram', chama `startAudioDeepgram(UIElements)` de `stt-deepgram.js`.

### 2.1. Inicializa√ß√£o do Deepgram (startAudioDeepgram)

- **Arquivo**: `stt-deepgram.js`
- **Fun√ß√£o/Evento**: `startAudioDeepgram(UIElements)` (linha ~185)
- **Descri√ß√£o**: Inicializa captura para input e output separadamente.
  - Se `UIElements.inputSelect?.value`: chama `startDeepgram('input', UIElements)`.
  - Se `UIElements.outputSelect?.value`: chama `startDeepgram('output', UIElements)`.

#### 2.1.1. Captura de Entrada (Microfone) e Sa√≠da (Sistema)

- **Arquivo**: `stt-deepgram.js`
- **Fun√ß√£o/Evento**: `startDeepgram(source, UIElements)` (linha ~475)
- **Descri√ß√£o**: Fun√ß√£o gen√©rica que inicializa captura tanto para entrada quanto sa√≠da, parametrizando por source.
  - `source` pode ser `'input'` (microfone) ou `'output'` (sistema).
  - **Para INPUT**:
    - Obt√©m `deviceId = UIElements.inputSelect?.value`.
    - Threshold: `0.02` (menos sens√≠vel).
    - Mensagem de acesso: `"üé§ Solicitando acesso √† entrada de √°udio (Microfone)..."`.
  - **Para OUTPUT**:
    - Obt√©m `deviceId = UIElements.outputSelect?.value`.
    - Threshold: `0.005` (mais sens√≠vel, para capturar finais de fala).
    - Mensagem de acesso: `"üîä Solicitando acesso √† sa√≠da de √°udio (VoiceMeter/Stereo Mix)..."`.
  - Verifica se j√° ativo via `deepgramVars[source].isActive()`, se sim retorna.
  - Chama `initDeepgramWS(source)` para WebSocket.
  - Define flags via deepgramVars:
    - `setWs(ws)`
    - `setActive(true)`
    - `setStartAt(Date.now())`
  - Solicita acesso ao dispositivo: `navigator.mediaDevices.getUserMedia({ audio: { deviceId: { exact: deviceId } } })`.
  - Cria `AudioContext` com 16kHz.
  - Carrega AudioWorklet: `audioContext.audioWorklet.addModule('./deepgram-audio-worklet-processor.js')`.
  - Cria `AudioWorkletNode` com threshold apropriado para o source.
  - Conecta fluxo: `source ‚Üí HPF (passa-alta) ‚Üí processor ‚Üí destination`.
  - Atualiza refer√™ncias via deepgramVars (stream, audioContext, source, hpf, processor).

### 2.2. Inicializa√ß√£o do WebSocket (initDeepgramWS)

- **Arquivo**: `stt-deepgram.js`
- **Fun√ß√£o/Evento**: `initDeepgramWS(source)` (linha ~50)
- **Descri√ß√£o**: Cria conex√£o WebSocket com Deepgram.
  - Obt√©m chave: `ipcRenderer.invoke('GET_API_KEY', 'deepgram')`.
  - Monta URL: `wss://api.deepgram.com/v1/listen?model=nova-2&language=pt-BR&smart_format=true&interim_results=true&encoding=linear16&sample_rate=16000&endpointing=300&utterance_end_ms=1000`.
  - Cria `ws = new WebSocket(url, ['token', apiKey])`.
  - Define `ws.onopen`: chama `startDeepgramHeartbeat(ws, source)`. Iniciando heartbeat para manter conex√£o viva.
  - Define `ws.onmessage`: `handleDeepgramMessage(JSON.parse(event.data), source)`.
  - Define `ws.onerror` e `ws.onclose`: logs e cleanup.
  - Retorna promise resolvendo ws.

## 3. Processamento de √Åudio em Tempo Real

- **Arquivo**: `deepgram-audio-worklet-processor.js`
- **Descri√ß√£o**: AudioWorklet processa √°udio continuamente.
  - Recebe dados de √°udio (Float32Array) no `process(inputs, outputs)`.
  - Aplica threshold: se volume < threshold, ignora (evita sil√™ncio).
  - Converte Float32 para Int16 (PCM16): `pcm16 = new Int16Array(float32.length); for(let i=0; i<float32.length; i++) pcm16[i] = float32[i] * 32767;`.
  - Envia via `this.port.postMessage({ type: 'audioData', pcm16 })`.
  - Tamb√©m calcula volume e envia `this.port.postMessage({ type: 'volumeUpdate', percent })`.

- **Arquivo**: `stt-deepgram.js`
- **Fun√ß√£o/Evento**: `deepgramInputProcessor.port.onmessage` / `deepgramOutputProcessor.port.onmessage` (linhas ~251 e ~331)
- **Descri√ß√£o**:
  - Recebe `{ type, pcm16, percent }`.
  - Se `type === 'audioData'`: envia `deepgramInputWebSocket.send(pcm16)` ou similar para output.
  - Se `type === 'volumeUpdate'`: emite `emitUIChange('onInputVolumeUpdate', { percent })` ou output.

## 4. Recep√ß√£o e Processamento de Transcri√ß√µes

- **Arquivo**: `stt-deepgram.js`
- **Fun√ß√£o/Evento**: `deepgramInputWebSocket.onmessage` / `deepgramOutputWebSocket.onmessage` (via `initDeepgramWS`)
- **Descri√ß√£o**: Recebe JSON do Deepgram.
  - Parseia `data = JSON.parse(event.data)`.
  - Chama `handleDeepgramMessage(data, source)`.

### 4.1. Processamento de Mensagens (handleDeepgramMessage)

- **Arquivo**: `stt-deepgram.js`
- **Fun√ß√£o/Evento**: `handleDeepgramMessage(data, source)` (linha ~630)
- **Descri√ß√£o**:
  - Extrai `transcript = data.channel?.alternatives?.[0]?.transcript`.
  - `confidence = data.channel?.alternatives?.[0]?.confidence`.
  - `isFinal = data.is_final`.
  - `speechFinal = data.speech_final`.
  - Se `!transcript?.trim()`, ignora.
  - Logs: `console.log(isFinal ? 'FINAL' : 'INTERIM', transcript)`.
  - Se `isFinal`: chama `handleFinalDeepgramMessage(transcript, confidence, source)`.
  - Sen√£o: chama `handleInterimDeepgramMessage(transcript, source)`.

### 4.2. Processamento de Interims (transcri√ß√µes parciais)

- **Arquivo**: `stt-deepgram.js`
- **Fun√ß√£o/Evento**: `handleInterimDeepgramMessage(transcript, source)` (linha ~588)
- **Descri√ß√£o**:
  - Define autor da transcri√ß√£o (Input ou Output): `author = isInput ? YOU : OTHER;`.
  - Define ID do elemento interim: `interimId = isInput ? 'deepgram-interim-input' : 'deepgram-interim-output'`.
  - **Emite** `emitUIChange('onUpdateInterim', { id: interimId, speaker: author, text: transcript })`
    para atualizar a interface com o texto sendo transcrito em tempo real (mostra o texto aparecendo gradualmente na tela, como um "typing effect" - efeito de digita√ß√£o).

### 4.3. Processamento de Finals (transcri√ß√µes completas)

- **Arquivo**: `stt-deepgram.js`
- **Fun√ß√£o/Evento**: `handleFinalDeepgramMessage(transcript, confidence, source)` (linha ~490)
- **Descri√ß√£o**:
  - Define `deepgramInputStopAt = Date.now()` ou output.
  - Calcula m√©tricas: latency, total time.
  - Cria placeholder ID √∫nico.
  - Emite `emitUIChange('onTranscriptAdd', { author, text, timeStr, elementId: 'conversation', placeholderId })`.
  - Emite `emitUIChange('onPlaceholderFulfill', { ... })` com m√©tricas.
  - Para output: emite `emitSTTEvent('transcriptionComplete', { text, speaker: author })`.
  - Limpa interim: `emitUIChange('onClearInterim', { id: 'deepgram-interim-input' })`.

## 5. Integra√ß√£o com Renderer (para Output)

- **Arquivo**: `renderer.js`
- **Fun√ß√£o/Evento**: Listener de `window.transcriptionEvents` (linha ~4216)
- **Descri√ß√£o**: Para output, o evento 'transcription' (interim) e 'transcriptionComplete' (final) s√£o ouvidos.
  - Para 'transcriptionComplete': chama `handleSpeech('OTHER', text)`.

- **Arquivo**: `renderer.js`
- **Fun√ß√£o/Evento**: `handleSpeech(author, text)` (linha ~2450)
- **Descri√ß√£o**:
  - Limpa texto: `text.replace(/√ä+|hum|ahn/gi, '').trim()`.
  - Se `cleaned.length < 3`, ignora.
  - Para 'OTHER': chama `handleCurrentQuestion('OTHER', cleaned, { isInterim: false })`.

- **Arquivo**: `renderer.js`
- **Fun√ß√£o/Evento**: `handleCurrentQuestion(author, text, options)` (linha ~2560)
- **Descri√ß√£o**:
  - Atualiza `currentQuestion.text += text`.
  - `currentQuestion.lastUpdateTime = Date.now()`.
  - Chama `renderCurrentQuestion()`.

## 6. Renderiza√ß√£o na Tela

- **Arquivo**: `config-manager.js`
- **Fun√ß√£o/Evento**: Ouvinte de `emitUIChange('onCurrentQuestionUpdate')`
- **Descri√ß√£o**: Atualiza `#current-question` com texto e classes.

- **Arquivo**: `config-manager.js`
- **Fun√ß√£o/Evento**: Ouvinte de `emitUIChange('onTranscriptAdd')`
- **Descri√ß√£o**: Adiciona √† `#conversation` usando `marked` para Markdown.

- **Arquivo**: `config-manager.js`
- **Fun√ß√£o/Evento**: Ouvinte de `emitUIChange('onUpdateInterim')`
- **Descri√ß√£o**: Atualiza elemento interim com texto.

## 7. Fechamento e Finaliza√ß√£o de Perguntas

- Quando `emitSTTEvent('transcriptionComplete')` para output, dispara fechamento.
- **Arquivo**: `renderer.js`
- **Fun√ß√£o/Evento**: `closeCurrentQuestion()` (linha ~2625)
- **Descri√ß√£o**:
  - Se `looksLikeQuestion(currentQuestion.text)`: processa.
  - Modo normal: `promoteCurrentToHistory(text)`.
  - Modo entrevista: chama `askGpt()` se turno correto.

## Pontos de Aten√ß√£o e Poss√≠veis Problemas

- **Configura√ß√£o**: Modelo deve ser 'deepgram' em config, chave API v√°lida.
- **WebSocket**: Falha em conectar se rede ruim ou chave errada (erro 401).
- **AudioWorklet**: Threshold alto pode ignorar fala; permiss√µes necess√°rias.
- **Mensagens**: JSON malformado causa erro em parse.
- **Eventos**: Se listeners em renderer n√£o ouvirem, transcri√ß√£o n√£o processa.
- **Heartbeat**: Sem KeepAlive, WS fecha em 1011.
- **Debug**: Logs em console mostram cada passo; verificar se WS abre e mensagens chegam.
