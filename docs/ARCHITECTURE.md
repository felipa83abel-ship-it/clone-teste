# Arquitetura AskMe - RefatoraÃ§Ã£o Completa

Documento de referÃªncia da arquitetura apÃ³s refatoraÃ§Ã£o FASE 1-4 (jan 2026) com consolidaÃ§Ã£o de Estado, Eventos e Modo.

## ğŸ“‹ VisÃ£o Geral

**AskMe** Ã© um aplicativo Electron single-window que funciona como overlay sempre visÃ­vel, capturando Ã¡udio ambiente, convertendo em texto via STT (Speech-to-Text) e gerando respostas via LLM (Large Language Model).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  USUÃRIO (Ctrl+D: captura Ã¡udio, Ctrl+Enter: pergunta) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Overlay UI (index.html)      â”‚  (transparente, frameless, sempre visÃ­vel)
        â”‚  â”Œâ”€ config-manager.js (DOM)    â”‚
        â”‚  â””â”€ RendererAPI (bridge)       â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚   renderer.js (OrquestraÃ§Ã£o)          â”‚
      â”‚  â”Œâ”€ AppState (State Centralized)      â”‚
      â”‚  â”œâ”€ EventBus (Global Events)          â”‚
      â”‚  â”œâ”€ ModeManager (INTERVIEW/NORMAL)    â”‚
      â”‚  â””â”€ Event Listeners (Handler Chain)   â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚          â”‚                  â”‚
    â–¼          â–¼                  â–¼
  STT       LLM               IPC (main.js)
 Providers  Handlers         Electron APIs
```

---

## ğŸ¯ MudanÃ§as na RefatoraÃ§Ã£o

### âœ… Fase 1: Limpeza RÃ¡pida

- Removido: `debugLogRenderer()` â†’ centralizado em `Logger.debug()` com flag
- Removido: `releaseThread()` duplicada
- Isolado: CÃ³digo mock em `mock-runner.js` (~500 linhas)
- Removido: FunÃ§Ãµes mortas (`promoteCurrentToHistory`, `getNavigableQuestionIds`, `restartAudioPipeline`)

### âœ… Fase 2: ConsolidaÃ§Ã£o de Estado

- Migrado: 14 variÃ¡veis globais â†’ `AppState` centralizado
- Adicionado: Getters/setters em AppState para acesso simplificado
- Exemplos: `appState.currentQuestion`, `appState.history`, `appState.selectedId`

### âœ… Fase 3: ConsolidaÃ§Ã£o de Eventos

- Removido: `UICallbacks` object (25+ callbacks)
- Removido: FunÃ§Ã£o `onUIChange()` obsoleta
- Consolidado: Todos os eventos â†’ `EventBus` global
- Exemplo: `onError` â†’ `error`, `onTranscriptAdd` â†’ `transcriptAdd`

### âœ… Fase 4: ConsolidaÃ§Ã£o de Modo

- Criado: `ModeManager` class (201 linhas) centralizando lÃ³gica de modo
- Removido: `CURRENT_MODE` global variable
- Removido: `ModeController` antigo
- Modos: `MODES.INTERVIEW` (streaming, auto-ask), `MODES.NORMAL` (batch)

### ğŸ“Š Resultados

- **renderer.js**: 2106 linhas â†’ 1542 linhas (-564, -26.8%)
- **Arquivos novos**: `mock-runner.js`, `mode-manager.js`
- **VariÃ¡veis globais**: 16 â†’ 1 (AppState)
- **Sistemas de eventos**: 2 (UICallbacks + EventBus) â†’ 1 (EventBus)

---

## ğŸ¯ Camadas Principais

### 1. **Renderer (Frontend) - Camada de OrquestraÃ§Ã£o**

**Arquivos**: `renderer.js`, `config-manager.js`, `index.html`, `styles.css`

#### renderer.js (Orquestrador Central)

**Responsabilidades**:

- Inicializa `AppState`, `EventBus`, `ModeManager`
- Registra listeners para eventos globais
- Orquestra fluxo: Captura de Ã¡udio â†’ STT â†’ LLM â†’ EmissÃ£o de eventos
- ExpÃµe `window.RendererAPI` com mÃ©todos pÃºblicos

**Componentes principais**:

```javascript
// AppState: Estado centralizado
appState.history          // array de perguntas
appState.interview.currentQuestion  // pergunta sendo formada
appState.selectedId       // pergunta selecionada

// EventBus: Sistema de eventos Ãºnico
eventBus.on('transcriptAdd', data => {...})
eventBus.emit('answerStreamChunk', {...})

// ModeManager: LÃ³gica de modo
modeManager.is(MODES.INTERVIEW)   // checking modo
modeManager.handle('onQuestionFinalize', ...)  // delegaÃ§Ã£o
```

**Event Listeners Consolidados** (linhas 42-85):

- `answerStreamChunk`: Streamer chunking para UI (INTERVIEW mode)
- `llmStreamEnd`: Marca como respondida, limpa pergunta atual
- `llmBatchEnd`: Marca como respondida, emite answerBatchEnd para UI
- `error`: Handler global de erros
- `audioDeviceChanged`: Reinicializa STT quando dispositivo muda

#### AppState (estado/AppState.js)

**Estrutura centralizada**:

```javascript
{
  history: [],  // array de questions ({id, text, turnId, response})
  interview: {
    currentQuestion: {},       // pergunta sendo formada
    interviewTurnId: 0,        // counter de turnos (INTERVIEW mode)
    answeredQuestions: Set,    // tracking de respondidas
    lastAskedQuestionNormalized: null,
    llmRequestedQuestionId: null,
    llmAnsweredTurnId: null
  },
  audio: {
    isRunning: false,
    capturedScreenshots: [],
    isCapturing: false,
    isAnalyzing: false
  },
  window: {
    isDraggingWindow: false,
    selectedId: null  // pergunta selecionada via navegaÃ§Ã£o
  }
}
```

**Getters/Setters para acesso simplificado**:

```javascript
appState.q                    // shortcut para currentQuestion
appState.history              // getter com proteÃ§Ã£o
appState.selectedId           // pergunta selecionada
appState.isRunning            // status de captura
appState.addToHistory(...)    // method para adicionar
```

#### ModeManager (mode-manager.js)

**Modos DisponÃ­veis**:

- `MODES.INTERVIEW`: Streaming, auto-ask LLM, turnId = counter incremental
- `MODES.NORMAL`: Batch processing, manual ask, turnId = question ID

**Responsabilidades**:

```javascript
modeManager.is(MODES.INTERVIEW); // check modo
modeManager.handle('onQuestionFinalize', questionId); // delegaÃ§Ã£o
modeManager.handle('onAnswerRequest', questionId); // routing lÃ³gica
```

**Handler Delegation**:

- Em INTERVIEW: `finalizeQuestion()` incrementa `interviewTurnId`
- Em NORMAL: `finalizeQuestion()` usa `Number.parseInt(questionId)` como `turnId`

#### config-manager.js (DOM & UI Events)

- Gerencia DOM (listener para `transcriptAdd`, `answerBatchEnd`, `answerStreamChunk`)
- Renderiza markdown com `marked.parse()`
- Renderiza badges com `turn-id-badge`
- Persiste configuraÃ§Ãµes em localStorage + electron-store
- Gerencia providers (OpenAI, Google/Gemini, OpenRouter)
- Abas: Geral, API e Modelos, Ãudio, Privacidade, Reset

#### EventBus (events/EventBus.js - Singleton)

**Eventos Principais**:

| Evento                   | Origem      | Destino        | Payload                          |
| ------------------------ | ----------- | -------------- | -------------------------------- |
| `transcriptAdd`          | STT modules | config-manager | `{text, duration, timestamp}`    |
| `answerStreamChunk`      | renderer.js | config-manager | `{questionId, chunk, turnId}`    |
| `answerBatchEnd`         | renderer.js | config-manager | `{questionId, response, turnId}` |
| `questionsHistoryUpdate` | renderer.js | config-manager | `{questions}`                    |
| `error`                  | Any module  | renderer.js    | `{message, error}`               |
| `audioDeviceChanged`     | STT         | renderer.js    | `{device}`                       |

---

### 2. **STT (Speech-to-Text)**

**DiretÃ³rio**: `stt/` com 4 providers implementados

#### stt-whisper.js (Principal)

```javascript
class WhisperSTT extends BaseSTT {
	// MÃ©todos principais:
	// â€¢ initialize(model) - Inicializa cliente
	// â€¢ startCapture(source, deviceId) - Abre stream de Ã¡udio
	// â€¢ transcribe() - Converte Ã¡udio em texto
	// â€¢ changeDevice(source, deviceId) - Troca entrada/saÃ­da
	// â€¢ stop() - Cleanup
}
```

**CaracterÃ­sticas**:

- Suporta 2 modos: local (Whisper.cpp CLI) + cloud (OpenAI Whisper-1)
- VAD (Voice Activity Detection) integrado via vad-engine.js
- Thresholds de silÃªncio/fala configurÃ¡veis
- Dispositivos de Ã¡udio dinÃ¢micos

#### Outros STT

- **stt-vosk.js**: Offline, multilingue, leve (Python subprocess)
- **stt-deepgram.js**: Cloud, alta precisÃ£o, real-time (via SDK)
- **stt-openrouter.js**: Agregador multimodel

#### vad-engine.js

- Motor centralizado de detecÃ§Ã£o de silÃªncio
- 3 modos: `NATIVE`, `FALLBACK` (volume), `HYBRID`
- Thresholds ajustÃ¡veis: silÃªncio (300ms), fala prÃ©-silÃªncio (100ms)

---

### 3. **LLM (Completions & Streaming)**

**DiretÃ³rio**: `llm/handlers/` com handlers plugÃ¡veis

#### PadrÃ£o Handler

```javascript
class MyLLMHandler {
	async initialize(apiKey) {
		/* Cliente setup */
	}
	async complete(messages) {
		/* Resposta completa (Promise<string>) */
	}
	async *stream(messages) {
		/* Generator async para tokens */
	}
}
```

#### Handlers Implementados

**openai-handler.js** âœ… (Completo)

- Modelos: GPT-4o, GPT-4o-mini, GPT-3.5-turbo
- Streaming via `on('data')` + parsing de SSE
- Timeout: 60s

**gemini-handler.js** âœ… (Pronto - pendente crÃ©dito para testar)

- Modelo: gemini-1.5-flash
- Streaming via AsyncGenerator + `text()` em stream
- Timeout: 60s
- Requer Google API key em https://ai.google.dev/

**template-handler.js** (ReferÃªncia)

- Guia passo-a-passo para criar novo handler
- Inclui exemplo de formato de mensagens e registro

#### LLMManager (renderer.js)

```javascript
const llmManager = new LLMManager();
llmManager.register('openai', openaiHandler);
llmManager.register('gemini', geminiHandler);
llmManager.selectProvider('openai'); // ou 'gemini'
const response = await llmManager.ask(messages);
```

---

### 4. **Main Process (Electron)**

**Arquivo**: `main.js`

#### Responsabilidades

1. **CriaÃ§Ã£o de janela**: overlay transparente, frameless, sempre visÃ­vel
2. **Armazenamento seguro**: `electron-store` com encriptaÃ§Ã£o
3. **InicializaÃ§Ã£o de clientes**: OpenAI, Gemini (baseado em chaves salvas)
4. **Handlers IPC**: Ponte renderer â†” main

#### IPC Handlers Principais

**ConfiguraÃ§Ã£o**:

- `GET_APP_CONFIG` â†’ retorna constantes APP_CONFIG
- `GET_API_KEY` â†’ lÃª chave do secure store
- `SAVE_API_KEY` â†’ salva chave + inicializa cliente (OpenAI ou Gemini)
- `DELETE_API_KEY` â†’ remove chave + desconecta cliente

**STT**:

- `transcribe-audio` â†’ chamada Whisper completa
- `transcribe-audio-partial` â†’ chamada Whisper streaming

**LLM**:

- `ask-llm` â†’ completaÃ§Ã£o OpenAI
- `ask-llm-stream` â†’ streaming OpenAI via eventos

**Atalhos globais**:

- `Ctrl+D` â†’ `CMD_TOGGLE_AUDIO` (inicia/para captura)
- `Ctrl+Enter` â†’ `CMD_ASK_LLM` (envia pergunta)

---

## ğŸ” SeguranÃ§a & Armazenamento

### electron-store (Encrypt)

```javascript
// InicializaÃ§Ã£o em main.js
const secureStore = new Store({
	configName: 'secure-config',
	encryptionKey: 'sua-chave-segura-aqui',
});

// Uso
secureStore.set('apiKeys.openai', trimmedKey);
const key = secureStore.get('apiKeys.openai');
secureStore.delete('apiKeys.openai');
```

### Fluxo de API Key

1. **UI** (config-manager.js) â†’ input campo "Google API Key"
2. **IPC SAVE_API_KEY** â†’ main.js valida + encripta + salva
3. **Client Init** â†’ main.js cria GoogleGenerativeAI(apiKey)
4. **Handler Acesso** â†’ gemini-handler usa cliente jÃ¡ inicializado
5. **Reset** â†’ apaga todas as chaves + desconecta clientes

---

## ğŸ“¡ Fluxo de Dados: Pergunta Completa

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. CAPTURA: UsuÃ¡rio fala (Ctrl+D ativa capture)                â”‚
â”‚    ModeController â†’ startAudioCapture() â†’ WhisperSTT.start()   â”‚
â”‚    VAD monitora volume, dispara transcribe() ao silÃªncio        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. STT: Converte Ã¡udio em texto (Whisper local ou OpenAI)      â”‚
â”‚    WhisperSTT.transcribe(audioBlob) â†’ "Como usar Node.js?"     â”‚
â”‚    Retorna IPC event: STT_RESULT â†’ renderer                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. PERGUNTA â†’ LLM: Envia para provider selecionado            â”‚
â”‚    ModeController â†’ llmManager.ask(messages)                   â”‚
â”‚    messages = [                                                 â”‚
â”‚      { role: 'system', content: SYSTEM_PROMPT },              â”‚
â”‚      { role: 'user', content: "Como usar Node.js?" }          â”‚
â”‚    ]                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. STREAMING: Tokens chegam via stream()                       â”‚
â”‚    async *stream(messages) â†’ yield "Node", yield ".js", ...   â”‚
â”‚    Cada token â†’ IPC LLM_STREAM_CHUNK â†’ UI atualiza em tempo realâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. RESPOSTA COMPLETA: Fim do streaming (LLM_STREAM_END)        â”‚
â”‚    Turn completo adicionado ao histÃ³rico com turnId            â”‚
â”‚    Pronto para prÃ³xima pergunta                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ ConfiguraÃ§Ã£o Chave (renderer.js, top)

```javascript
// Sistema prompt para LLM
const SYSTEM_PROMPT = `VocÃª Ã© um assistente de IA Ãºtil...`;

// Thresholds de silÃªncio (em ms)
const SILENCE_THRESHOLD = 300;
const LEADING_SILENCE_THRESHOLD = 100;

// Timeout transcriÃ§Ã£o
const TRANSCRIPTION_TIMEOUT = 30000; // 30s

// SeleÃ§Ã£o de STT/LLM
const DEFAULT_STT_MODEL = 'whisper'; // ou 'vosk', 'deepgram'
const DEFAULT_LLM_PROVIDER = 'openai'; // ou 'gemini'
```

---

## ğŸ“¦ DependÃªncias Principais

```json
{
	"devDependencies": {
		"electron": "^39.2.7",
		"electron-reload": "^2.0.0-alpha.1",
		"cross-env": "^10.1.0"
	},
	"dependencies": {
		"electron-store": "^11.0.2",
		"openai": "^6.10.0",
		"@google/generative-ai": "^0.x.x",
		"marked": "^17.0.1",
		"highlight.js": "^11.11.1",
		"wav": "^1.0.2"
	}
}
```

---

## ğŸš€ Como Estender

### Adicionar Novo LLM Provider

1. **Criar handler** em `llm/handlers/seu-provider-handler.js`

   ```javascript
   const Handler = require('./template-handler.js');
   class SeuProviderHandler extends Handler {
   	// Implementar: initialize, complete, stream
   }
   module.exports = new SeuProviderHandler();
   ```

2. **Registrar em renderer.js**

   ```javascript
   const suaHandler = require('./llm/handlers/seu-provider-handler.js');
   llmManager.register('seu-provider', suaHandler);
   ```

3. **Adicionar em main.js**

   ```javascript
   let seuClient = null;
   function initializeSeuClient(apiKey) {
   	/* setup */
   }
   // Atualizar handleSaveApiKey e handleDeleteApiKey
   ```

4. **Adicionar UI em config-manager.js**
   ```javascript
   // Aba "seu-provider" com input API key
   ```

ReferÃªncia completa em `llm/handlers/template-handler.js`.

### Adicionar Novo STT Provider

Similar ao LLM, herde de `BaseSTT` (nÃ£o existe yet - considerar refatorar).

---

## ğŸ“Š HistÃ³rico de Turnos (Turns)

Cada pergunta+resposta = 1 turn com estrutura:

```javascript
{
  turnId: 1,  // Incrementado globalmente
  timestamp: 1234567890,
  question: "Como usar Node.js?",
  answer: "Node.js Ã©...",
  provider: "openai",  // Qual LLM respondeu
  model: "gpt-4o-mini",
  status: "COMPLETED"  // ou ERROR
}
```

Renderizado em HTML com markdown (marked.js) + syntax highlight (highlight.js).

---

## âœ… Checklist de Qualidade PÃ³s-RefatoraÃ§Ã£o

- [x] 5 bugs da FASE 3 corrigidos e testados
- [x] Tema dark como padrÃ£o
- [x] Reset factory com limpeza total
- [x] OpenAI LLM integrado e testado
- [x] Gemini LLM integrado (pronto para testar)
- [x] Template para novos providers
- [ ] Testes unitÃ¡rios (nÃ£o implementado)
- [ ] DocumentaÃ§Ã£o de API em JSDoc
- [ ] SonarQube analysis (opcional)

---

## ğŸ”œ PrÃ³ximos Passos (FASE 5.3+)

1. **Teste Gemini** quando houver crÃ©dito
2. **Integrar Anthropic** (usar template-handler.js)
3. **Cleanup code**: Remover comentÃ¡rios antigos de refatoraÃ§Ã£o
4. **SonarQube**: AnÃ¡lise de qualidade de cÃ³digo
5. **Merge para main** quando pronto para produÃ§Ã£o

---

**Ãšltima atualizaÃ§Ã£o**: 23 jan 2026  
**Ramo**: `refatoracao`  
**Status**: FASE 5 em progresso
