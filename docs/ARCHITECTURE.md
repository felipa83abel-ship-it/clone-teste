# Arquitetura AskMe - RefatoraÃ§Ã£o Completa

Documento de referÃªncia da arquitetura apÃ³s refatoraÃ§Ã£o FASE 1-4 (jan 2026).

## ğŸ“‹ VisÃ£o Geral

**AskMe** Ã© um aplicativo Electron single-window que funciona como overlay sempre visÃ­vel, capturando Ã¡udio ambiente, convertendo em texto via STT (Speech-to-Text) e gerando respostas via LLM (Large Language Model).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  USUÃRIO (Ctrl+D: captura Ã¡udio, Ctrl+Enter: pergunta) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Overlay UI   â”‚  (transparente, frameless, sempre visÃ­vel)
        â”‚  (index.html)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  ModeController   â”‚  (Fala â†’ STT â†’ LLM â†’ Resposta)
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚          â”‚          â”‚
    â–¼          â–¼          â–¼
  STT       LLM        IPC
 Engine    Manager    Handlers
```

---

## ğŸ¯ Camadas Principais

### 1. **Renderer (Frontend)**

**Arquivos**: `renderer.js`, `config-manager.js`, `index.html`, `styles.css`

#### renderer.js

- **Ponto de entrada** do app (rodando no contexto renderer do Electron)
- ExpÃµe `window.RendererAPI` com mÃ©todos:
  - `startAudioCapture()` / `stopAudioCapture()`
  - `registerHotkey(keys, callback)`
  - `setText(text)`
  - IntegraÃ§Ã£o com medidores (VAD, volume)

#### ModeController

- **Orquestra o fluxo** principal: Fala â†’ STT â†’ LLM â†’ UI
- Gerencia turnos (questions/answers) com `turnId` Ãºnico
- Estados: `IDLE`, `LISTENING`, `TRANSCRIBING`, `ASKING_LLM`, `WAITING_RESPONSE`
- HeurÃ­sticas de silÃªncio/timeout configurÃ¡veis

#### config-manager.js

- Persiste configuraÃ§Ãµes em localStorage + secure store (electron-store)
- Gerencia seleÃ§Ã£o de providers (OpenAI, Google/Gemini, OpenRouter)
- UI abas: Geral, API e Modelos, Ãudio, Privacidade, Reset
- IntegraÃ§Ã£o com IPC para salvar/deletar chaves seguras

---

### 2. **STT (Speech-to-Text)**

**DiretÃ³rio**: `stt/` com 4 providers implementados

#### stt-whisper.js (Principal)

```javascript
class WhisperSTT extends BaseSTT {
	// MÃ©todos principais:
	// â€¢ initialize(model) - Inicializa cliente
	// â€¢ startCapture(source, deviceId) - Abre stream de Ã¡udio
	// â€¢ transcribe() - Converte Ã¡udio em texto
	// â€¢ changeDevice(source, deviceId) - Troca entrada/saÃ­da
	// â€¢ stop() - Cleanup
}
```

**CaracterÃ­sticas**:

- Suporta 2 modos: local (Whisper.cpp CLI) + cloud (OpenAI Whisper-1)
- VAD (Voice Activity Detection) integrado via vad-engine.js
- Thresholds de silÃªncio/fala configurÃ¡veis
- Dispositivos de Ã¡udio dinÃ¢micos

#### Outros STT

- **stt-vosk.js**: Offline, multilingue, leve (Python subprocess)
- **stt-deepgram.js**: Cloud, alta precisÃ£o, real-time (via SDK)
- **stt-openrouter.js**: Agregador multimodel

#### vad-engine.js

- Motor centralizado de detecÃ§Ã£o de silÃªncio
- 3 modos: `NATIVE`, `FALLBACK` (volume), `HYBRID`
- Thresholds ajustÃ¡veis: silÃªncio (300ms), fala prÃ©-silÃªncio (100ms)

---

### 3. **LLM (Completions & Streaming)**

**DiretÃ³rio**: `llm/handlers/` com handlers plugÃ¡veis

#### PadrÃ£o Handler

```javascript
class MyLLMHandler {
	async initialize(apiKey) {
		/* Cliente setup */
	}
	async complete(messages) {
		/* Resposta completa (Promise<string>) */
	}
	async *stream(messages) {
		/* Generator async para tokens */
	}
}
```

#### Handlers Implementados

**openai-handler.js** âœ… (Completo)

- Modelos: GPT-4o, GPT-4o-mini, GPT-3.5-turbo
- Streaming via `on('data')` + parsing de SSE
- Timeout: 60s

**gemini-handler.js** âœ… (Pronto - pendente crÃ©dito para testar)

- Modelo: gemini-1.5-flash
- Streaming via AsyncGenerator + `text()` em stream
- Timeout: 60s
- Requer Google API key em https://ai.google.dev/

**template-handler.js** (ReferÃªncia)

- Guia passo-a-passo para criar novo handler
- Inclui exemplo de formato de mensagens e registro

#### LLMManager (renderer.js)

```javascript
const llmManager = new LLMManager();
llmManager.register('openai', openaiHandler);
llmManager.register('gemini', geminiHandler);
llmManager.selectProvider('openai'); // ou 'gemini'
const response = await llmManager.ask(messages);
```

---

### 4. **Main Process (Electron)**

**Arquivo**: `main.js`

#### Responsabilidades

1. **CriaÃ§Ã£o de janela**: overlay transparente, frameless, sempre visÃ­vel
2. **Armazenamento seguro**: `electron-store` com encriptaÃ§Ã£o
3. **InicializaÃ§Ã£o de clientes**: OpenAI, Gemini (baseado em chaves salvas)
4. **Handlers IPC**: Ponte renderer â†” main

#### IPC Handlers Principais

**ConfiguraÃ§Ã£o**:

- `GET_APP_CONFIG` â†’ retorna constantes APP_CONFIG
- `GET_API_KEY` â†’ lÃª chave do secure store
- `SAVE_API_KEY` â†’ salva chave + inicializa cliente (OpenAI ou Gemini)
- `DELETE_API_KEY` â†’ remove chave + desconecta cliente

**STT**:

- `transcribe-audio` â†’ chamada Whisper completa
- `transcribe-audio-partial` â†’ chamada Whisper streaming

**LLM**:

- `ask-llm` â†’ completaÃ§Ã£o OpenAI
- `ask-llm-stream` â†’ streaming OpenAI via eventos

**Atalhos globais**:

- `Ctrl+D` â†’ `CMD_TOGGLE_AUDIO` (inicia/para captura)
- `Ctrl+Enter` â†’ `CMD_ASK_LLM` (envia pergunta)

---

## ğŸ” SeguranÃ§a & Armazenamento

### electron-store (Encrypt)

```javascript
// InicializaÃ§Ã£o em main.js
const secureStore = new Store({
	configName: 'secure-config',
	encryptionKey: 'sua-chave-segura-aqui',
});

// Uso
secureStore.set('apiKeys.openai', trimmedKey);
const key = secureStore.get('apiKeys.openai');
secureStore.delete('apiKeys.openai');
```

### Fluxo de API Key

1. **UI** (config-manager.js) â†’ input campo "Google API Key"
2. **IPC SAVE_API_KEY** â†’ main.js valida + encripta + salva
3. **Client Init** â†’ main.js cria GoogleGenerativeAI(apiKey)
4. **Handler Acesso** â†’ gemini-handler usa cliente jÃ¡ inicializado
5. **Reset** â†’ apaga todas as chaves + desconecta clientes

---

## ğŸ“¡ Fluxo de Dados: Pergunta Completa

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. CAPTURA: UsuÃ¡rio fala (Ctrl+D ativa capture)                â”‚
â”‚    ModeController â†’ startAudioCapture() â†’ WhisperSTT.start()   â”‚
â”‚    VAD monitora volume, dispara transcribe() ao silÃªncio        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. STT: Converte Ã¡udio em texto (Whisper local ou OpenAI)      â”‚
â”‚    WhisperSTT.transcribe(audioBlob) â†’ "Como usar Node.js?"     â”‚
â”‚    Retorna IPC event: STT_RESULT â†’ renderer                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. PERGUNTA â†’ LLM: Envia para provider selecionado            â”‚
â”‚    ModeController â†’ llmManager.ask(messages)                   â”‚
â”‚    messages = [                                                 â”‚
â”‚      { role: 'system', content: SYSTEM_PROMPT },              â”‚
â”‚      { role: 'user', content: "Como usar Node.js?" }          â”‚
â”‚    ]                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. STREAMING: Tokens chegam via stream()                       â”‚
â”‚    async *stream(messages) â†’ yield "Node", yield ".js", ...   â”‚
â”‚    Cada token â†’ IPC LLM_STREAM_CHUNK â†’ UI atualiza em tempo realâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. RESPOSTA COMPLETA: Fim do streaming (LLM_STREAM_END)        â”‚
â”‚    Turn completo adicionado ao histÃ³rico com turnId            â”‚
â”‚    Pronto para prÃ³xima pergunta                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ ConfiguraÃ§Ã£o Chave (renderer.js, top)

```javascript
// Sistema prompt para LLM
const SYSTEM_PROMPT = `VocÃª Ã© um assistente de IA Ãºtil...`;

// Thresholds de silÃªncio (em ms)
const SILENCE_THRESHOLD = 300;
const LEADING_SILENCE_THRESHOLD = 100;

// Timeout transcriÃ§Ã£o
const TRANSCRIPTION_TIMEOUT = 30000; // 30s

// SeleÃ§Ã£o de STT/LLM
const DEFAULT_STT_MODEL = 'whisper'; // ou 'vosk', 'deepgram'
const DEFAULT_LLM_PROVIDER = 'openai'; // ou 'gemini'
```

---

## ğŸ“¦ DependÃªncias Principais

```json
{
	"devDependencies": {
		"electron": "^39.2.7",
		"electron-reload": "^2.0.0-alpha.1",
		"cross-env": "^10.1.0"
	},
	"dependencies": {
		"electron-store": "^11.0.2",
		"openai": "^6.10.0",
		"@google/generative-ai": "^0.x.x",
		"marked": "^17.0.1",
		"highlight.js": "^11.11.1",
		"wav": "^1.0.2"
	}
}
```

---

## ğŸš€ Como Estender

### Adicionar Novo LLM Provider

1. **Criar handler** em `llm/handlers/seu-provider-handler.js`

   ```javascript
   const Handler = require('./template-handler.js');
   class SeuProviderHandler extends Handler {
   	// Implementar: initialize, complete, stream
   }
   module.exports = new SeuProviderHandler();
   ```

2. **Registrar em renderer.js**

   ```javascript
   const suaHandler = require('./llm/handlers/seu-provider-handler.js');
   llmManager.register('seu-provider', suaHandler);
   ```

3. **Adicionar em main.js**

   ```javascript
   let seuClient = null;
   function initializeSeuClient(apiKey) {
   	/* setup */
   }
   // Atualizar handleSaveApiKey e handleDeleteApiKey
   ```

4. **Adicionar UI em config-manager.js**
   ```javascript
   // Aba "seu-provider" com input API key
   ```

ReferÃªncia completa em `llm/handlers/template-handler.js`.

### Adicionar Novo STT Provider

Similar ao LLM, herde de `BaseSTT` (nÃ£o existe yet - considerar refatorar).

---

## ğŸ“Š HistÃ³rico de Turnos (Turns)

Cada pergunta+resposta = 1 turn com estrutura:

```javascript
{
  turnId: 1,  // Incrementado globalmente
  timestamp: 1234567890,
  question: "Como usar Node.js?",
  answer: "Node.js Ã©...",
  provider: "openai",  // Qual LLM respondeu
  model: "gpt-4o-mini",
  status: "COMPLETED"  // ou ERROR
}
```

Renderizado em HTML com markdown (marked.js) + syntax highlight (highlight.js).

---

## âœ… Checklist de Qualidade PÃ³s-RefatoraÃ§Ã£o

- [x] 5 bugs da FASE 3 corrigidos e testados
- [x] Tema dark como padrÃ£o
- [x] Reset factory com limpeza total
- [x] OpenAI LLM integrado e testado
- [x] Gemini LLM integrado (pronto para testar)
- [x] Template para novos providers
- [ ] Testes unitÃ¡rios (nÃ£o implementado)
- [ ] DocumentaÃ§Ã£o de API em JSDoc
- [ ] SonarQube analysis (opcional)

---

## ğŸ”œ PrÃ³ximos Passos (FASE 5.3+)

1. **Teste Gemini** quando houver crÃ©dito
2. **Integrar Anthropic** (usar template-handler.js)
3. **Cleanup code**: Remover comentÃ¡rios antigos de refatoraÃ§Ã£o
4. **SonarQube**: AnÃ¡lise de qualidade de cÃ³digo
5. **Merge para main** quando pronto para produÃ§Ã£o

---

**Ãšltima atualizaÃ§Ã£o**: 23 jan 2026  
**Ramo**: `refatoracao`  
**Status**: FASE 5 em progresso
