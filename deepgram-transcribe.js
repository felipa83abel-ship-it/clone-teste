/**
 * üåä DEEPGRAM LIVE STREAMING - M√ìDULO INDEPENDENTE
 *
 * Implementa√ß√£o isolada de transcri√ß√£o com Deepgram Live Streaming.
 * - Captura √°udio diretamente via WebSocket (sem IPC para dados bin√°rios)
 * - Consolida interim results em transcri√ß√µes finais
 * - Converge para handleSpeech() como outros providers (Whisper, Vosk)
 *
 * Uso:
 * - startAudioDeepgram() -> startDeepgramInput() / stopDeepgramInput() para capturar microfone
 * - startAudioDeepgram() -> startDeepgramOutput() / stopDeepgramOutput() para capturar sa√≠da
 */

/* ================================
   IMPORTS
================================ */
const { ipcRenderer } = require('electron');

/* ================================
   CONSTANTES
================================ */
const YOU = 'Voc√™'; // Autor das transcri√ß√µes de entrada
const OTHER = 'Outros'; // Autor das transcri√ß√µes de sa√≠da

/* ================================
   ESTADO DO DEEPGRAM
================================ */

let deepgramInputWebSocket = null;
let deepgramOutputWebSocket = null; // ‚ö†Ô∏è WebSocket SEPARADO para OUTPUT
let isDeepgramInputActive = false;
let isDeepgramOutputActive = false;

let deepgramInputAudioContext = null;
let deepgramInputStream = null;
let deepgramInputProcessor = null;

let deepgramOutputAudioContext = null;
let deepgramOutputStream = null;
let deepgramOutputProcessor = null;

// Estado simplificado para interims atuais
let deepgramCurrentInterimInput = null; // Texto atual do interim input
let deepgramCurrentInterimOutput = null; // Texto atual do interim output

// Timestamps para sincronizar com padr√£o de outros modelos
let deepgramInputStartAt = null;
let deepgramInputStopAt = null;
let deepgramOutputStartAt = null;
let deepgramOutputStopAt = null;

// üî• Keepalive para evitar timeout 1011 do Deepgram
// Envia mensagem JSON {"type": "KeepAlive"} a cada 5 segundos
// Documenta√ß√£o: https://developers.deepgram.com/docs/audio-keep-alive
let deepgramInputHeartbeatInterval = null;
let deepgramOutputHeartbeatInterval = null;
const DEEPGRAM_HEARTBEAT_INTERVAL = 5000; // 5 segundos (entre 3-5 segundos conforme documenta√ß√£o)

/* ================================
   INICIALIZA√á√ÉO DO WEBSOCKET
================================ */

/**
 * Inicializa conex√£o WebSocket com Deepgram (gen√©rica para input/output)
 * @param {string} source - 'input' ou 'output'
 * @returns {Promise<WebSocket>}
 */
async function initDeepgramWS(source = 'input') {
	const isInput = source === 'input';
	const existingWS = isInput ? deepgramInputWebSocket : deepgramOutputWebSocket;

	if (existingWS && existingWS.readyState === WebSocket.OPEN) {
		console.log(`üåä WebSocket Deepgram ${source} j√° aberto`);
		return existingWS;
	}

	// Pega chave Deepgram salva
	const apiKey = await ipcRenderer.invoke('GET_API_KEY', 'deepgram');
	if (!apiKey) {
		throw new Error('‚ùå Chave Deepgram n√£o configurada. Configure em "API e Modelos"');
	}

	console.log(`üåä Inicializando WebSocket Deepgram ${source}...`);

	// Monta URL com par√¢metros (token √© passado na URL para evitar erros 401)
	const params = new URLSearchParams({
		model: 'nova-2',
		language: 'pt-BR',
		smart_format: 'true',
		interim_results: 'true',
		encoding: 'linear16',
		sample_rate: '16000',
		endpointing: '300', // Detecta pausas naturais
		utterance_end_ms: '1000', // Finaliza a frase ap√≥s 1s de sil√™ncio
	});

	const wsUrl = `wss://api.deepgram.com/v1/listen?${params.toString()}`;
	const ws = new WebSocket(wsUrl, ['token', apiKey.trim()]);

	return new Promise((resolve, reject) => {
		ws.onopen = () => {
			console.log(`‚úÖ WebSocket Deepgram ${source} conectado | readyState: ${ws.readyState}`);

			// Inicia heartbeat para manter conex√£o viva
			startDeepgramHeartbeat(ws, source);
			resolve(ws);
		};

		ws.onmessage = event => {
			console.log('üí¨ Mensagem Deepgram OUTPUT recebida (tamanho:', event.data.length, 'bytes)');
			try {
				const data = JSON.parse(event.data);
				handleDeepgramMessage(data, source);
			} catch (e) {
				console.error(`‚ùå Erro ao processar mensagem Deepgram ${source}:`, e);
			}
		};

		ws.onerror = err => {
			console.error(`‚ùå Erro WebSocket Deepgram ${source}:`, err);
			console.error('   Type:', err.type, 'Message:', err.message);

			reject(new Error(`Falha ao conectar Deepgram ${source}`));
		};

		ws.onclose = event => {
			console.log(
				`üõë WebSocket Deepgram ${source} fechado | Code: ${event.code} | Reason: ${event.reason || 'nenhum'} | Clean: ${
					event.wasClean
				}`,
			);
			stopDeepgramHeartbeat(source);
			if (isInput) deepgramInputWebSocket = null;
			else deepgramOutputWebSocket = null;
		};
	});
}

/**
 * Inicia heartbeat para manter WebSocket Deepgram vivo
 * @param {WebSocket} ws - WebSocket aberto
 * @param {string} source - 'input' ou 'output'
 */
function startDeepgramHeartbeat(ws, source) {
	const interval = setInterval(() => {
		if (ws && ws.readyState === WebSocket.OPEN) {
			try {
				ws.send(JSON.stringify({ type: 'KeepAlive' }));
			} catch (e) {
				console.error(`‚ùå Erro ao enviar KeepAlive ${source}:`, e);
			}
		}
	}, DEEPGRAM_HEARTBEAT_INTERVAL);

	if (source === 'input') {
		deepgramInputHeartbeatInterval = interval;
	} else {
		deepgramOutputHeartbeatInterval = interval;
	}
}

/**
 * Para heartbeat de um WebSocket
 * @param {string} source - 'input' ou 'output'
 */
function stopDeepgramHeartbeat(source) {
	if (source === 'input') {
		if (deepgramInputHeartbeatInterval) {
			clearInterval(deepgramInputHeartbeatInterval);
			deepgramInputHeartbeatInterval = null;
		}
	} else if (source === 'output') {
		if (deepgramOutputHeartbeatInterval) {
			clearInterval(deepgramOutputHeartbeatInterval);
			deepgramOutputHeartbeatInterval = null;
		}
	}
}

/* ===============================
   DEEPGRAM - INICIA FLUXO (STT)
=============================== */

// üî• DEEPGRAM: Inicia captura (wrapper)
async function startAudioDeepgram(UIElements) {
	debugLogRenderer('In√≠cio da fun√ß√£o: "startAudioDeepgram"');

	try {
		// üåä Deepgram: Inicia INPUT/OUTPUT
		if (UIElements.inputSelect?.value) await startDeepgramInput(UIElements);
		if (UIElements.outputSelect?.value) await startDeepgramOutput(UIElements);
	} catch (error) {
		console.error('‚ùå Erro ao iniciar Deepgram:', error);
		throw error;
	}

	debugLogRenderer('Fim da fun√ß√£o: "startAudioDeepgram"');
}

/**
 * Inicia captura de √°udio do dispositivo de entrada com Deepgram
 */
async function startDeepgramInput(UIElements) {
	// Passo 1: Iniciar captura de √°udio da sa√≠da

	if (isDeepgramInputActive) {
		console.warn('‚ö†Ô∏è Deepgram INPUT j√° ativo');
		return;
	}

	try {
		// Obt√©m o dispositivo INPUT selecionado no UI (busca diretamente no DOM)
		const inputDeviceId = UIElements.inputSelect?.value;

		console.log(`üîä Iniciando captura INPUT com dispositivo: ${inputDeviceId}`);

		// Inicializa WebSocket usando fun√ß√£o gen√©rica
		const ws = await initDeepgramWS('input');
		deepgramInputWebSocket = ws;
		isDeepgramInputActive = true;
		deepgramInputStartAt = Date.now();
		deepgramInputStopAt = null;
		deepgramCurrentInterimInput = null; // Inicializar interim

		// Solicita acesso ao dispositivo INPUT selecionado
		console.log('üé§ Solicitando acesso √† entrada de √°udio (Microfone)...');

		deepgramInputStream = await navigator.mediaDevices.getUserMedia({
			audio: { deviceId: { exact: inputDeviceId } },
		});

		console.log('‚úÖ Entrada de √°udio autorizada');

		// Cria AudioContext com 16kHz
		deepgramInputAudioContext = new (window.AudioContext || window.webkitAudioContext)({
			sampleRate: 16000,
		});

		// Carrega o AudioWorklet
		await deepgramInputAudioContext.audioWorklet.addModule('./deepgram-audio-worklet-processor.js');

		const source = deepgramInputAudioContext.createMediaStreamSource(deepgramInputStream);

		// Cria AudioWorkletNode em vez de ScriptProcessor
		deepgramInputProcessor = new AudioWorkletNode(deepgramInputAudioContext, 'deepgram-audio-worklet-processor');

		// Define threshold mais alto para input (microfone) para filtrar ru√≠do
		deepgramInputProcessor.port.postMessage({ type: 'setThreshold', threshold: 0.01 });

		// Escuta mensagens do worklet
		deepgramInputProcessor.port.onmessage = event => {
			const { type, pcm16, percent } = event.data;
			if (type === 'audioData' && deepgramInputWebSocket?.readyState === WebSocket.OPEN) {
				// Envia PCM16 via WebSocket
				deepgramInputWebSocket.send(pcm16);
			} else if (type === 'volumeUpdate') {
				// Atualiza UI com volume
				emitUIChange('onInputVolumeUpdate', { percent });
			}
		};

		source.connect(deepgramInputProcessor);
		deepgramInputProcessor.connect(deepgramInputAudioContext.destination);

		console.log('‚ñ∂Ô∏è Captura Deepgram INPUT iniciada');
	} catch (error) {
		console.error('‚ùå Erro ao iniciar Deepgram INPUT:', error);
		isDeepgramInputActive = false;
		stopDeepgramInput();
		throw error;
	}
}

/**
 * Inicia captura de √°udio da sa√≠da (speaker/loopback via VoiceMeter ou Stereo Mix)
 * Usa o dispositivo selecionado no select #audio-output-device (mesma l√≥gica do INPUT)
 */
async function startDeepgramOutput(UIElements) {
	// Passo 1: Iniciar captura de √°udio da sa√≠da

	if (isDeepgramOutputActive) {
		console.warn('‚ö†Ô∏è Deepgram OUTPUT j√° ativo');
		return;
	}

	try {
		// Obt√©m o dispositivo OUTPUT selecionado no UI (busca diretamente no DOM)
		const outputDeviceId = UIElements.outputSelect?.value;

		if (!outputDeviceId) {
			console.warn('‚ö†Ô∏è Nenhum dispositivo OUTPUT selecionado. Pulando captura OUTPUT.');
			return;
		}

		console.log(`üîä Iniciando captura OUTPUT com dispositivo: ${outputDeviceId}`);

		// Inicializa WebSocket usando fun√ß√£o gen√©rica
		const ws = await initDeepgramWS('output');
		deepgramOutputWebSocket = ws;
		isDeepgramOutputActive = true;
		deepgramOutputStartAt = Date.now();
		deepgramOutputStopAt = null;
		deepgramCurrentInterimOutput = null; // Inicializar interim

		// Solicita acesso ao dispositivo OUTPUT selecionado
		console.log('üîä Solicitando acesso √† sa√≠da de √°udio (VoiceMeter/Stereo Mix)...');

		deepgramOutputStream = await navigator.mediaDevices.getUserMedia({
			audio: { deviceId: { exact: outputDeviceId } },
		});

		console.log('‚úÖ Sa√≠da de √°udio autorizada');

		// Cria AudioContext com 16kHz
		deepgramOutputAudioContext = new (window.AudioContext || window.webkitAudioContext)({
			sampleRate: 16000,
		});

		// Carrega o AudioWorklet
		await deepgramOutputAudioContext.audioWorklet.addModule('./deepgram-audio-worklet-processor.js');

		const source = deepgramOutputAudioContext.createMediaStreamSource(deepgramOutputStream);

		// Cria AudioWorkletNode em vez de ScriptProcessor
		deepgramOutputProcessor = new AudioWorkletNode(deepgramOutputAudioContext, 'deepgram-audio-worklet-processor');

		// Define threshold para output (VoiceMeter) - mais baixo, pois √© mais limpo
		deepgramOutputProcessor.port.postMessage({ type: 'setThreshold', threshold: 0.005 });

		// Escuta mensagens do worklet
		deepgramOutputProcessor.port.onmessage = event => {
			const { type, pcm16, percent } = event.data;
			if (type === 'audioData' && deepgramOutputWebSocket?.readyState === WebSocket.OPEN) {
				//console.log(`üü° Enviando √°udio OUTPUT para o Deepgram - ${new Date().toLocaleTimeString("pt-BR")}`);

				// Envia PCM16 via WebSocket
				deepgramOutputWebSocket.send(pcm16);
			} else if (type === 'volumeUpdate') {
				// Atualiza UI com volume
				emitUIChange('onOutputVolumeUpdate', { percent });
			}
		};

		source.connect(deepgramOutputProcessor);
		deepgramOutputProcessor.connect(deepgramOutputAudioContext.destination);

		console.log('‚ñ∂Ô∏è Captura Deepgram OUTPUT iniciada');
	} catch (error) {
		console.error('‚ùå Erro ao iniciar Deepgram OUTPUT:', error);
		isDeepgramOutputActive = false;
		stopDeepgramOutput();
		throw error;
	}
}

/* ================================
	DEEPGRAM - PARA FLUXO (STT)
================================ */

// üî• DEEPGRAM: Para captura (wrapper) - Agora s√≠ncrona, sem async desnecess√°rio
function stopAudioDeepgram() {
	debugLogRenderer('In√≠cio da fun√ß√£o: "stopAudioDeepgram"');

	try {
		// üåä Deepgram: Para INPUT e OUTPUT
		stopAllDeepgram(); // Fecha WebSocket
		console.log('‚úÖ Deepgram parado');
	} catch (error) {
		console.error('‚ùå Erro ao parar Deepgram:', error);
	}

	debugLogRenderer('Fim da fun√ß√£o: "stopAudioDeepgram"');
}

// Fun√ß√£o gen√©rica para parar input ou output (elimina duplica√ß√£o)
function stopDeepgram(source) {
	const isInput = source === 'input';
	const ws = isInput ? deepgramInputWebSocket : deepgramOutputWebSocket;
	const isActive = isInput ? isDeepgramInputActive : isDeepgramOutputActive;

	// Verifica√ß√£o de estado: se j√° parado, sai cedo
	if (!isActive) {
		console.log(`‚ö†Ô∏è Deepgram ${source} j√° parado, pulando.`);
		return;
	}

	// Define flag como false
	if (isInput) isDeepgramInputActive = false;
	else isDeepgramOutputActive = false;

	// Envia "CloseStream" se WebSocket estiver aberto
	if (ws && ws.readyState === WebSocket.OPEN) {
		try {
			ws.send(JSON.stringify({ type: 'CloseStream' }));
			console.log(`üì§ CloseStream enviado para ${source.toUpperCase()}`);
		} catch (e) {
			console.error(`‚ùå Erro ao enviar CloseStream ${source}:`, e);
		}
	}

	// Para heartbeat
	stopDeepgramHeartbeat(source);

	// Fecha WebSocket
	if (ws) {
		try {
			ws.close();
		} catch (e) {
			console.error(`Erro ao fechar WebSocket ${source}:`, e);
		}
		if (isInput) deepgramInputWebSocket = null;
		else deepgramOutputWebSocket = null;
	}

	// Limpar interims
	if (isInput) deepgramCurrentInterimInput = null;
	else deepgramCurrentInterimOutput = null;

	// Limpa recursos (usando vari√°veis din√¢micas)
	const processor = isInput ? deepgramInputProcessor : deepgramOutputProcessor;
	const stream = isInput ? deepgramInputStream : deepgramOutputStream;
	const audioContext = isInput ? deepgramInputAudioContext : deepgramOutputAudioContext;

	if (processor) {
		processor.disconnect();
		if (isInput) deepgramInputProcessor = null;
		else deepgramOutputProcessor = null;
	}

	if (stream) {
		stream.getTracks().forEach(t => t.stop());
		if (isInput) deepgramInputStream = null;
		else deepgramOutputStream = null;
	}

	if (audioContext) {
		audioContext.close();
		if (isInput) deepgramInputAudioContext = null;
		else deepgramOutputAudioContext = null;
	}

	console.log(`üõë Captura Deepgram ${source.toUpperCase()} parada`);
}

// Atualiza stopAllDeepgram para usar a fun√ß√£o gen√©rica
function stopAllDeepgram() {
	stopDeepgram('input');
	stopDeepgram('output');
	console.log('üåä Deepgram completamente parado');
}

/* ================================
   PROCESSAMENTO DE MENSAGENS
================================ */

/**
 * Processa mensagens do Deepgram para INPUT ou OUTPUT
 * INPUT = Microfone do usu√°rio (Voc√™ / Microfone)
 * OUTPUT = Sa√≠da de √°udio do PC (Outros / VoiceMeter)
 */
function handleDeepgramMessage(data, source = 'input') {
	const transcript = data.channel?.alternatives?.[0]?.transcript || '';
	const confidence = data.channel?.alternatives?.[0]?.confidence || 0;
	const isFinal = data.is_final || false;
	const speechFinal = data.speech_final;

	if (!transcript || !transcript.trim()) return; // Ignora transcri√ß√µes vazias

	// Logs b√°sicos
	console.log(`üì• RESPOSTA DO DEEPGRAM - (${source}) - ${new Date().toLocaleTimeString('pt-BR')}`);
	console.log(`üü° isFinal: ${isFinal}, speechFinal: ${speechFinal}, transcript: "${transcript}"`);

	const isInput = source === 'input';
	const author = isInput ? YOU : OTHER;

	if (isFinal) {
		console.log(`üìù ‚úÖ FINAL [${source.toUpperCase()}]: "${transcript}" (${(confidence * 100).toFixed(1)}%)`);

		// Chamar handleSpeech para criar nova transcri√ß√£o no hist√≥rico
		handleSpeech(author, transcript);

		// Resetar interim atual
		if (isInput) {
			deepgramCurrentInterimInput = null;
		} else {
			deepgramCurrentInterimOutput = null;
		}

		// Limpar elemento interim no UI
		const interimId = isInput ? 'deepgram-interim-input' : 'deepgram-interim-output';
		if (globalThis.RendererAPI?.emitUIChange) {
			globalThis.RendererAPI.emitUIChange('onClearInterim', { id: interimId });
		}

		// Emite evento global onTranscriptionComplete para OUTPUT
		if (source === 'output' && globalThis.emitSTTEvent) {
			console.log('üåä Deepgram OUTPUT: Emitindo evento onTranscriptionComplete');
			globalThis.emitSTTEvent('transcriptionComplete', {
				text: transcript,
				speaker: author,
				isFinal: true,
				model: 'deepgram',
				confidence: confidence,
			});
		}
	} else {
		// Interim: Atualizar o texto do elemento "current interim"
		console.log(`üü° INTERIM [${source}]: "${transcript}"`);

		const interimId = isInput ? 'deepgram-interim-input' : 'deepgram-interim-output';

		if (globalThis.RendererAPI?.emitUIChange) {
			globalThis.RendererAPI.emitUIChange('onUpdateInterim', {
				id: interimId,
				speaker: author,
				text: transcript,
			});
		}

		// Atualizar estado
		if (isInput) {
			deepgramCurrentInterimInput = transcript;
		} else {
			deepgramCurrentInterimOutput = transcript;

			// Para output, atualizar CURRENT em tempo real
			if (typeof globalThis.handleSpeechInterim === 'function') {
				console.log(`üîÑ [INTERIM] Atualizando CURRENT em tempo real com: "${transcript}"`);
				globalThis.handleSpeechInterim(author, transcript, { isInterim: true, skipAddToUI: true });
			}
		}
	}
}

/* ================================
   EXPORTS (CommonJS)
================================ */
// Exp√µe fun√ß√µes globalmente para uso em renderer.js
// Nota: Em Electron com nodeIntegration: true, as fun√ß√µes
// definidas aqui ficar√£o acess√≠veis no escopo global
// Alternativa: module.exports para acesso via require()
module.exports = {
	startAudioDeepgram,
	stopAudioDeepgram,
};
