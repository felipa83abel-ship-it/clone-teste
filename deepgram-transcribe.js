/**
 * üåä DEEPGRAM LIVE STREAMING - M√ìDULO INDEPENDENTE
 *
 * Implementa√ß√£o isolada de transcri√ß√£o com Deepgram Live Streaming.
 * - Captura √°udio diretamente via WebSocket (sem IPC para dados bin√°rios)
 * - Consolida interim results e transcri√ß√µes finais
 *
 * Uso:
 * - startAudioDeepgram() -> startDeepgramInput() / stopDeepgramInput() para capturar entrada
 * - startAudioDeepgram() -> startDeepgramOutput() / stopDeepgramOutput() para capturar sa√≠da
 */

/* ================================
   IMPORTS
================================ */
const { ipcRenderer } = require('electron');

/* ================================
   CONSTANTES
================================ */
const USE_DEEPGRAM_MOCK = false; // Ativa mock para testes sem Deepgram real

const YOU = 'Voc√™'; // Autor das transcri√ß√µes de entrada
const OTHER = 'Outros'; // Autor das transcri√ß√µes de sa√≠da

const DEEPGRAM_HEARTBEAT_INTERVAL = 5000; // 5 segundos (entre 3-5 segundos conforme documenta√ß√£o)

/* ================================
   ESTADO DO DEEPGRAM
================================ */

let deepgramInputWebSocket = null; // ‚ö†Ô∏è WebSocket SEPARADO para INPUT
let deepgramOutputWebSocket = null; // ‚ö†Ô∏è WebSocket SEPARADO para OUTPUT
let isDeepgramInputActive = false;
let isDeepgramOutputActive = false;

let deepgramInputAudioContext = null;
let deepgramInputStream = null;
let deepgramInputProcessor = null;
let deepgramInputSource = null; // MediaStreamSource para input
let deepgramInputHPF = null; // High-pass filter para input

let deepgramOutputAudioContext = null;
let deepgramOutputStream = null;
let deepgramOutputProcessor = null;
let deepgramOutputSource = null; // MediaStreamSource para output
let deepgramOutputHPF = null; // High-pass filter para output

let isSwitchingInput = false;
let isSwitchingOutput = false;

// üî• Keepalive para evitar timeout 1011 do Deepgram
// Envia mensagem JSON {"type": "KeepAlive"} a cada 5 segundos
// Documenta√ß√£o: https://developers.deepgram.com/docs/audio-keep-alive
let deepgramInputHeartbeatInterval = null;
let deepgramOutputHeartbeatInterval = null;

// Timestamps para sincronizar com padr√£o de outros modelos
let deepgramInputStartAt = null;
let deepgramOutputStartAt = null;

// Objeto para mapear vari√°veis de input/output
const deepgramVars = {
	input: {
		ws: () => deepgramInputWebSocket,
		setWs: val => (deepgramInputWebSocket = val),
		isActive: () => isDeepgramInputActive,
		setActive: val => (isDeepgramInputActive = val),
		processor: () => deepgramInputProcessor,
		setProcessor: val => (deepgramInputProcessor = val),
		stream: () => deepgramInputStream,
		setStream: val => (deepgramInputStream = val),
		audioContext: () => deepgramInputAudioContext,
		setAudioContext: val => (deepgramInputAudioContext = val),
		lastActive: Date.now(),
		inSilence: false,
		noiseStartTime: null, // üî• NOVO: Rastreia quando o ru√≠do come√ßou
		finalizeTriggered: false, // üî• NOVO: Garante que o pr√≥ximo final dispare o GPT
	},
	output: {
		ws: () => deepgramOutputWebSocket,
		setWs: val => (deepgramOutputWebSocket = val),
		isActive: () => isDeepgramOutputActive,
		setActive: val => (isDeepgramOutputActive = val),
		processor: () => deepgramOutputProcessor,
		setProcessor: val => (deepgramOutputProcessor = val),
		stream: () => deepgramOutputStream,
		setStream: val => (deepgramOutputStream = val),
		audioContext: () => deepgramOutputAudioContext,
		setAudioContext: val => (deepgramOutputAudioContext = val),
		lastActive: Date.now(),
		inSilence: false,
		noiseStartTime: null, // üî• NOVO: Rastreia quando o ru√≠do come√ßou
		finalizeTriggered: false, // üî• NOVO: Garante que o pr√≥ximo final dispare o GPT
	},
};

/* ===============================
   DEEPGRAM - INICIA FLUXO (STT)
=============================== */
/**
 * Inicia captura de √°udio do dispositivo de entrada e/ou sa√≠da com Deepgram
 */
async function startAudioDeepgram(UIElements) {
	debugLogRenderer('In√≠cio da fun√ß√£o: "startAudioDeepgram"');

	try {
		// üåä Deepgram: Inicia INPUT/OUTPUT
		if (UIElements.inputSelect?.value) await startDeepgramInput(UIElements);
		if (UIElements.outputSelect?.value) await startDeepgramOutput(UIElements);
	} catch (error) {
		console.error('‚ùå Erro ao iniciar Deepgram:', error);
		throw error;
	}

	debugLogRenderer('Fim da fun√ß√£o: "startAudioDeepgram"');
}

/**
 * Inicia captura de √°udio do dispositivo de entrada com Deepgram
 */
async function startDeepgramInput(UIElements) {
	// Passo 1: Iniciar captura de √°udio da sa√≠da

	if (isDeepgramInputActive) {
		console.warn('‚ö†Ô∏è Deepgram INPUT j√° ativo');
		return;
	}

	try {
		// Obt√©m o dispositivo INPUT selecionado no UI (busca diretamente no DOM)
		const inputDeviceId = UIElements.inputSelect?.value;

		console.log(`üîä Iniciando captura INPUT com dispositivo: ${inputDeviceId}`);

		// Inicializa WebSocket usando fun√ß√£o gen√©rica
		const ws = USE_DEEPGRAM_MOCK ? initDeepgramWSMock() : await initDeepgramWS('input');

		// Define flags globais
		deepgramInputWebSocket = ws;
		isDeepgramInputActive = true;
		deepgramInputStartAt = Date.now();

		// Solicita acesso ao dispositivo INPUT selecionado
		console.log('üé§ Solicitando acesso √† entrada de √°udio (Microfone)...');

		deepgramInputStream = await navigator.mediaDevices.getUserMedia({
			audio: {
				deviceId: { exact: inputDeviceId },
				echoCancellation: true,
				noiseSuppression: true,
				autoGainControl: false,
			},
		});

		console.log('‚úÖ Entrada de √°udio autorizada');

		// Cria AudioContext com 16kHz
		deepgramInputAudioContext = new (globalThis.AudioContext || globalThis.webkitAudioContext)({
			sampleRate: 16000,
		});

		// Carrega o AudioWorklet
		await deepgramInputAudioContext.audioWorklet.addModule('./deepgram-audio-worklet-processor.js');

		// Cria MediaStreamSource e guarda em vari√°vel global para permitir troca din√¢mica
		deepgramInputSource = deepgramInputAudioContext.createMediaStreamSource(deepgramInputStream);

		// üî• NOVO: Filtro Passa-Alta para supress√£o de ru√≠do (ventilador, respira√ß√£o)
		// Corta frequ√™ncias abaixo de 200Hz que n√£o s√£o essenciais para a fala mas cont√™m muito ru√≠do.
		deepgramInputHPF = deepgramInputAudioContext.createBiquadFilter();
		deepgramInputHPF.type = 'highpass';
		deepgramInputHPF.frequency.value = 200; // Ajuste fino para cortar ar do ventilador
		deepgramInputHPF.Q.value = 1;

		// Cria AudioWorkletNode em vez de ScriptProcessor
		deepgramInputProcessor = new AudioWorkletNode(deepgramInputAudioContext, 'deepgram-audio-worklet-processor');

		// Define threshold para input - Ajustado para ignorar sil√™ncio ruidoso
		deepgramInputProcessor.port.postMessage({ type: 'setThreshold', threshold: 0.02 });

		// Escuta mensagens do worklet
		deepgramInputProcessor.port.onmessage = event => {
			const { type, pcm16, percent } = event.data;
			if (type === 'audioData' && deepgramInputWebSocket?.readyState === WebSocket.OPEN) {
				// Envia PCM16 via WebSocket
				deepgramInputWebSocket.send(pcm16);
			} else if (type === 'volumeUpdate') {
				// Atualiza UI com volume
				if (globalThis.RendererAPI?.emitUIChange) {
					globalThis.RendererAPI.emitUIChange('onInputVolumeUpdate', { percent });
				}

				// Trata detec√ß√£o de sil√™ncio
				handleSilenceDetection('input', percent);
			}
		};

		// Conecta fluxo: Source -> HighPassFilter -> Worklet
		deepgramInputSource.connect(deepgramInputHPF);
		deepgramInputHPF.connect(deepgramInputProcessor);
		deepgramInputProcessor.connect(deepgramInputAudioContext.destination);

		console.log('‚ñ∂Ô∏è Captura Deepgram INPUT iniciada');
	} catch (error) {
		console.error('‚ùå Erro ao iniciar Deepgram INPUT:', error);
		isDeepgramInputActive = false;
		stopDeepgram('input');
		throw error;
	}
}

/**
 * Inicia captura de √°udio da sa√≠da (speaker/loopback via VoiceMeter ou Stereo Mix)
 * Usa o dispositivo selecionado no select #audio-output-device (mesma l√≥gica do INPUT)
 */
async function startDeepgramOutput(UIElements) {
	// Passo 1: Iniciar captura de √°udio da sa√≠da

	if (isDeepgramOutputActive) {
		console.warn('‚ö†Ô∏è Deepgram OUTPUT j√° ativo');
		return;
	}

	try {
		// Obt√©m o dispositivo OUTPUT selecionado no UI (busca diretamente no DOM)
		const outputDeviceId = UIElements.outputSelect?.value;

		console.log(`üîä Iniciando captura OUTPUT com dispositivo: ${outputDeviceId}`);

		// Inicializa WebSocket usando fun√ß√£o gen√©rica
		const ws = USE_DEEPGRAM_MOCK ? initDeepgramWSMock() : await initDeepgramWS('output');

		// Define flags globais
		deepgramOutputWebSocket = ws;
		isDeepgramOutputActive = true;
		deepgramOutputStartAt = Date.now();

		// Solicita acesso ao dispositivo OUTPUT selecionado
		console.log('üîä Solicitando acesso √† sa√≠da de √°udio (VoiceMeter/Stereo Mix)...');

		deepgramOutputStream = await navigator.mediaDevices.getUserMedia({
			audio: {
				deviceId: { exact: outputDeviceId },
				echoCancellation: true,
				noiseSuppression: true,
				autoGainControl: false, // Evita que o volume suba no sil√™ncio, expondo ru√≠do residual
			},
		});

		console.log('‚úÖ Sa√≠da de √°udio autorizada');

		// Cria AudioContext com 16kHz
		deepgramOutputAudioContext = new (globalThis.AudioContext || globalThis.webkitAudioContext)({
			sampleRate: 16000,
		});
		// Carrega o AudioWorklet
		await deepgramOutputAudioContext.audioWorklet.addModule('./deepgram-audio-worklet-processor.js');

		// Cria MediaStreamSource a partir do stream capturado e guarda para troca din√¢mica
		deepgramOutputSource = deepgramOutputAudioContext.createMediaStreamSource(deepgramOutputStream);

		// üî• NOVO: Filtro Passa-Alta para supress√£o de ru√≠do (ventilador, respira√ß√£o)
		// Corta frequ√™ncias abaixo de 200Hz que n√£o s√£o essenciais para a fala mas cont√™m muito ru√≠do.
		deepgramOutputHPF = deepgramOutputAudioContext.createBiquadFilter();
		deepgramOutputHPF.type = 'highpass';
		deepgramOutputHPF.frequency.value = 200; // Ajuste fino para cortar ar do ventilador
		deepgramOutputHPF.Q.value = 1;

		// Cria AudioWorkletNode em vez de ScriptProcessor
		deepgramOutputProcessor = new AudioWorkletNode(deepgramOutputAudioContext, 'deepgram-audio-worklet-processor');

		// Define threshold para output - Ajustado para ignorar sil√™ncio ruidoso
		deepgramOutputProcessor.port.postMessage({ type: 'setThreshold', threshold: 0.005 });

		// Escuta mensagens do worklet
		deepgramOutputProcessor.port.onmessage = event => {
			const { type, pcm16, percent } = event.data;
			if (type === 'audioData' && deepgramOutputWebSocket?.readyState === WebSocket.OPEN) {
				// Envia PCM16 via WebSocket
				deepgramOutputWebSocket.send(pcm16);
			} else if (type === 'volumeUpdate') {
				// Atualiza UI com volume
				if (globalThis.RendererAPI?.emitUIChange) {
					globalThis.RendererAPI.emitUIChange('onOutputVolumeUpdate', { percent });
				}

				// Trata detec√ß√£o de sil√™ncio
				handleSilenceDetection('output', percent, 700);
			}
		};

		// Conecta fluxo: Source -> HighPassFilter -> Worklet
		deepgramOutputSource.connect(deepgramOutputHPF);
		deepgramOutputHPF.connect(deepgramOutputProcessor);
		deepgramOutputProcessor.connect(deepgramOutputAudioContext.destination);

		console.log('‚ñ∂Ô∏è Captura Deepgram OUTPUT iniciada');
	} catch (error) {
		console.error('‚ùå Erro ao iniciar Deepgram OUTPUT:', error);
		isDeepgramOutputActive = false;
		stopDeepgram('output');
		throw error;
	}
}

// Trata detec√ß√£o de sil√™ncio com base no volume percentual
function handleSilenceDetection(source, percent, silenceTimeout = 500) {
	// NOSONAR console.log(`üîä ${source} volume: ${percent.toFixed(2)}%`);

	const vars = deepgramVars[source];

	// Constantes de debouncing
	const NOISE_IGNORE_THRESHOLD = 200; //ms - ignora picos de ru√≠do se j√° estiver em sil√™ncio

	if (percent > 0) {
		if (vars.inSilence) {
			// Se est√° em sil√™ncio mas detectou som, inicia timer de ru√≠do
			if (!vars.noiseStartTime) vars.noiseStartTime = Date.now();

			const noiseDuration = Date.now() - vars.noiseStartTime;

			//----------- Logs detalhados para debug
			const now = new Date();
			const timeStr =
				`${now.getHours().toString().padStart(2, '0')}:` +
				`${now.getMinutes().toString().padStart(2, '0')}:` +
				`${now.getSeconds().toString().padStart(2, '0')}.` +
				`${now.getMilliseconds().toString().padStart(3, '0')}`;
			console.log(
				`üîä ${source} | noiseDuration: ${noiseDuration} > NOISE_IGNORE_THRESHOLD: ${NOISE_IGNORE_THRESHOLD} - volume: ${percent.toFixed(
					2,
				)}% | ${timeStr}`,
			);
			//----------- Fim dos logs detalhados

			if (noiseDuration >= NOISE_IGNORE_THRESHOLD) {
				// S√≥ quebra o sil√™ncio se o som for persistente (fala real)
				vars.inSilence = false;
				vars.noiseStartTime = null;

				// NOSONAR
				console.log('üîä Fala real detectada (som persistente): ', percent.toFixed(2), '%');
			}
		} else {
			// Se n√£o est√° em sil√™ncio, apenas atualiza o tempo de atividade
			vars.lastActive = Date.now();
			vars.noiseStartTime = null;

			//----------- Logs detalhados para debug
			const now = new Date();
			const timeStr =
				`${now.getHours().toString().padStart(2, '0')}:` +
				`${now.getMinutes().toString().padStart(2, '0')}:` +
				`${now.getSeconds().toString().padStart(2, '0')}.` +
				`${now.getMilliseconds().toString().padStart(3, '0')}`;
			console.log(`üîä ${source} | vars.inSilence: ${vars.inSilence} - volume: ${percent.toFixed(2)}% | ${timeStr}`);
			//----------- Fim dos logs detalhados
		}
	} else {
		// Se est√° em sil√™ncio absoluto (percent 0), reseta timer de ru√≠do
		vars.noiseStartTime = null;

		const elapsed = Date.now() - vars.lastActive;

		if (elapsed >= silenceTimeout && !vars.inSilence) {
			//----------- Logs detalhados para debug
			const now = new Date();
			const timeStr =
				`${now.getHours().toString().padStart(2, '0')}:` +
				`${now.getMinutes().toString().padStart(2, '0')}:` +
				`${now.getSeconds().toString().padStart(2, '0')}.` +
				`${now.getMilliseconds().toString().padStart(3, '0')}`;
			console.log(
				`üîä ${source} | elapsed: ${elapsed} >= silenceTimeout: ${silenceTimeout} !vars.inSilence: ${!vars.inSilence} - volume: ${percent.toFixed(
					2,
				)}% | ${timeStr}`,
			);
			//----------- Fim dos logs detalhados

			vars.inSilence = true;
			vars.finalizeTriggered = true; // üî• Trava a inten√ß√£o de finalizar

			// NOSONAR
			console.log('***** üîá Sil√™ncio detectado (est√°vel)! *****');

			// enviar comando Finalize para Deepgram
			sendDeepgramFinalize(source);
		}
	}
}

/* ================================
   INICIALIZA√á√ÉO DO WEBSOCKET
================================ */

// Mock simples para n√£o abrir conex√£o real
function initDeepgramWSMock() {
	return {
		readyState: WebSocket.CLOSED, // nunca abre
		send: data => console.log('Simula√ß√£o: dados de √°udio capturados', data),
		close: () => console.log('Simula√ß√£o: conex√£o fechada'),
	};
}

/**
 * Inicializa conex√£o WebSocket com Deepgram (gen√©rica para input/output)
 * @param {string} source - 'input' ou 'output'
 * @returns {Promise<WebSocket>}
 */
async function initDeepgramWS(source = 'input') {
	const isInput = source === 'input';
	const existingWS = isInput ? deepgramInputWebSocket : deepgramOutputWebSocket;

	if (existingWS && existingWS.readyState === WebSocket.OPEN) {
		console.log(`üåä WebSocket Deepgram ${source} j√° aberto`);
		return existingWS;
	}

	// Pega chave Deepgram salva
	const apiKey = await ipcRenderer.invoke('GET_API_KEY', 'deepgram');
	if (!apiKey) {
		throw new Error('‚ùå Chave Deepgram n√£o configurada. Configure em "API e Modelos"');
	}

	console.log(`üåä Inicializando WebSocket Deepgram ${source}...`);

	// Monta URL com par√¢metros (token √© passado na URL para evitar erros 401)
	const params = new URLSearchParams({
		model: 'nova-3',
		language: 'multi',
		encoding: 'linear16', // PCM16
		sample_rate: '16000', // 16kHz
		smart_format: 'true', // Formata√ß√£o inteligente
		interim_results: 'true', // Habilita interim results
		utterance_end_ms: '1000', // Finaliza a frase ap√≥s 1s de sil√™ncio
		endpointing: '100', // Detecta pausas naturais
		keyterm: ['JDK', 'JRE', 'JVM', 'P.O.O', 'TDD', 'BDD', 'DDD', 'DLT', 'SOLID', 'MVC'], // Termos t√©cnicos comuns
		punctuate: 'true', // Melhor pontua√ß√£o
		utterances: 'true', // Habilita timestamps de utterances para calcular dura√ß√£o real da fala
	});

	const wsUrl = `wss://api.deepgram.com/v1/listen?${params.toString()}`;
	const ws = new WebSocket(wsUrl, ['token', apiKey.trim()]);

	return new Promise((resolve, reject) => {
		ws.onopen = () => {
			console.log(`‚úÖ WebSocket Deepgram ${source} conectado | readyState: ${ws.readyState}`);

			// Inicia heartbeat para manter conex√£o viva
			startDeepgramHeartbeat(ws, source);
			resolve(ws);
		};

		ws.onmessage = event => {
			console.log('üí¨ Mensagem Deepgram OUTPUT recebida (tamanho:', event.data.length, 'bytes)');
			try {
				// Recep√ß√£o e Processamento de Transcri√ß√µes
				const data = JSON.parse(event.data);
				handleDeepgramMessage(data, source);
			} catch (e) {
				console.error(`‚ùå Erro ao processar mensagem Deepgram ${source}:`, e);
			}
		};

		ws.onerror = err => {
			console.error(`‚ùå Erro WebSocket Deepgram ${source}:`, err);
			console.error('   Type:', err.type, 'Message:', err.message);

			reject(new Error(`Falha ao conectar Deepgram ${source}`));
		};

		ws.onclose = event => {
			console.log(
				`üõë WebSocket Deepgram ${source} fechado | Code: ${event.code} | Reason: ${event.reason || 'nenhum'} | Clean: ${
					event.wasClean
				}`,
			);
			stopDeepgramHeartbeat(source);
			if (isInput) deepgramInputWebSocket = null;
			else deepgramOutputWebSocket = null;
		};
	});
}

/**
 * Inicia heartbeat para manter WebSocket Deepgram vivo
 * @param {WebSocket} ws - WebSocket aberto
 * @param {string} source - 'input' ou 'output'
 */
function startDeepgramHeartbeat(ws, source) {
	const interval = setInterval(() => {
		if (ws && ws.readyState === WebSocket.OPEN) {
			try {
				ws.send(JSON.stringify({ type: 'KeepAlive' }));
			} catch (e) {
				console.error(`‚ùå Erro ao enviar KeepAlive ${source}:`, e);
			}
		}
	}, DEEPGRAM_HEARTBEAT_INTERVAL);

	if (source === 'input') {
		deepgramInputHeartbeatInterval = interval;
	} else {
		deepgramOutputHeartbeatInterval = interval;
	}
}

/**
 * Para heartbeat de um WebSocket
 * @param {string} source - 'input' ou 'output'
 */
function stopDeepgramHeartbeat(source) {
	if (source === 'input') {
		if (deepgramInputHeartbeatInterval) {
			clearInterval(deepgramInputHeartbeatInterval);
			deepgramInputHeartbeatInterval = null;
		}
	} else if (source === 'output') {
		if (deepgramOutputHeartbeatInterval) {
			clearInterval(deepgramOutputHeartbeatInterval);
			deepgramOutputHeartbeatInterval = null;
		}
	}
}

/**
 * Envia comando "Finalize" para Deepgram para for√ßar processamento imediato do buffer de √°udio pendente
 */
function sendDeepgramFinalize(source) {
	const ws = source === 'input' ? deepgramInputWebSocket : deepgramOutputWebSocket;

	if (ws && ws.readyState === WebSocket.OPEN) {
		try {
			ws.send(JSON.stringify({ type: 'Finalize' }));
		} catch (e) {
			console.error(`‚ùå Erro ao enviar Finalize ${source}:`, e);
		}
	}
}

/**
 * Troca din√¢mica do dispositivo de INPUT enquanto Deepgram est√° ativo
 * @param {string} newDeviceId
 */
async function switchDeepgramInputDevice(newDeviceId) {
	if (isSwitchingInput) {
		console.warn('J√° em processo de troca de dispositivo INPUT');
		return;
	}
	if (!deepgramVars.input.isActive()) {
		console.warn('Deepgram INPUT n√£o est√° ativo; nada a trocar');
		return;
	}

	isSwitchingInput = true;
	try {
		// Opcional: pede ao Deepgram para finalizar buffer atual
		sendDeepgramFinalize('input');

		// Adquire novo MediaStream para o device solicitado
		const newStream = await navigator.mediaDevices.getUserMedia({
			audio: {
				deviceId: { exact: newDeviceId },
				echoCancellation: true,
				noiseSuppression: true,
				autoGainControl: false,
			},
		});

		// Cria nova source e conecta ao HPF existente (ou cria HPF se necess√°rio)
		const newSource = deepgramInputAudioContext.createMediaStreamSource(newStream);
		if (!deepgramInputHPF) {
			deepgramInputHPF = deepgramInputAudioContext.createBiquadFilter();
			deepgramInputHPF.type = 'highpass';
			deepgramInputHPF.frequency.value = 150;
			deepgramInputHPF.Q.value = 1;
		}

		// Desconecta antiga source
		try {
			if (deepgramInputSource) deepgramInputSource.disconnect();
		} catch (e) {}

		// Conecta nova source -> HPF -> processor
		newSource.connect(deepgramInputHPF);
		deepgramInputHPF.connect(deepgramInputProcessor);

		// Para evitar leaks, para tracks do stream anterior
		if (deepgramInputStream) {
			try {
				deepgramInputStream.getTracks().forEach(t => t.stop());
			} catch (e) {}
		}

		// Atualiza refer√™ncias
		deepgramInputStream = newStream;
		deepgramInputSource = newSource;
		deepgramVars.input.setStream(newStream);

		console.log('‚úÖ Troca de dispositivo INPUT conclu√≠da');
	} catch (e) {
		console.error('‚ùå Falha ao trocar dispositivo INPUT:', e);
		throw e;
	} finally {
		isSwitchingInput = false;
	}
}

/**
 * Troca din√¢mica do dispositivo de OUTPUT enquanto Deepgram est√° ativo
 * @param {string} newDeviceId
 */
async function switchDeepgramOutputDevice(newDeviceId) {
	if (isSwitchingOutput) {
		console.warn('J√° em processo de troca de dispositivo OUTPUT');
		return;
	}
	if (!deepgramVars.output.isActive()) {
		console.warn('Deepgram OUTPUT n√£o est√° ativo; nada a trocar');
		return;
	}

	isSwitchingOutput = true;
	try {
		sendDeepgramFinalize('output');

		const newStream = await navigator.mediaDevices.getUserMedia({
			audio: {
				deviceId: { exact: newDeviceId },
				echoCancellation: true,
				noiseSuppression: true,
				autoGainControl: false,
			},
		});

		const newSource = deepgramOutputAudioContext.createMediaStreamSource(newStream);
		if (!deepgramOutputHPF) {
			deepgramOutputHPF = deepgramOutputAudioContext.createBiquadFilter();
			deepgramOutputHPF.type = 'highpass';
			deepgramOutputHPF.frequency.value = 150;
			deepgramOutputHPF.Q.value = 1;
		}

		try {
			if (deepgramOutputSource) deepgramOutputSource.disconnect();
		} catch (e) {}

		newSource.connect(deepgramOutputHPF);
		deepgramOutputHPF.connect(deepgramOutputProcessor);

		if (deepgramOutputStream) {
			try {
				deepgramOutputStream.getTracks().forEach(t => t.stop());
			} catch (e) {}
		}

		deepgramOutputStream = newStream;
		deepgramOutputSource = newSource;
		deepgramVars.output.setStream(newStream);

		console.log('‚úÖ Troca de dispositivo OUTPUT conclu√≠da');
	} catch (e) {
		console.error('‚ùå Falha ao trocar dispositivo OUTPUT:', e);
		throw e;
	} finally {
		isSwitchingOutput = false;
	}
}

/* ================================
   PROCESSAMENTO DE MENSAGENS
================================ */

/**
 * Processa mensagens do Deepgram para INPUT ou OUTPUT
 * INPUT = Microfone do usu√°rio (Voc√™ / Microfone)
 * OUTPUT = Sa√≠da de √°udio do PC (Outros / VoiceMeter)
 */
function handleDeepgramMessage(data, source = 'input') {
	const transcript = data.channel?.alternatives?.[0]?.transcript || '';

	const isFinal = data.is_final || false;
	const speechFinal = data.speech_final;

	// Logs b√°sicos
	console.log(`üì• RESPOSTA DO DEEPGRAM - (${source}) - ${new Date().toLocaleTimeString('pt-BR')}`);
	console.log(`üì• Mensagem Deepgram ${source} recebida:`, data);
	console.log(`üü° isFinal: ${isFinal}, speechFinal: ${speechFinal}`);

	if (!transcript?.trim()) return; // Ignora transcri√ß√µes vazias

	if (isFinal) {
		handleFinalDeepgramMessage(source, transcript);
	} else {
		handleInterimDeepgramMessage(source, transcript);
	}
}

/**
 * Processa mensagens interim do Deepgram (transcri√ß√µes parciais)
 */
function handleInterimDeepgramMessage(source, transcript) {
	console.log(`üü° Handle INTERIM [${source}]: "${transcript}"`);

	const isInput = source === 'input';
	const author = isInput ? YOU : OTHER;

	// Define ID do elemento interim
	const interimId = isInput ? 'deepgram-interim-input' : 'deepgram-interim-output';

	// Emitir atualiza√ß√£o de interim via RendererAPI
	if (globalThis.RendererAPI?.emitUIChange) {
		globalThis.RendererAPI.emitUIChange('onUpdateInterim', {
			id: interimId,
			speaker: author,
			text: transcript,
		});
	}

	// Para OUTPUT, atualizar CURRENT com interim
	if (!isInput && globalThis.RendererAPI?.handleCurrentQuestion) {
		globalThis.RendererAPI.handleCurrentQuestion(author, transcript, {
			isInterim: true,
			inSilence: deepgramVars[source].inSilence,
		});
	}
}

/**
 * Processa mensagens finais do Deepgram (transcri√ß√µes completas)
 */
function handleFinalDeepgramMessage(source, transcript) {
	console.log(`üìù ‚úÖ Handle FINAL [${source.toUpperCase()}]: "${transcript}"`);

	const vars = deepgramVars[source];
	// üî• NOVO: Consideramos sil√™ncio se a flag est√° ativa OU se acabamos de disparar um Finalize
	const shouldFinalize = vars.inSilence || vars.finalizeTriggered;

	// Calcular m√©tricas de timing
	const isInput = source === 'input';
	const author = isInput ? YOU : OTHER;
	const now = Date.now();
	const metrics = isInput
		? { startAt: deepgramInputStartAt, stopAt: now }
		: { startAt: deepgramOutputStartAt, stopAt: now };
	const { startAt, stopAt } = metrics;
	const startStr = startAt ? new Date(startAt).toLocaleTimeString() : new Date(now).toLocaleTimeString();
	const stopStr = stopAt ? new Date(stopAt).toLocaleTimeString() : new Date(now).toLocaleTimeString();
	const recordingDuration = startAt ? ((stopAt - startAt) / 1000).toFixed(2) : '0.00';
	const latency = startAt ? ((now - startAt) / 1000).toFixed(2) : '0.00';
	const total = startAt ? ((stopAt - deepgramInputStartAt) / 1000).toFixed(2) : '0.00';

	// Criar placeholder ID √∫nico
	const placeholderId = `dg-${source}-${Date.now()}-${Math.floor(Math.random() * 1000)}`;

	// Adicionar transcri√ß√£o com placeholder via evento
	const transcriptData = {
		author,
		text: '...', // Placeholder, ser√° preenchido com onPlaceholderFulfill
		timeStr: startAt ? new Date(startAt).toLocaleTimeString() : new Date(now).toLocaleTimeString(),
		elementId: 'conversation',
		placeholderId: placeholderId,
	};

	if (globalThis.RendererAPI?.emitUIChange) {
		globalThis.RendererAPI.emitUIChange('onTranscriptAdd', transcriptData);
	}

	// Preencher placeholder com m√©tricas
	if (globalThis.RendererAPI?.emitUIChange) {
		globalThis.RendererAPI.emitUIChange('onPlaceholderFulfill', {
			speaker: author,
			text: transcript,
			placeholderId: placeholderId,
			startStr: startStr,
			stopStr: stopStr,
			recordingDuration: recordingDuration,
			latency: latency,
			total: total,
			showMeta: false, // N√£o exibir m√©tricas para Deepgram por enquanto
		});
	}

	// Limpar elemento interim no UI
	const interimId = isInput ? 'deepgram-interim-input' : 'deepgram-interim-output';
	if (globalThis.RendererAPI?.emitUIChange) {
		globalThis.RendererAPI.emitUIChange('onClearInterim', { id: interimId });
	}

	// Para OUTPUT, atualizar CURRENT com final
	if (!isInput && globalThis.RendererAPI?.handleCurrentQuestion) {
		globalThis.RendererAPI.handleCurrentQuestion(author, transcript, {
			isInterim: false,
			inSilence: shouldFinalize,
		});
	}

	// Reset da flag de trigger ap√≥s processar a mensagem final
	vars.finalizeTriggered = false;
}

/* ================================
	DEEPGRAM - PARA FLUXO (STT)
================================ */

// Wrapper para parar Deepgram INPUT e OUTPUT
function stopAudioDeepgram() {
	debugLogRenderer('In√≠cio da fun√ß√£o: "stopAudioDeepgram"');

	try {
		// üåä Deepgram: Para INPUT e OUTPUT
		stopAllDeepgram(); // Fecha WebSocket
		console.log('‚úÖ Deepgram parado');
	} catch (error) {
		console.error('‚ùå Erro ao parar Deepgram:', error);
	}

	debugLogRenderer('Fim da fun√ß√£o: "stopAudioDeepgram"');
}

/**
 * Para ambos Deepgram INPUT e OUTPUT
 */
function stopAllDeepgram() {
	stopDeepgram('input');
	stopDeepgram('output');
	console.log('üåä Deepgram completamente parado');
}

/**
 * Para captura Deepgram de um source espec√≠fico (input/output)
 */
function stopDeepgram(source) {
	const vars = deepgramVars[source];

	// Verifica√ß√£o de estado: se j√° parado, sai cedo
	if (!vars.isActive()) {
		console.log(`‚ö†Ô∏è Deepgram ${source} j√° parado, pulando.`);
		return;
	}

	// Define flag como false
	vars.setActive(false);

	// Envia "CloseStream" se WebSocket estiver aberto
	const ws = vars.ws();
	if (ws && ws.readyState === WebSocket.OPEN) {
		try {
			ws.send(JSON.stringify({ type: 'CloseStream' }));
			console.log(`üì§ CloseStream enviado para ${source.toUpperCase()}`);
		} catch (e) {
			console.error(`‚ùå Erro ao enviar CloseStream ${source}:`, e);
		}
	}

	// Para heartbeat
	stopDeepgramHeartbeat(source);

	// Fecha WebSocket
	if (ws) {
		try {
			ws.close();
		} catch (e) {
			console.error(`Erro ao fechar WebSocket ${source}:`, e);
		}
		vars.setWs(null);
	}

	// Limpar elemento interim no UI
	const interimId = source === 'input' ? 'deepgram-interim-input' : 'deepgram-interim-output';
	if (globalThis.RendererAPI?.emitUIChange) {
		globalThis.RendererAPI.emitUIChange('onClearInterim', { id: interimId });
	}

	// Limpa recursos
	const processor = vars.processor();
	if (processor) {
		processor.disconnect();
		vars.setProcessor(null);
	}

	const stream = vars.stream();
	if (stream) {
		stream.getTracks().forEach(t => t.stop());
		vars.setStream(null);
	}

	// Desconecta e limpa MediaStreamSource/HPF se existirem
	if (source === 'input') {
		if (deepgramInputSource) {
			try {
				deepgramInputSource.disconnect();
			} catch (e) {}
			deepgramInputSource = null;
		}
		if (deepgramInputHPF) {
			try {
				deepgramInputHPF.disconnect();
			} catch (e) {}
			deepgramInputHPF = null;
		}
	} else if (source === 'output') {
		if (deepgramOutputSource) {
			try {
				deepgramOutputSource.disconnect();
			} catch (e) {}
			deepgramOutputSource = null;
		}
		if (deepgramOutputHPF) {
			try {
				deepgramOutputHPF.disconnect();
			} catch (e) {}
			deepgramOutputHPF = null;
		}
	}

	const audioContext = vars.audioContext();
	if (audioContext) {
		audioContext.close();
		vars.setAudioContext(null);
	}

	console.log(`üõë Captura Deepgram ${source.toUpperCase()} parada`);
}

/* ================================
   EXPORTS (CommonJS)
================================ */

// Exporta fun√ß√µes principais para uso externo
module.exports = {
	startAudioDeepgram,
	stopAudioDeepgram,
	switchDeepgramInputDevice,
	switchDeepgramOutputDevice,
};
