/**
 * üåä DEEPGRAM LIVE STREAMING - M√ìDULO INDEPENDENTE
 *
 * Implementa√ß√£o isolada de transcri√ß√£o com Deepgram Live Streaming.
 * - Captura √°udio diretamente via WebSocket (sem IPC para dados bin√°rios)
 * - Consolida interim results em transcri√ß√µes finais
 * - Converge para handleSpeech() como outros providers (Whisper, Vosk)
 *
 * Uso:
 * - startAudioDeepgram() -> startDeepgramInput() / stopDeepgramInput() para capturar microfone
 * - startAudioDeepgram() -> startDeepgramOutput() / stopDeepgramOutput() para capturar sa√≠da
 */

/* ================================
   IMPORTS
================================ */
const { ipcRenderer } = require('electron');

/* ================================
   CONSTANTES
================================ */
const YOU = 'Voc√™'; // Autor das transcri√ß√µes de entrada
const OTHER = 'Outros'; // Autor das transcri√ß√µes de sa√≠da

const DEEPGRAM_HEARTBEAT_INTERVAL = 5000; // 5 segundos (entre 3-5 segundos conforme documenta√ß√£o)

/* ================================
   ESTADO DO DEEPGRAM
================================ */

let deepgramInputWebSocket = null; // ‚ö†Ô∏è WebSocket SEPARADO para INPUT
let deepgramOutputWebSocket = null; // ‚ö†Ô∏è WebSocket SEPARADO para OUTPUT
let isDeepgramInputActive = false;
let isDeepgramOutputActive = false;

let deepgramInputAudioContext = null;
let deepgramInputStream = null;
let deepgramInputProcessor = null;

let deepgramOutputAudioContext = null;
let deepgramOutputStream = null;
let deepgramOutputProcessor = null;

// üî• Keepalive para evitar timeout 1011 do Deepgram
// Envia mensagem JSON {"type": "KeepAlive"} a cada 5 segundos
// Documenta√ß√£o: https://developers.deepgram.com/docs/audio-keep-alive
let deepgramInputHeartbeatInterval = null;
let deepgramOutputHeartbeatInterval = null;

// Timestamps para sincronizar com padr√£o de outros modelos
let deepgramInputStartAt = null;
let deepgramOutputStartAt = null;

// Objeto para mapear vari√°veis de input/output
const deepgramVars = {
	input: {
		ws: () => deepgramInputWebSocket,
		setWs: val => (deepgramInputWebSocket = val),
		isActive: () => isDeepgramInputActive,
		setActive: val => (isDeepgramInputActive = val),
		processor: () => deepgramInputProcessor,
		setProcessor: val => (deepgramInputProcessor = val),
		stream: () => deepgramInputStream,
		setStream: val => (deepgramInputStream = val),
		audioContext: () => deepgramInputAudioContext,
		setAudioContext: val => (deepgramInputAudioContext = val),
		lastActive: Date.now(),
		inSilence: false,
	},
	output: {
		ws: () => deepgramOutputWebSocket,
		setWs: val => (deepgramOutputWebSocket = val),
		isActive: () => isDeepgramOutputActive,
		setActive: val => (isDeepgramOutputActive = val),
		processor: () => deepgramOutputProcessor,
		setProcessor: val => (deepgramOutputProcessor = val),
		stream: () => deepgramOutputStream,
		setStream: val => (deepgramOutputStream = val),
		audioContext: () => deepgramOutputAudioContext,
		setAudioContext: val => (deepgramOutputAudioContext = val),
		lastActive: Date.now(),
		inSilence: false,
	},
};

/* ===============================
   DEEPGRAM - INICIA FLUXO (STT)
=============================== */
/**
 * Inicia captura de √°udio do dispositivo de entrada e/ou sa√≠da com Deepgram
 */
async function startAudioDeepgram(UIElements) {
	debugLogRenderer('In√≠cio da fun√ß√£o: "startAudioDeepgram"');

	try {
		// üåä Deepgram: Inicia INPUT/OUTPUT
		if (UIElements.inputSelect?.value) await startDeepgramInput(UIElements);
		if (UIElements.outputSelect?.value) await startDeepgramOutput(UIElements);
	} catch (error) {
		console.error('‚ùå Erro ao iniciar Deepgram:', error);
		throw error;
	}

	debugLogRenderer('Fim da fun√ß√£o: "startAudioDeepgram"');
}

/**
 * Inicia captura de √°udio do dispositivo de entrada com Deepgram
 */
async function startDeepgramInput(UIElements) {
	// Passo 1: Iniciar captura de √°udio da sa√≠da

	if (isDeepgramInputActive) {
		console.warn('‚ö†Ô∏è Deepgram INPUT j√° ativo');
		return;
	}

	try {
		// Obt√©m o dispositivo INPUT selecionado no UI (busca diretamente no DOM)
		const inputDeviceId = UIElements.inputSelect?.value;

		console.log(`üîä Iniciando captura INPUT com dispositivo: ${inputDeviceId}`);

		// Inicializa WebSocket usando fun√ß√£o gen√©rica
		const ws = await initDeepgramWS('input');

		// Define flags globais
		deepgramInputWebSocket = ws;
		isDeepgramInputActive = true;
		deepgramInputStartAt = Date.now();

		// Solicita acesso ao dispositivo INPUT selecionado
		console.log('üé§ Solicitando acesso √† entrada de √°udio (Microfone)...');

		deepgramInputStream = await navigator.mediaDevices.getUserMedia({
			audio: { deviceId: { exact: inputDeviceId } },
		});

		console.log('‚úÖ Entrada de √°udio autorizada');

		// Cria AudioContext com 16kHz
		deepgramInputAudioContext = new (globalThis.AudioContext || globalThis.webkitAudioContext)({
			sampleRate: 16000,
		});

		// Carrega o AudioWorklet
		await deepgramInputAudioContext.audioWorklet.addModule('./deepgram-audio-worklet-processor.js');

		const source = deepgramInputAudioContext.createMediaStreamSource(deepgramInputStream);

		// Cria AudioWorkletNode em vez de ScriptProcessor
		deepgramInputProcessor = new AudioWorkletNode(deepgramInputAudioContext, 'deepgram-audio-worklet-processor');

		// Define threshold para input (microfone) - ajustado para capturar mais
		deepgramInputProcessor.port.postMessage({ type: 'setThreshold', threshold: 0.01 });

		// Escuta mensagens do worklet
		deepgramInputProcessor.port.onmessage = event => {
			const { type, pcm16, percent } = event.data;
			if (type === 'audioData' && deepgramInputWebSocket?.readyState === WebSocket.OPEN) {
				// Envia PCM16 via WebSocket
				deepgramInputWebSocket.send(pcm16);
			} else if (type === 'volumeUpdate') {
				// Atualiza UI com volume
				if (globalThis.RendererAPI?.emitUIChange) {
					globalThis.RendererAPI.emitUIChange('onInputVolumeUpdate', { percent });
				}

				// Trata detec√ß√£o de sil√™ncio
				handleSilenceDetection('input', percent);
			}
		};

		source.connect(deepgramInputProcessor);
		deepgramInputProcessor.connect(deepgramInputAudioContext.destination);

		console.log('‚ñ∂Ô∏è Captura Deepgram INPUT iniciada');
	} catch (error) {
		console.error('‚ùå Erro ao iniciar Deepgram INPUT:', error);
		isDeepgramInputActive = false;
		stopDeepgram('input');
		throw error;
	}
}

/**
 * Inicia captura de √°udio da sa√≠da (speaker/loopback via VoiceMeter ou Stereo Mix)
 * Usa o dispositivo selecionado no select #audio-output-device (mesma l√≥gica do INPUT)
 */
async function startDeepgramOutput(UIElements) {
	// Passo 1: Iniciar captura de √°udio da sa√≠da

	if (isDeepgramOutputActive) {
		console.warn('‚ö†Ô∏è Deepgram OUTPUT j√° ativo');
		return;
	}

	try {
		// Obt√©m o dispositivo OUTPUT selecionado no UI (busca diretamente no DOM)
		const outputDeviceId = UIElements.outputSelect?.value;

		console.log(`üîä Iniciando captura OUTPUT com dispositivo: ${outputDeviceId}`);

		// Inicializa WebSocket usando fun√ß√£o gen√©rica
		const ws = await initDeepgramWS('output');

		// Define flags globais
		deepgramOutputWebSocket = ws;
		isDeepgramOutputActive = true;
		deepgramOutputStartAt = Date.now();

		// Solicita acesso ao dispositivo OUTPUT selecionado
		console.log('üîä Solicitando acesso √† sa√≠da de √°udio (VoiceMeter/Stereo Mix)...');

		deepgramOutputStream = await navigator.mediaDevices.getUserMedia({
			audio: { deviceId: { exact: outputDeviceId } },
		});

		console.log('‚úÖ Sa√≠da de √°udio autorizada');

		// Cria AudioContext com 16kHz
		deepgramOutputAudioContext = new (globalThis.AudioContext || globalThis.webkitAudioContext)({
			sampleRate: 16000,
		});
		// Carrega o AudioWorklet
		await deepgramOutputAudioContext.audioWorklet.addModule('./deepgram-audio-worklet-processor.js');

		// Cria MediaStreamSource a partir do stream capturado
		const source = deepgramOutputAudioContext.createMediaStreamSource(deepgramOutputStream);

		// Cria AudioWorkletNode em vez de ScriptProcessor
		deepgramOutputProcessor = new AudioWorkletNode(deepgramOutputAudioContext, 'deepgram-audio-worklet-processor');

		// Define threshold para output (VoiceMeter) - ainda mais baixo para capturar finais de fala
		deepgramOutputProcessor.port.postMessage({ type: 'setThreshold', threshold: 0.005 });

		// Escuta mensagens do worklet
		deepgramOutputProcessor.port.onmessage = event => {
			const { type, pcm16, percent } = event.data;
			if (type === 'audioData' && deepgramOutputWebSocket?.readyState === WebSocket.OPEN) {
				// Envia PCM16 via WebSocket
				deepgramOutputWebSocket.send(pcm16);
			} else if (type === 'volumeUpdate') {
				// Atualiza UI com volume
				if (globalThis.RendererAPI?.emitUIChange) {
					globalThis.RendererAPI.emitUIChange('onOutputVolumeUpdate', { percent });
				}

				// Trata detec√ß√£o de sil√™ncio
				handleSilenceDetection('output', percent, 500); // 500ms para output
			}
		};

		source.connect(deepgramOutputProcessor);
		deepgramOutputProcessor.connect(deepgramOutputAudioContext.destination);

		console.log('‚ñ∂Ô∏è Captura Deepgram OUTPUT iniciada');
	} catch (error) {
		console.error('‚ùå Erro ao iniciar Deepgram OUTPUT:', error);
		isDeepgramOutputActive = false;
		stopDeepgram('output');
		throw error;
	}
}

/* ================================
   INICIALIZA√á√ÉO DO WEBSOCKET
================================ */

/**
 * Inicializa conex√£o WebSocket com Deepgram (gen√©rica para input/output)
 * @param {string} source - 'input' ou 'output'
 * @returns {Promise<WebSocket>}
 */
async function initDeepgramWS(source = 'input') {
	const isInput = source === 'input';
	const existingWS = isInput ? deepgramInputWebSocket : deepgramOutputWebSocket;

	if (existingWS && existingWS.readyState === WebSocket.OPEN) {
		console.log(`üåä WebSocket Deepgram ${source} j√° aberto`);
		return existingWS;
	}

	// Pega chave Deepgram salva
	const apiKey = await ipcRenderer.invoke('GET_API_KEY', 'deepgram');
	if (!apiKey) {
		throw new Error('‚ùå Chave Deepgram n√£o configurada. Configure em "API e Modelos"');
	}

	console.log(`üåä Inicializando WebSocket Deepgram ${source}...`);

	// Monta URL com par√¢metros (token √© passado na URL para evitar erros 401)
	const params = new URLSearchParams({
		model: 'nova-3',
		language: 'pt-BR',
		smart_format: 'true',
		punctuate: 'true', // Melhor pontua√ß√£o
		interim_results: 'true',
		encoding: 'linear16',
		sample_rate: '16000',
		endpointing: '300', // Detecta pausas naturais
		utterance_end_ms: '1000', // Finaliza a frase ap√≥s 1s de sil√™ncio
		utterances: 'true', // Habilita timestamps de utterances para calcular dura√ß√£o real da fala
	});

	const wsUrl = `wss://api.deepgram.com/v1/listen?${params.toString()}`;
	const ws = new WebSocket(wsUrl, ['token', apiKey.trim()]);

	return new Promise((resolve, reject) => {
		ws.onopen = () => {
			console.log(`‚úÖ WebSocket Deepgram ${source} conectado | readyState: ${ws.readyState}`);

			// Inicia heartbeat para manter conex√£o viva
			startDeepgramHeartbeat(ws, source);
			resolve(ws);
		};

		ws.onmessage = event => {
			console.log('üí¨ Mensagem Deepgram OUTPUT recebida (tamanho:', event.data.length, 'bytes)');
			try {
				// Recep√ß√£o e Processamento de Transcri√ß√µes
				const data = JSON.parse(event.data);
				handleDeepgramMessage(data, source);
			} catch (e) {
				console.error(`‚ùå Erro ao processar mensagem Deepgram ${source}:`, e);
			}
		};

		ws.onerror = err => {
			console.error(`‚ùå Erro WebSocket Deepgram ${source}:`, err);
			console.error('   Type:', err.type, 'Message:', err.message);

			reject(new Error(`Falha ao conectar Deepgram ${source}`));
		};

		ws.onclose = event => {
			console.log(
				`üõë WebSocket Deepgram ${source} fechado | Code: ${event.code} | Reason: ${event.reason || 'nenhum'} | Clean: ${
					event.wasClean
				}`,
			);
			stopDeepgramHeartbeat(source);
			if (isInput) deepgramInputWebSocket = null;
			else deepgramOutputWebSocket = null;
		};
	});
}

/**
 * Inicia heartbeat para manter WebSocket Deepgram vivo
 * @param {WebSocket} ws - WebSocket aberto
 * @param {string} source - 'input' ou 'output'
 */
function startDeepgramHeartbeat(ws, source) {
	const interval = setInterval(() => {
		if (ws && ws.readyState === WebSocket.OPEN) {
			try {
				ws.send(JSON.stringify({ type: 'KeepAlive' }));
			} catch (e) {
				console.error(`‚ùå Erro ao enviar KeepAlive ${source}:`, e);
			}
		}
	}, DEEPGRAM_HEARTBEAT_INTERVAL);

	if (source === 'input') {
		deepgramInputHeartbeatInterval = interval;
	} else {
		deepgramOutputHeartbeatInterval = interval;
	}
}

/**
 * Para heartbeat de um WebSocket
 * @param {string} source - 'input' ou 'output'
 */
function stopDeepgramHeartbeat(source) {
	if (source === 'input') {
		if (deepgramInputHeartbeatInterval) {
			clearInterval(deepgramInputHeartbeatInterval);
			deepgramInputHeartbeatInterval = null;
		}
	} else if (source === 'output') {
		if (deepgramOutputHeartbeatInterval) {
			clearInterval(deepgramOutputHeartbeatInterval);
			deepgramOutputHeartbeatInterval = null;
		}
	}
}

/* ================================
   PROCESSAMENTO DE MENSAGENS
================================ */

/**
 * Processa mensagens do Deepgram para INPUT ou OUTPUT
 * INPUT = Microfone do usu√°rio (Voc√™ / Microfone)
 * OUTPUT = Sa√≠da de √°udio do PC (Outros / VoiceMeter)
 */
function handleDeepgramMessage(data, source = 'input') {
	const transcript = data.channel?.alternatives?.[0]?.transcript || '';

	const isFinal = data.is_final || false;
	const speechFinal = data.speech_final;

	// Logs b√°sicos
	console.log(`üì• RESPOSTA DO DEEPGRAM - (${source}) - ${new Date().toLocaleTimeString('pt-BR')}`);
	console.log(`üì• Mensagem Deepgram ${source} recebida:`, data);
	console.log(`üü° isFinal: ${isFinal}, speechFinal: ${speechFinal}`);

	if (!transcript?.trim()) return; // Ignora transcri√ß√µes vazias

	if (isFinal) {
		handleFinalDeepgramMessage(source, transcript);
	} else {
		handleInterimDeepgramMessage(source, transcript);
	}
}

/**
 * Processa mensagens interim do Deepgram (transcri√ß√µes parciais)
 */
function handleInterimDeepgramMessage(source, transcript) {
	console.log(`üü° Handle INTERIM [${source}]: "${transcript}"`);

	const isInput = source === 'input';
	const author = isInput ? YOU : OTHER;

	// Define ID do elemento interim
	const interimId = isInput ? 'deepgram-interim-input' : 'deepgram-interim-output';

	// Emitir atualiza√ß√£o de interim via RendererAPI
	if (globalThis.RendererAPI?.emitUIChange) {
		globalThis.RendererAPI.emitUIChange('onUpdateInterim', {
			id: interimId,
			speaker: author,
			text: transcript,
		});
	}

	// Para OUTPUT, atualizar CURRENT com interim
	if (!isInput && globalThis.RendererAPI?.handleCurrentQuestion) {
		globalThis.RendererAPI.handleCurrentQuestion(author, transcript, {
			isInterim: true,
			inSilence: deepgramVars[source].inSilence,
		});
	}
}

/**
 * Processa mensagens finais do Deepgram (transcri√ß√µes completas)
 */
function handleFinalDeepgramMessage(source, transcript) {
	console.log(`üìù ‚úÖ Handle FINAL [${source.toUpperCase()}]: "${transcript}"`);

	// Calcular m√©tricas de timing
	const isInput = source === 'input';
	const author = isInput ? YOU : OTHER;
	const now = Date.now();
	const metrics = isInput
		? { startAt: deepgramInputStartAt, stopAt: now }
		: { startAt: deepgramOutputStartAt, stopAt: now };
	const { startAt, stopAt } = metrics;
	const startStr = startAt ? new Date(startAt).toLocaleTimeString() : new Date(now).toLocaleTimeString();
	const stopStr = stopAt ? new Date(stopAt).toLocaleTimeString() : new Date(now).toLocaleTimeString();
	const recordingDuration = startAt ? ((stopAt - startAt) / 1000).toFixed(2) : '0.00';
	const latency = startAt ? ((now - startAt) / 1000).toFixed(2) : '0.00';
	const total = startAt ? ((stopAt - deepgramInputStartAt) / 1000).toFixed(2) : '0.00';

	// Criar placeholder ID √∫nico
	const placeholderId = `dg-${source}-${Date.now()}-${Math.floor(Math.random() * 1000)}`;

	// Adicionar transcri√ß√£o com placeholder via evento
	const transcriptData = {
		author,
		text: '...', // Placeholder, ser√° preenchido com onPlaceholderFulfill
		timeStr: startAt ? new Date(startAt).toLocaleTimeString() : new Date(now).toLocaleTimeString(),
		elementId: 'conversation',
		placeholderId: placeholderId,
	};

	if (globalThis.RendererAPI?.emitUIChange) {
		globalThis.RendererAPI.emitUIChange('onTranscriptAdd', transcriptData);
	}

	// Preencher placeholder com m√©tricas
	if (globalThis.RendererAPI?.emitUIChange) {
		globalThis.RendererAPI.emitUIChange('onPlaceholderFulfill', {
			speaker: author,
			text: transcript,
			placeholderId: placeholderId,
			startStr: startStr,
			stopStr: stopStr,
			recordingDuration: recordingDuration,
			latency: latency,
			total: total,
			showMeta: false, // N√£o exibir m√©tricas para Deepgram por enquanto
		});
	}

	// Limpar elemento interim no UI
	const interimId = isInput ? 'deepgram-interim-input' : 'deepgram-interim-output';
	if (globalThis.RendererAPI?.emitUIChange) {
		globalThis.RendererAPI.emitUIChange('onClearInterim', { id: interimId });
	}

	// Para OUTPUT, atualizar CURRENT com final
	if (!isInput && globalThis.RendererAPI?.handleCurrentQuestion) {
		globalThis.RendererAPI.handleCurrentQuestion(author, transcript, {
			isInterim: false,
			inSilence: deepgramVars[source].inSilence,
		});
	}
}

// Trata detec√ß√£o de sil√™ncio com base no volume percentual
function handleSilenceDetection(source, percent, silenceTimeout = 1000) {
	// NOSONAR console.log(`üîä ${source} volume: ${percent.toFixed(2)}%`);

	const vars = deepgramVars[source];
	let { lastActive, inSilence } = vars;

	if (percent > 0) {
		vars.lastActive = Date.now();
		if (inSilence) {
			// NOSONAR console.log('üîä Som voltou: ', percent.toFixed(2), '%');
			vars.inSilence = false;
		}
	} else {
		const elapsed = Date.now() - lastActive;
		if (elapsed >= silenceTimeout && !inSilence) {
			// NOSONAR
			console.log('***** üîá Sil√™ncio detectado! *****');
			vars.inSilence = true;

			// enviar comando Finalize para Deepgram
			sendDeepgramFinalize(source);
		}
	}
}

/**
 * Envia comando "Finalize" para Deepgram para for√ßar processamento imediato do buffer de √°udio pendente
 */
function sendDeepgramFinalize(source) {
	const ws = source === 'input' ? deepgramInputWebSocket : deepgramOutputWebSocket;

	if (ws && ws.readyState === WebSocket.OPEN) {
		try {
			ws.send(JSON.stringify({ type: 'Finalize' }));
		} catch (e) {
			console.error(`‚ùå Erro ao enviar Finalize ${source}:`, e);
		}
	}
}

/* ================================
	DEEPGRAM - PARA FLUXO (STT)
================================ */

// Wrapper para parar Deepgram INPUT e OUTPUT
function stopAudioDeepgram() {
	debugLogRenderer('In√≠cio da fun√ß√£o: "stopAudioDeepgram"');

	try {
		// üåä Deepgram: Para INPUT e OUTPUT
		stopAllDeepgram(); // Fecha WebSocket
		console.log('‚úÖ Deepgram parado');
	} catch (error) {
		console.error('‚ùå Erro ao parar Deepgram:', error);
	}

	debugLogRenderer('Fim da fun√ß√£o: "stopAudioDeepgram"');
}

/**
 * Para ambos Deepgram INPUT e OUTPUT
 */
function stopAllDeepgram() {
	stopDeepgram('input');
	stopDeepgram('output');
	console.log('üåä Deepgram completamente parado');
}

/**
 * Para captura Deepgram de um source espec√≠fico (input/output)
 */
function stopDeepgram(source) {
	const vars = deepgramVars[source];

	// Verifica√ß√£o de estado: se j√° parado, sai cedo
	if (!vars.isActive()) {
		console.log(`‚ö†Ô∏è Deepgram ${source} j√° parado, pulando.`);
		return;
	}

	// Define flag como false
	vars.setActive(false);

	// Envia "CloseStream" se WebSocket estiver aberto
	const ws = vars.ws();
	if (ws && ws.readyState === WebSocket.OPEN) {
		try {
			ws.send(JSON.stringify({ type: 'CloseStream' }));
			console.log(`üì§ CloseStream enviado para ${source.toUpperCase()}`);
		} catch (e) {
			console.error(`‚ùå Erro ao enviar CloseStream ${source}:`, e);
		}
	}

	// Para heartbeat
	stopDeepgramHeartbeat(source);

	// Fecha WebSocket
	if (ws) {
		try {
			ws.close();
		} catch (e) {
			console.error(`Erro ao fechar WebSocket ${source}:`, e);
		}
		vars.setWs(null);
	}

	// Limpar elemento interim no UI
	const interimId = source === 'input' ? 'deepgram-interim-input' : 'deepgram-interim-output';
	if (globalThis.RendererAPI?.emitUIChange) {
		globalThis.RendererAPI.emitUIChange('onClearInterim', { id: interimId });
	}

	// Limpa recursos
	const processor = vars.processor();
	if (processor) {
		processor.disconnect();
		vars.setProcessor(null);
	}

	const stream = vars.stream();
	if (stream) {
		stream.getTracks().forEach(t => t.stop());
		vars.setStream(null);
	}

	const audioContext = vars.audioContext();
	if (audioContext) {
		audioContext.close();
		vars.setAudioContext(null);
	}

	console.log(`üõë Captura Deepgram ${source.toUpperCase()} parada`);
}

/* ================================
   EXPORTS (CommonJS)
================================ */

// Exporta fun√ß√µes principais para uso externo
module.exports = {
	startAudioDeepgram,
	stopAudioDeepgram,
};
